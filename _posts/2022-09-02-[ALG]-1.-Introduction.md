---
layout: post
date: 2022-09-02
title: "[ALG] 1. Introduction"
tags: [Algorithm, ]
categories: [Notes, ]
use_math: true
---


Algorithm : Big O and MSS


# **1.0. Computational Thinking**


## **Definition of computational thinking**


The thought processes involved in (i) formulating a problem and (ii) expressing its solutions in such a way that a computer --human or machine- can effectively carry out.

1. Problem formulation (abstraction)
2. Solution expression (automation)
3. Solution execution & evaluation (analyses)

## **Characteristics of computational thinking**

- Formulating problems in a way that enables us to use a computer and other tools to help solve them
- Logically organizing and analyzing data → Data structure
- Representing data though abstractions such as models and simulations → Data Structure
- Automating solutions through algorithmic thinking (a series of ordered steps) → Algorithm
- Identifying, analyzing, and implementing possible solutions with the goal of achieving the most efficient and effective combination of steps and resources → time and space complexity
- Generalizing and transferring the problem solving process to a wide variety of problems

## **Problem Solving in Computer Science and Engineering**


문 제 (Problem) → 해 (Solution)

- Problem : 가상 현실, 문서작성, 홈뱅킹, 인터넷 신문, 문서 번역, 회로 설계, 유전자 분석, 무인 자동차, 온라인 게임, 비디오 편집, 자료 검색, 영화 제작, 음성 인식, 가상 수술, 건축 설계, 기상 예측, 주가 예측, 인공 지능, 대용량 과학 계산, …

## **Problem Solving Pipeline**


![0](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/0.png)


# **도강 문제**


한 어부(M)가 늑대(W), 염소(G), 양배추(C)를 강 한 쪽에서 다른 쪽으로 옮기려 한다. 어부가 배를 타고 강을 건널 때 어부 자신 외에 늑대, 염 소, 양배추 중 하나만 배에 가지고 갈 수가 있는데, 문제는 어부가 늑대 를 싣고 가는 동안, 염소가 양배추를 같은 쪽에 남겨두면 염소가 양배 추를 먹어버리게 되고, 양배추를 싣고 갈 때 늑대와 염소를 같은 쪽에 남겨둘 경우 늑대가 염소를 잡아 먹게 된다. 과연 어떻게 하면 어부가 가장 적은 회수로 강을 건너면서 세 가지를 모두 안전하게 옮길 수 있을까?


## **문제 분석**


![1](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/1.png)

- 

![2](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/2.png)


## **해법 고안**

- Graph, search, and so on → Which data structures and algorithms?
- Cost, time, space, and so on → What complexities?

[연습] 이 문제에 대한 알고리즘과 시간/공간 복잡도를 컴퓨터학의 용 어를 써서 기술한다면, ???

- 무슨 말인지 전혀 모르겠으면 [43-080 자료구조]를 재수강한 후 이 과목을 들을 것!

# **구현 : ✓ Programming is an art!**

- 어떻게 하면 주어진 알고리즘을 가장 효과적으로 구현을 할 수 있을까?
- 어떻게 하면 C/C++를 사용하여 주어진 알고리즘을 가장 최적으로 구현할 수 있을까?
	- 원시 코드 레벨의 측면
	- 어셈블러 레벨의 측면
	- 시스템 레벨의 측면
	- 기타
- ✓ 과연 내가 [http://acm.uva.es/problemset/에](http://acm.uva.es/problemset/%EC%97%90) 있는 문제들을 스스로 “문제 분석 → 해법 고안 → 구현” 과정을 통하여 효과적으로 해결할 수 있을까???
	- Programming Challenges by S. Skiena and M. Revilla, Springer, 2003.
- 어떻게 하면 좋은 구현 결과를 얻을 수 있는가?
	- 동일한 프로세서 상에서 더 빠르게
	- 적은 메모리만 사용하게
	- 안정적이게
- 구현 예

	![3](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/3.png)


	![4](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/4.png)


19 0.265968초 4.862961초 3.4GHz Intel Core i7 CPU


# **Data Structure → Algorithm → Theory of Computation**

- 어떻게 하면 주어진 복잡한 문제를 이진수 형태의 낮은 수준의 명령어만 이해하는 ‘단순한’ 컴퓨터 상에서 효율적으로 해결할 수 있을까?
1. [Data Structure] 주어진 추상적인 문제를 어떠한 자료 구조를 사용하여 컴 퓨터의 구조에 최적화된 형태로 표현할 수 있을까?
2. [Algorithm] 주어진 추상적인 문제를 어떠한 알고리즘을 사용하여 컴퓨터를 사용하여 가장 효율적으로 해결할 수 있을까?
3. [Complexity] 과연 컴퓨터가 주어진 문제를 효율적으로 해결할 수 있을까 ?
4. [Computability] 과연 컴퓨터가 세상의 모든 문제를 해결할 수 있을까?
- ✓ 이 과목에서는 [CSE3080 자료구조] 과목에 이어, 1번과 2번을 집중적으로 살펴보 고, 3번 문제에 대하여 어느 정도 살펴볼 예정임.
- 4번 문제는 [CSE3085 자동장치이론] 과목에서 다룸.

# **1.1 - 1.2 Solve with Alg**


# **1. How to think and solve problems with computer**


## **Data Structure→Algorithm→Theory of Computation**

- 어떻게 하면 주어진 복잡한 문제를 이진수 형태의 낮은 수준의 명령어만 이해하는 ‘단순한’ 컴퓨터 상에서 효율적으로 해결할 수 있을까?
	1. [Data Structure] 주어진 추상적인 문제를 **어떠한 자료 구조**를 사용하여 컴 퓨터의 구조에 최적화된 형태로 표현할 수 있을까?
	2. [Algorithm] 주어진 추상적인 문제를 어떠한 **알고리즘을** 사용하여 컴퓨터를 사용하여 가장 효율적으로 해결할 수 있을까
	3. [Complexity] 과연 컴퓨터가 주어진 문제를 **효율적으로** 해결할 수 있을까 ?
	4. [Computability] 과연 컴퓨터가 세상의 **모든 문제를 해결**할 수 있을까?
- Data Structure & Algorithm → 1, 2, 3
- Automata Theory → 4

# **2. Def. of Algorithm**


## **Definition of Algorithm**


from [Horowitz 1.2]

- An **algorithm** is a **finite set of instructions that**, if followed, accomplishes a particular task. In addition, all algorithms must satisfy the following criteria:
	1. **Input**.
	- Zero or more quantities from the outside.
	- 외부로부터 0개 이상의 수량이 입력으로서 들어온다.
	1. **Output**.
	- At least one quantity is produced.
	- 하나 이상의 결과값이 수행된다.
	1. **Definiteness**.
	- Each instruction is clear and unambiguous.
	- 각 지침은 모두 명확하며, 애매하게 쓰여 있지 않다.
	1. **Finiteness**.
	- If we trace out the instructions of an algorithm, then for all cases, the algorithm terminates after a finite number of steps.
	- 제한된 수의 단계 후 종료된다.
	1. **Effectiveness**.
	- Every instruction must be basic enough to be carried out, in principle, by a person using only pencil and paper.
	- 손으로 풀 수 있을 만큼 효과적이어야 한다.
	- It is not enough that each operation be definite as in (3);
	- it also must be feasible. 또한 실현 가능하여야 한다.

## **Thoughts on 4) Finiteness: [Computability]**

- Problem ([Post’s correspondence problem](https://en.wikipedia.org/wiki/Post_correspondence_problem) 포스트 대응 문제)
	- 결정 불가능한 결정 문제의 예시, 1946년 emil post 에 의해 고안
	- Consider a finite set _P_ of ordered pairs of nonempty strings such as _P_={(_a_,_ab_),(_b_,_c__a_),(_c__a_,_a_),(_ab__c_,_c_)}
	- A match of _P_ is any string w such that, for some _m_>0 and some pairs (_u_1,_v_1),(_u_2,_v_2),...,(_u__m_,_v__m_)∈_P_, _w_=_u_1_u_2..._u__m_=_v_1_v_2..._v__m_.
	- Design an algorithm that determine, given P, whether P has a match.
- Cheolsu’s algorithm

	```c++
	For i = 1, 2, 3, ... do
	  For each permutation of P of length i, do
	    If it is a match, print ‘yes’ and exit.
	    If not, continue.
	
	```

	- Can this be regarded as an algorithm?

## **Thoughts on Efficiency: [Complexity]**

- **An algorithm is regarded as efficient or good** if there exist a polynomial _P_(_n_) such that the time required for solving any instance of size _n_ is bounded above by _P_(_n_).
- NP-Complete problems:
	- Nobody has found so far any good algorithm for any problem in this class.
	- It has been proved that if a good algorithm exists for some algorithm in this class, then a good algorithm exists for all NP-Complete Problem.
- Examples
	- Suppose a CD-ROM can store up to 720MBytes of data. You have a sequence of n files of sizes _s_1,_s_2,...,_s__n_ Mbytes, to dump into backup CDs. What is the minimum number of necessary CDs to store all the files?
	- Consider n tasks to be executed on CPU. All the tasks must be finished within the time requirement L (seconds). If the _i_th task takes _s__i_ seconds, and you can harness multiple processors, what would be the minimum number of processors needed to accomplish this?
	- Ex. _L_=10, _n_=6, and $(s_1, s_2, s_3, s_4, s_5, s_6) = (5, 6, 3, 7, 5, 4) $
	- then (5,5),(6,4),(7,3)

어떻게 하면 좀 더 “효율적으로” 문제를 해결할까?


## **Efficient Algorithm Design**


**Example 1**

- Sequential search vs binary search
	- Problem: Determine whether _x_ is in the sorted array _S_ of _n_ keys.
	- Inputs: positive integer _n_, sorted (nondecreasing order) arrays of keys S indexed from 0 to _n_−1, a key _x_.
	- Outputs: the location of _x_∈_S_ (−1 if _x_∈/_S_).
- Sequential search: _T_(_n_)=_O_(_n_)
- Binary search: _T_(_n_)=_O_(_l__o__g__n_)
- 

	![5](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/5.png)

	- [From Neapolitan] The number of comparisons done by Sequential & Binary Search when _x_ is larger than all the array items
		- 40억 개의 element가 array에 있을 때, Sequential Search는 40억 개 항목과 비교하는 반면에 Binary Search는 단 33개의 항목만을 비교한다.
		- 컴퓨터가 1ns에 whlie loop를 통과할 수 있다고 가정한들 Binary search는 즉각적으로 결정을 내리는 반면 Sequential Search는 4s가 걸린다.
- Why is the binary search more efficient? 왜 이진검색이 더 효율적인가?

**Example 2:The Fibonacci Sequence**

- Problem: Determine the _n_th term in the Fibonacci sequence.
- Inputs: a nonnegative integer _n_
- Outputs: the nth term of the Fibonacci sequence.

	_f_0=0_f_1=1_f__n_=_f__n_−1+_f__n_−2 for _n_≥2


```c++
//<recursive: divide-and-conquer>
int fib (int n) {
  if (n == 0) return 0;
  else if (n == 1) return 1;
  else return fib(n-1) + fib(n-2);
}

//<iterative: dynamic programming>
  int fib(int n) {
  index i;
  int f[0 .. n];
  f[0] = 0;
  if (n > 0) {
  	f[1] = 1;
    for (i = 2; i <= n; i++)
      f[i] = f[i-1] + f[i-2];
  }return f[n];
}

```

- Recursive: $T(n) = O(2^n) $
- Iterative: _T_(_n_)=_O_(_n_)
- Why is the iterative version more efficient?
	- 

		![6](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/6.png)

	- _T_(_n_)>22_n_ for _n_≥2
	- Mathematical induction을 써서 증명해볼 것!
- Linear versus exponential
	- 

		![7](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/7.png)

	- [From Neapolitan] This table compares these expressions for various values of n. The execution times are based on the simplifying assumption that one term can be computed in 10−9 second.
	- The table shows the time it would take 'Iterative Algorithm' to compute the nth term on a hypothetical computer that could compute each term in a nanosecond, and it shows a lower bound on the time it would take to execute 'Iterative Algorithm'.
	- By the time n is 80, 'Recursive Algorithm' takes at least 18 minutes. When n is 120, it takes more than 36 years, an amount of time intolerable compared with a human life span. Even if we could build a computer one billion times as fast, 'Recursive Algorithm' would take over 40,000 years to compute the 200th term. This result can be obtained by dividing the time for the 200th term by one billion.
	- We see that regardless of how fast computers become, 'Recursive Algorithm' will still take an intolerable amount of time unless n is small. On the other hand, 'Iterative Algorithm' computes the nth Fibonacci term almost instantaneously.

	This comparison shows why the efficiency of an algorithm remains an important consideration regardless of how fast computers become


# [ALG] 1.3. Order of Algorithms (1)

- 제일 먼저 생각
	- Input Size
		- Problem을 풀고자 하는데 이를 sol하고자 하는 algorithm에서, 알고리즘에 들어오는 data의 크기는 어떻게 되는가.
			- 문제 상황에 따라 가로 n, 세로 m의 데이터가 들어오면 (n,m) n일수도 nm일수도 있다.
		- data size가 커짐에 따라 얼마나 시간이 걸리는가 분석 : 얼마난 크기의 데이터가 들어왔을 때, 얼마나 시간이 걸리는가.
		- 시간 분석의 기본 요소 : data의 수
	- Cost : $g(n)$
		- 문제가 있을 때 n에 대하여 어느 정도의 비용이 걸리는가.

# _O_ (Big $O$ Notation)


> 💡 for given two functions $f(n)$ and $g(n)$,  
>   
> $g(n) = O(f(n))\iff \exists c \in \mathbb{R}, N \in \mathbb{N}\quad g(n)\leq c\cdot f(n), \forall n \geq N$

- complexity를 따질 때, data size가 작을 때 보다는 커질 때 문제가 발생함을 확인하고 싶음.
	- → 모든 n일 필요는 없고, 그 N보다 큰 모든 input size에 대해서 이러한 조건을 만족하면.
- then we say that :$g(n)$ is big O of $f(n)$
- 예)
	- 코드의 비용을 분석해 봤더니
		- for loop 1, for loop n 자승만큼 돌게 된다.

		```c
		x = x + 1;
		for (i = 1; i <= n; i++)
			y = y + 2;
		for (i = n; i >=1; i--)
			for (j = n; j >= 1; j--)
				z = z + 1;
		```

- 비용 : $g(n) = c_0 + c_1 n + c_2 n^2$
- 예 : $g(n) = 5 + 6 + 7n^2 \leq 8n^2 \quad \forall n \geq 8$
	- $8 \cdot n^2 = c \cdot f(n), N = 8$
		- n이 커지면 g(n)이 압도적으로 다른 친구들을 누르게 된다.
		- 다시한번 이야기하지만, n이 커질 때, 내가 분석한 비용은 f(n)이라는 함수에 눌리게 되는 upper bound 개념
	- $g(n) = O(n^2)$
- $g(n) = O(n^{1000})$?
	- 정의에 의하면 맞음 : 그래프상 확인해보아도 맞음.
	- $f(n)\geq g(n) \cdot c$

## Notes for big O

- [Note 1] The big O puts an <u>**asymptotic**</u> <u>upper bound</u> on a function.
	- 복잡도를 따질 때 ‘몇 초'가 걸린다기 보다는 얼마나 효율적인가를 따지는 척도
		- PL, HW 상황에 대해서 implementation 관점에서 개인 차 발생
	- Asymptotic analysis (from Wikipedia)
		- asymptotic : 점근적인
		- data size가 커질 때, 이 알고리즘이 시간이나 필요로 하는 메모리 사이즈가 얼마나 나빠지는가? → 알고리즘이 요구하는 시간, 메모리 양 등이 얼마나 나쁜 형태로 변화하는지 ‘형태’

			> If $f(n) = n^2 + 3n$, then as n becomes very large, the term $3n$ becomes insignificant compared to $n^2$. The function f(n)f(n) is said to be "asymptotically equivalent to n^2n2, as $n→∞$". This is often written symbolically as $f(n) -> n^2$, which is read as "$f(n)$ is asymptotic to $n^2$".

	- 계산 비용이 $0.01n^2$ 과 $100n$ 알고리즘 중 어떤 것이 더 효율적인가?
		- 이론적인 관점에서 $100n = O(n), 0.01n^2 = O(n^2)$
		- input size $n=3$: $0.09 \quad 300$
		- input size $n=10^6$: $0.01 \cdot (10^6)^2 = 10^{10}$, $100 \cdot 10^6 = 10^8$

		→ 결국 $O(n^2)$

	- (Tight) upper bound
		- $37log n + 0.1n = O(n)$
			- n이 커지면 $\log n$은 상당히 작아짐
		- $n^2 + 10n = O(n^2)$
		- $4(\log n)^2 + n \log n + 100n = O(n \log n)$
			- $\log n$ vs $n$ → 당연하게 $\log n$
			- $n \log n > {\log n} ^2$
		- $n^2 + 10n = O(n^{200})$???
			- upper bound 맞아 틀린 말은 아니지만, 일반적으로 O Notation을 활용할 때에는 tight upper bound를 선택하여 표현한다.

		> 💡 Dominating Term   
		> - 지배하는 term을 찾아 Upper Bound를 찾는다.

			- 지배하는 term을 찾아 Upper Bound를 찾는다.
		- $\log _en $등 base는 왜 고려하지 않느냐 → 상수에 해당하므로 상관 없기 때문에.
			- $\log _2 n = \frac {\log_e n }{\log_e2}$

	### Growth Rates of Some Common Complexity Functions

	- 이론적으로는 $n^3$은 efficient하지만 현실적으로는 문제가 발생할 수 있을만한 복잡도
	- 감당할 수 없을 정도로 커지네 등 asymptotic 특성을 분석하기 위함

![8](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/8.png)

- [Note 2] Given a cost function g(n), how do you find the proper complexity function f(n) such that $g(n) = O(f(n))$?
	- Suppress lower-order terms and constant factors!
	- Example:
		- $10^3 + 10^3n + 10^-3 n^2 = O(n^2)$
			- then $lim_{n \to \infty} \frac{n^2}{n} = \infty$
		- $5n \log_3 n + 3(\log_2 n)^2 + n + 6n^2 = O(n^2)$
			- then $lim_{n \to \infty} \frac{n}{log_en} = lim _{n \to \infty} = \infty$
		- $3(log_2 n)^2+ 0.1n = O(?)$
			- Dominate Term이 무엇일까?
			- $\lim _{n \rightarrow \infty}{\frac {(\log n)^2}{n}}$ =$\infty, c, 0$
				- $\infty$ : $(\log n)^2$ , $0$ : $n$ , $c$ :
				- L’Hospital Theorem : $\lim _{n \rightarrow \infty}{\frac {f(n)}{g(n)}} = \lim _{n \rightarrow \infty}{\frac {f'(n)}{g'(n)}} $
					- $\lim _{n \rightarrow \infty}{\frac {(\log n)^2}{n}} = \lim = \lim _{n \rightarrow \infty} {\frac {2}{n}{}}0$
			- → Linear Time
		- $2^{n+5} = O(2^n)$ ??
		- $2^{5n} = O(2^n)$??

## Comparing Orders of Growth

- How do you compare orders of growth of two functions?
	- One possible way is to compute the limit of the ratio of two functions in question.
	- $x = lim_{n \to \infty } \frac{f_1(n)}{f_2(n)}$
		- if _x_=0, _f_1 has a smaller order of growth than _f_2
		- if $x=c$, $f_1$ has a same order of growth than $f_2$
		- if $x=\infty$, $f_1$ has a larger order of growth than $f_2$
	- Ex.1: $\log_2 n $ vs. $\sqrt{n}$
		- $lim_{n \to \infty} \frac{log_2 n}{\sqrt(n)} = lim_{n \to \infty} \frac{(log_2 n)'}{(\sqrt(n))'} = lim_{n \to \infty} \frac{(log_2 e)\frac{1}{n}}{\sqrt\frac{1}{2\sqrt(n)}} $
	- Ex.1.2.: $\log_2 n $ vs. $n^{0.0001}$
		- $lim_{n \to \infty} \frac{log_2 n}{\sqrt(n)} $
	- Ex.2: $n!$ vs $2^n$ - factorial vs. exponential
		- $lim_{n \to \infty} \frac{ n!}{2^n} = lim_{n \to \infty} \frac{\sqrt{2 \pi n} (\frac {n}{e})^n}{2^n}=lim_{n \to \infty }\sqrt{2 \pi n} \frac{({n})^n}{2^n e^n}$
		- stirling's formula : $n! \approx \sqrt{2 \pi n} (\frac {n}{e})^n$

# $Ω$ (Big Omega Notation)


→ Lower Bound

- for two given functions $f(n), g(n)$

> 💡 $g(n) = \Omega(f(n))g(n)=Ω(f(n)) ⟺ \exists c \in \mathbb{R}, ∃c∈R,$ and $N \in \mathbb{Z^+ \cup {0}}$, s.t. $g(n) \geq cf(n) \forall n \geq N$

- We say that g(n)_g_(_n_) is _ω_ of $f(n)$.
- The Ω puts an asymptotic lower bound on a function.
- Ex:
	- $37\log n+0.1n=\Omega(n)$
	- $n^2 + 10n = \Omega(n^2)$
	- $4(logn)^2 +nlogn+100n=\Omega(nlogn)$
	- $n^{200} +10n=\Omega(n^2)$
	- 

		![9](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/9.png)


# $Θ$ (Big Theta Notation)

- for two given functions f(n)_f_(_n_) , g(n)_g_(_n_)
	- 위에서 누르고
	- 아래에서 누르고

> 💡 $g(n) = \Theta(f(n))g(n)=Θ(f(n)) \iff⟺ g(n) = O(f(n))g(n)=O(f(n)) and g(n) = \Omega (f(n))$

- that is,

	> 💡 $g(n) = \Theta (f(n))g(n)=Θ(f(n)) \iff⟺ \exists c,d \in \mathbb{R}∃c,d∈R and N \in \mathbb{Z^+ \cup {0}}N∈Z+∪0 s.t. g(n) \geq cf(n)g(n)≥cf(n) \forall n \geq N∀n≥N$

- We say that g(n)_g_(_n_) is order of f(n)_f_(_n_).
- The \ThetaΘ puts an asymptotic bound on a function.
- $0.1n + 10n^2 = O(n^{1000}) / O(n^2)$
	- Big O 로 N 자승이다 하며는 tight upper bound를 이야기한다.
- Ex:
	- $37\log n+0.1n=\Theta(n)$
		- $O(n), \Omega(n)$
	- $n^2 + 10n = \Theta(n^2)$
	- $4(logn)^2 +nlogn+100n=\Theta(nlogn)$

> 💡 $\Theta(1)<\Theta(log n)<\Theta(n)<\Theta(n log n)<\Theta(n^2)<\Theta(n^3)<\Theta(n^j)<\Theta(n^k)<\Theta(a^n)<\Theta(b^n)<\Theta(n!)$

- for $k>j>3 , b>a>1$
- O(1) or _O_(_c_) : constant
	- $g(n) = 0.000001 \cdot n$
	- g(n) = 1000000_g_(_n_)=1000000
- Ref. Neapolitan Ex. (pp.42) 19, 24, 26, 28]

# Big O, Omega, and Order

- 

	![10](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/10.png)

- Ref._Ref_. [ Neapolitan Chapter 1.]

## Execution Times for Algorithms with the Given Time Complexities

- n의 k승, 이를 polynomial time (다항 시간)이라고 칭한다.
- n log n, log는 다항식이 아닌데 왜 polynomial이라고 하는가?
	- upperbound : n 자승보다 빠르니까 polynomial time에 들어가게 됨.
- 실제적으로 회사 가서 이 문제를 풀어주는 SW를 해서, 제출한다고 했을 때, n이 커짐에 따라 이러한 효율적인 알고리즘들은 그 피해가 덜한데, 뒤는 피해가 현실적으로 받아들일 수 없을 정도로 커진다. 우리가 이론적으로 구별은 무엇이냐 하면은 polynomial - nonpolynomial alg.를 구분
	- $n^6$은 이론적으로는 polynomial - 안 좋긴 하지만
- exponential, factorial algorithm은 inefficient, polynomial algorithm은 algorithm
	- 현실적으로는 cubic도 빡셈
- 알고리즘 :
	- 이론적인 측면에서 polynomial time 에 쓰이는가
	- 프로그램을 구현해서 돌릴 때, 당연히 cuvic보다는 효유적으로 돌아갈 것이다
- 현실적으루 n이 작을 때에는 그렇게 큰 지장이 없지만, n이 점차 커질 때 log, linear는 잘 버티는 데에 반해 exp, factorial
	- processor가 좋아진다 한들 풀고자 하는 문제가 더 커지기 때문에 시대적 needs라기 보다는 항상 우리 곁의 needs

	![11](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/11.png)

	- logarithmic, linear, n log n, quadratic, cubic << exp << factorial

![12](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/12.png)


# Worst-Case vs. Average-Case Time Complexity

- complexity : time, space complexity
	- 편의상 time complexity를 따짐
- **Expected value** (from Wikipedia)
	- let X_X_ be a random variable with a finite number of finite outcomes $x_1, x_2, ..., x_k$ occuring with probabilities $p_1, p_2, ... p_k$ respectively.
	- the Expectation of X is defined as :
		- $E(X) = \sum_{i=1}^{k }{x_i p_i} = x_1p_1+ x_2 p_2 + ... + x_k p_k$
	- since the sum of all probabilities $p_i$ is 1 (\sum_{i=1}^{k} {p_i}=1∑_i_=1_k__pi_=1) , the expected value is the weighted sum of the x_i_xi_ values, with the p_i_pi_ values being the weights
	- $a_1, a_2, a_3 \rightarrow b_1 , b_2, b_3$
		- input size n에 대해서 모든 가능한 input들의 집합을 S_n
		- 임의의 input $I$
		- $c(I) $ :
		- $p(I):$
- Worst-case complexity :
	- 모든 가능한 인풋중에 최악으로 가장 많은 시간이 걸리는 경우. 가장 시간이 많이 걸리는 경우
	- $T_W (n) = max \{ c(I)| I \in S_n \}$
- Average-case complexity
	- 모든 input에 대해서 일어날 확률 등에 대해 평균을 낸 것.
	- $T_A (n) = \sum_{I \in S_n} p(I) c(I)$
- Problem
	- Find the index of a given value _a_ in a givven array $(a_0, a_1, ...,a _{n-1})$. if _a_ doesn't exist in the array return −1
- Cost for a linear search algorithm
	- let P_i_Pi_ be the probability such that a= a_i_a_=_ai_
	- then the average cost is :

		$g(n) = 1 \cdot P_0 + 2 \cdot P_1 + 3 \cdot P_2 + ...+ n \cdot P_{n-1} + n (1 - \sum_{k=0}^{n-1} P_k)$


		$= \sum_{k=0}^{n-1} (k+1)P_k + n (1 - \sum_{k=0}^{n-1} P_k)=∑k=0n−1(k+1)Pk+n(1−∑k=0n−1Pk)$

		- Ex.1. $n = 10^9$, $P_0 + P_1 + ...+ P_{10^3} = 1$ so $g(n)=O(1)$
		- Ex.2. $n = 10^9$, $P_0 + P_1 + ...+ P_{\frac n {100} }= 1$, so g(n) = O(n)_g_(_n_)=_O_(_n_)

> 💡 배우게 될 내용, 중요

- [중요] **참고: Quick sort 알고리즘 →**
	- Worst-case : $O(n^2)$
	- Average-Case : $O(n \log n)$

# Reviews


## Summation

- Sums of powers
	- $\sum_{i=1}^{n} i = \frac {n(n+1)} {2}$
	- $\sum_{i=1}^{n} i^2 = \frac {n(n+1)(2n+1)} {6}$
	- $\sum_{i=1}^{n} i^3 = (\frac {n(n+1)} {2})^2$
	- $\sum_{i=1}^{n} i^4 = \frac {n(n+1)(2n+1)(3n^2+3n-1)} {30}$
	- $\sum_{i=1}^{n} i^s = \frac {(n+1)^{s+1}} {s+1} + \sum_{k=1}^{s} \frac {B_k} {s-k+1} {s \choose k} (n+1)^{s-k+1}$
		- $B_k$ is the $k^{th}$ Bernoulli Number.
	- $\sum_{i=1}^{n} i^{-s} = \prod_{p prime} \frac {1} {1 - p^{-s}} = \zeta(s)$
		- $\zeta_k$ is the Riemann zeta function
- Growth rates
	- $\sum_{i=1}^{n} i^c \in \Theta(n^{c+1})$
		- for real c greater than 1−1
	- $\sum_{i=1}^{n} \frac 1 i \in \Theta(log n)$
	- $\sum_{i=1}^{n} c^i \in \Theta( n \cdot log(n)^{c+1})$
		- for real c_c_ greater than 11
	- $\sum_{i=1}^{n} log(i)^c \in \Theta(n \cdot log(n)^{c})$ for nonnegative real $c$
	- $
	
	\sum_{i=1}^{n} log(i)^c \cdot i^d \in \Theta(n^{d+1} \cdot log(n)^{c})$ for nonnegative real $c, d$
	- $\sum_{i=1}^{n} log(i)^c \cdot i^d \cdot b^i \in \Theta(n^{d} \cdot log(n)^{c} \cdot b^n) $for nonnegative real $b>1, c, db>1,c,d$
- **Read** [_Summation_](http://en.wikipedia.org/wiki/Summation), [_Mathematical Series_](http://en.wikipedia.org/wiki/List_of_mathematical_series.)

## Run Time Analysis


What is the worst-case time complexity of each loop?

- 어디가 dominate한가 : SW를 개발 할 때 최적화를 해 주어야 함. program이 도는 것을 보면 어디가 bottleneck이 되어 비효율적인가
- (1) Matrix Addition : $O(n^2)$

	```c
	for (i = 0; i < N; i++)
	  for (j = 0; j < N; j++)
	    a[i][j] = b[i][j] + c[i][j];
	```

- (2)$O(n^2)$
	- `x+= i+j`가 i번 수행되고, $\Sigma_{i=1}^N i = \frac{N(N+1)}{2} = \frac {N^2} 2 + \frac N 2$

	```c
	x = 0;
	for (i = 1; i <= N; i++)
	  for (j = 1; j <= i; j++)
	    x += i + j;
	```

- (3) $O(n^2)$

	```c
	for (i = 1; i <= N; i++)
	        if (i % 2 == 0)
	            a[i] = 1;
	        else
	            a[i] = -1;
	    // N^2
	for (i = 1; i <= N; i++)
	        for (j = 1; j <= N; j++)
	            a[i][j] = i + j;
	    // N^2
	```

- (4) $O(n^3)$
	- $\frac N 2 \cdot N$ . $\frac N 2 N^2$ → $n^3$이 dominate

	```c
	for (i = 1; i <= N; i++)
	    {
	        if (i % 2)
	        {
	            for (j = 1; j <= N; j++)
	                a[i][j] = i + j;
	        }
	        else
	        {
	            for (j = 1; j <= N; j++)
	            {
	                a[i][j] = 0;
	                for (k = 1; k <= N; k++)
	                    a[i][j] += k;
	            }
	        }
	    }
	```

- (5)
	- $\Sigma_{i=1}^N \Sigma_{j=1}^i j= O(N^3)$

	```c
	x = 0;
	for (i = 1; i <= N; i++)
	  for (j = 1; j <= i; j++)
		//What if this is i*i?
			for (k = 1; k <= j; k++)
			x += i + j + k;
	```

- (6)$ \rightarrow O(N^4)$
	- $\Sigma_{i=1}^N \Sigma_{j=1}^{i^2} \Sigma_{k=1}^j k= O(N^4)$

	```c
	x = 0;
	for (i = 1; i<=N;i++)
	  for (j = 1; j <= i*i; j++)
	    if (j % i == 0) //j가 i의 배수이면
	      for (k = 1; k <= j; k++)
	        x++;
	```

	- n 이 작냐, 크냐에 따라서 10만이냐 100만이냐 할 때 어떤 속도로 나빠질 것인가? 얼마나 잘 유지될 것인가?
	- 항상 j가 1부터 i^2까지 도는데, j%i ==0 일 때 까지만 돈다 : j가 i의 배수인 경우
	- j가 i의 배수일 때 :
		- $i = 1,2, ... n$
		- $j = 1, i, 2i, ..., i^2$
		- $\Sigma_{i=1}^{N}{(1 + i + ... + i^2)}$
		- 

What is the worst-case time complexity of each loop?

- (1)

	```c
	// n = 2^k for some positive
	    // integer k
	    for (i = 1; i < N; i++)
	    {
	        j = n;
	        while (j >= 1)
	        {
	            // some O(1) computation
	            j = j / 2;
	        }
	    }
	```

- (2)

	```c
	// n = 2^k for some positive
	    // integer k
	    i = n;
	    while (i >= 1)
	    {
	        j = i;
	        while (j <= n)
	        {
	            // some O(1) computation
	            j = 2 * j;
	        }
	        i = i / 2;
	    }
	```

- (3) Could this be faster?

	```c
	//
	    float x[n][n + 1];
	    for (i = 0; i <= n - 2; i++)
	        for (j = i + 1; j <= n - 1; j++)
	            for (k = i; k <= n; k++)
	                x[j][k] = x[j][k] – x[i][k] * x[j][i] / x[i][i];
	```

- (4) Magic square : Could this be faster?

	```c
	// n: odd integer
	    for (i = 0; i < n; i++)
	        for (j = 0; j < n; j++)
	            s[i][j] = 0;
	    s[0][(n - 1) / 2] = 1;
	    j = (n - 1) / 2;
	    for (key = 2; key <= n * n; key++)
	    {
	        k = (i) ? (i - 1) : (n - 1);
	        l = (j) ? (j - 1) : (n - 1);
	        if (s[k][l])
	            i = (i + 1) % n;
	        else
	        {
	            i = k;
	            j = l;
	        }
	        s[i][j] = key;
	    }
	```

- (5)$ O(\log n)$

	```c
	// compute x^n (n >= 0)
	    m = n;
	    power = 1;
	    z = x;
	    while (m > 0)
	    {
	        while (!(m % 2))
	        {
	            m /= 2;
	            z *= z;
	        }
	        m--;
	        power *= z;
	    }
	```

- time complexity. : $c_0 + c_1 n + c_2 n^2 = O(n^2)$

	```c
			x = x + 1;
	    for (i = 1; i <= n; i++)
	        y = y + 2;
	    for (i = n; i >= 1; i--)
	        for (j = n; j >= 1; j--)
	            z = z + 1;
	```

- time complexity. : $c( ⌊{log_2 n}⌋+1) \cdot n^2 = O(n^2)$

	```c
	c = 0;// n > 0
	for (i = 1; i <= n; i++)
	  for (j = 1; j <= n; j++)
	    for (k = 1; k <= n; k = k*2)
	      c += 2;
	```

	- for k=1;k≤n;k=k*2
	- floor : 3.7 → 3, ceil : 3.7 → 4
	- $n=15 \rightarrow \lfloor log_2 15 \rfloor = \lfloor 3.*** \rfloor = 3$
	- 1 2 4 8 15
- time complexity. : $??= O( \sqrt n)$

	```c
			i = 1;
	    j = 1;
	    m = 0; // n > 0
	    while (j <= n)
	    {
	        i++;
	        j = j + i;
	        m = m + 2;
	    }
	```


# [ALG] 1.4. MSS (1)


> 최대 부분 수열의 합 Maximum Subsequence Sum

- 어떠한 알고리즘을 설계하느냐에 따라서 어떻게 결과가 달라지는지.

# Maximum Subsequence Sum (MSS) Problem

- _Ref_. **[M. Weiss,** **Data Structure and Algorithm Analysis in C (2nd ed.), Pearson, 1997. 2.4.3]**
	- Given $N$ (possiblly negative) $A_0, A_1, ..., A_{N-1} \in \mathbb{Z}$
	- find the maximum value of $\sum_{k=i}^{j} {A_k }$ for $0 \leq i \leq j \leq N-1$
	- for convenience, the max subseuqence sum is 0 if all the integers 're <0
- Example
	- $(-2, 11, -4, 13, -5, -2). → MSS = 20$
	- $(a_1, ..., a_6)$ : 수열의 모든 가능한 부분수열 중 $\Sigma_{k=i}^j {A_k}$ 임의의 i에서 시작해서 j에서 끝나는 것들을 더했는데 그런 것들 중 제일 큰 것을 찾아라.
		- sequence element들은 정수일 때 subsequence를 찾는다.: subsequence의 합이 최대가 되게하는 수열.
		- 주어진 수열의 정수가 모두 음수이면 mss=0 간주
	- length = 0, 1, 2로 시작하거나,,
		- 아무리 빨라도 $n^2$보다 빠르게는 못 만들겠다는 생각이 들 수 있다.
			- n개 data 중 가장 작은 것 뽑기 : 한 번씩 sequential search를 해야 하므로 n
			- n^2개의 경우는 n^2가 될 것 같은데,
			- divide n conquer : $O(N \log N), $ DP : $O(n)$
		- → $n + (n-1) + (n-2) + ... + 2 + 1 = \frac {n(n+1)}{2} = O(n^2)$
	- 이 안에 모든 존재하는 subsequence 중에 합을 가장 크게 하는 subsequence를 찾아라.

		![13](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/13.png)

- Maximum Subarray Problem
- Maximum Positive Sum Subarray Problem
- Max. Sum Subsequence versus Max. Subsequence Sum

# Alg of Maximum Subsequence Sum

- 길이 n인 정수의 수열 $a_0, a_1, ..., a_{n-1}$이 입력으로 주어져 있다.
- 여기서 부분 수열 $[i, j]$ 라는 것은 $ a_i, a_{i+1}, a_{i+2}..., , a_{j}$를 말한다.
- a의 최대값을 구하는 문제이다.
	- (이때 주어진 수열의 정수가 모두 음수이면 최대 부분 수열의 합은 0 이라고 간주한다)
	- 예를 들어 다음과 같은 수열이 주어졌을 때, $+ 31, −41, +59, +26, −53, +58, +97, −93, −23, +84$  최대 부분 수열은 [2,6]이며 수열의 합은 187 이 된다.

	![14](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/14.png)

- 이 문제는 최대 부분 수열의 합을 구하는 것이지만, 앞으로 소개할 알고리즘을 조금만 수정하면 최대 부분 수열도 쉽게 구할 수 있다.
	- empty string : letter char=0, NULL String
	- substring
	- string
	- length

	> Algorithm1 : 모든 경우의 수 찾기 - $O(N^3) $


	> Algorithm2 : Sum구할 때 중복 조금 피하기 - $O(N^2)$ 

	- simple counting
		- $O(n^2)$ : SS 여러 개가 있는데 한 번씩 모두 보자.
		- $i$에서 시작하는 것들 1, 2, … 개를 모두 보자 : $n^2$개를 모두 본 것.

	![15](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/15.png)


	> Algorithm3 : Divide n Conquer - $O(N \log N)$ 

	- Divide n Conquer
		- 경우를 나눈다 : MSS subsequence가 존재하는데 이를 반으로 잘라서 분명히 어딘가 존재한다 → 왼쪽 혹은 오른쪽, 아니면 양다리 걸치던지.
		- 왼쪽 중 제일 큰 것 찾고, 오른쪽 존재 중 제일 큰 것 ㅈ찾고, 양다리 중 제일 큰 것 찾고.
		- 그중에 제일 큰 것을 찾았는데 O(Nlog N)걸리더라

	![16](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/16.png)


	> Algorithm4 : Dynamic Programming - $O(N)$

	- DP
		- 각각의 i에 대해서 i번째 끝나는 애들
		- 분명히 maximum sum을 해주는 것은 하나 존재하는데 첫 번째 원서로 끝나던지, … 몇 번째쯤에 끝날 것이다. n번째에서 끝나는 것들 각각을 보자는 의미이다.

	![17](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/17.png)

	- algorithm을 만들 때, 효율을 신경쓰지 말고 하나하나 따져본다. 고등학교 때 순열과 조합으로 경우의 수를 따지는데, 전공에서 매우 중요한 요소이다.
		- 문제를 어떻게 접근해 해결함에 따라 n^2개가 있음에도 불구하고 훨씬 더 효율적으로 문제를 해결할 수 있다.
	- 이런 수열이 주어졌을 때 분명 답은 존재한다:
	- alg 1, 2
		- 모두 -라면 정답은 0이고 :
			- -임을 확인하는 비용은 linear time
		- 양수가 하나라도 있으면 찾아보아야 한다

	0에서 시작하는거 다 따져봐서 합이 제일 큰 것 찾고, —- 1, 2 번째에서 시작하는거 다 따져봐서 합이 제일 큰 것 찾고. n-1 까지 중 제일 작은 거 


# MSS 1 - simple counting

- Strategy
	- Enumerate all possibilities one at a time.
	- No efficiency is considered, resulting in a lot of unnecessary computation!

		```c
		Maxsum = 0 for (i = 0; i < n; i++)
		{
		    for (j = i; j < n; j++)
		    {
		        Thissum = sum(A [i:j])
		            Maxsum = max(Thissum, Maxsum)
		    }
		}
		```

	- 모든 경우의 수를 하나하나 모두 따져보는 방법.

		```c
		int MaxSubsequenceSum(const int A[], int N)
		{
		    int ThisSum, MaxSum, i, j, k;
		    // i = 리스트 왼쪽 끝 인덱스, j = 리스트 오른쪽 끝 인덱스,
		    //  ThisSum = 고려 대상 부분 리스트 합, MaxSum = 문제 최종결론
		    MaxSum = 0;
		    for (i = 0; i < N; i++)
		        for (j = i; j < N; j++)
		        {
		            ThisSum = 0;
		            for (k = i; k <= j; k++)
		                ThisSum += A[k];
		            if (ThisSum > MaxSum)
		                MaxSum = ThisSum;
		        }
		    return MaxSum;
		}
		```

	- Is this for-loop OK for you?
	- Time Complexity : $O(N^3)$
		- 𝑖와 관련된 반복문은 𝑛n번, 𝑗와 관련된 반복문은 최대 𝑛번, Thissum을 구할 때 최대 𝑛개의 요소를 계산해야 하기에
		- $\sum_{i=0}^{N-1} \sum_{j=i}^{N-1} \sum_{k=i}^{j} 1 = \frac{N^3 + 3N^2 + 2N}{6}$

			```c
			for (i = 0; i < N; i++)
			```

		- $\sum_{j=i}^{N-1}\ (j-i+1) = \frac{(N-i+1)(N-i)}{2}$

			```c
			// for (i = 0; i < N; i++)
			    for (j = i; j < N; j++)
			   // {
			     //   ThisSum = 0;
			       // for (k = i; k <= j; k++)
			```

		- $\sum_{k=i}^{j} 1 = j-i+1$

			```c
			//for (i = 0; i < N; i++)
			//    for (j = i; j < N; j++)
			//    {
			//        ThisSum = 0;
			        for (k = i; k <= j; k++)
			```

	- 0번째에서 시작해서 Max 구한 것,…, n번째에서 시작하여 Max 구한 것.
	- 크게 바깥쪽에서 for loop이 돌면서 i번째부터 시작해서 i 하나, 두개, 세개, … 모든 것을 다 봐서 i번째에서 시작하는 것 중 가장 큰 것을 찾으려 한다.
	- for loop은 i, i+1, i - i+2, i - n-1… 까지 더해 봄.

	> 💡 [개선점] 이전에 더한것에다가 하나만 더 더하면 되지 않을까


![18](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/18.png)


# MSS 2

- Strategy

	> 💡 이전 스택에서 하나만 더 더하면 되는 것 아닌가?

	- Get rid of the inefficiency in the innermost for-loop. Algorithm 1보다 중복을 줄이는 방법
	- for loop가 하나 사라지게 됨.

		```c
		Maxsum = 0 for (i = 0; i < n; i++)
		{
		    for (j = i; j < n; j++)
		    {
		        Thissum = sum(A [i:j])
		            Maxsum = max(Thissum, Maxsum)
		    }
		}
		```

		- Notice that $\sum_{k=i}^{j } {A_k} = A_j + \sum_{k=i}^{j-1} {A_k}$

		```c
		int MaxSubsequenceSum(const int A[], int N)
		{
		    int ThisSum, MaxSum, i, j;
		    MaxSum = 0;
		    for (i = 0; i < N; i++)
		    {
		        ThisSum = 0;
		        for (j = i; j < N; j++)
		        {
		            ThisSum += A[j];
		            if (ThisSum > MaxSum)
		                MaxSum = ThisSum;
		        }
		    }
		    return MaxSum;
		```

	- time complexity : $O(N^3) \rightarrow O(N^2)$

![19](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/19.png)


# MSS  3 : Divide n Conquer


![20](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/20.png)

- Divide and Conquer
	- 경우의 수를 따짐 : 전부 다 음수가 아니라면 분명히 하나 존재한다.
	- 0번 원소부터 n-1 원소까지 있는데 이를 반으로 1/2로 뚝 자르고,
		- 홀수 개수면 정확히 나눠지지 않음, 짝수 개수이면 정확히 둘로 나누어짐
	- left segment에 있던지 right segment에 있던지 양다리 걸치던지. 의 세가지 케이스 중 제일 큰 값을 찾는다.
	- → 이 전체에서 mss를 찾고자 하는데, 일단 왼쪽하고 오른쪽 각각에서 MSS 찾고
- 원래 플고자 하는 문제와 problem size만 다르다
	- 전체 subsequence를 반으로 잘라 left- right segment 각각 영역에서의 MSS를  찾고자 함.
	- 결국 같은 문제 : problem size 만 1/2, 1/2된 케이스
	- 전체 문제 사이즈 2인것을 1, 1로 divide하여 각각의 segment에서 conquer하여 찾는다
	- with - ‘Recursion’
		- 자기 자신을 부른다 :
		- 항상 recursive call을 할 때는 problem size를 작게 하여 부른다.
		- 양다리 걸치는 것 중 제일 큰 것을 찾아 비교
		- 각 동네에서 MSS를 찾아 그 중 제일 큰 것을 돌린다.
- Why is Log N
	- [사진]
	- Binary Tree에서 각 depth별로 $1 , 2, 4, 8, ...$
	- $O (N \log N)$
- Strategy
	- Use the **Divide-and-Conquer** strategy.
		- 원 문제를 작은 문제로 나눠 풀고, 그 결과를 합쳐 문제를 해결하는 알고리즘
	- The maximum subsequence sum can be in one of three places.
	- 교재에 탑재되어 있지만 그렇게 좋은 코드가 아닌듯 하다 !
	- leaf node 1개까지 내려왔을 경우 양수이면 그대로 return하고 음수이면 0
	- Divide and Conquer
		- center를 찾아 중앙 지점 : 똑같은 문제 [index left-right] 를 풀지만 [left-center], [center-right]로 원래 풀고자 하는 문제를 divide해서 푼다.
		- recursion의 묘미 : 막아주는 부분 (else return 0)이 있어야 top-down으로 내려갈 수 있는 divide and conquer

		```c
		int MaxSubSum(const int A[], int Left, int Right)
		{
		    int MaxLeftSum, MaxRightSum;
		    int MaxLeftBorderSum, MaxRightBorderSum;
		    int LeftBorderSum, RightBorderSum;
		    int Center, i;
		    //종료조건if (Left == Right){
		    if (A[Left] > 0)
		        return A[Left];
		    else
		        return 0;
		}
		// divide n conquer
		Center = (Left + Right) / 2;
		//왼쪽, 오른쪽, 중간
		MaxLeftSum = MaxSubSum(A, Left, Center);
		MaxRightSum = MaxSubSum(A, Center + 1, Right);
		
		MaxLeftBorderSum = 0;
		LeftBorderSum = 0;
		// 1. left ending 끝으로 하는 mss
		for (i = Center; i >= Left; i--)
		{
		    LeftBorderSum += A[i];
		    if (LeftBorderSum > MaxLeftBorderSum)
		        MaxLeftBorderSum = LeftBorderSum;
		}
		MaxRightBorderSum = 0;
		RightBorderSum = 0;
		
		// 2. right ending 시작으로 하는 mss
		for (i = Center; i <= Right; i++)
		{
		    RightBorderSum += A[i];
		    if (RightBorderSum > MaxRightBorderSum)
		        MaxRightBorderSum = RightBorderSum;
		}
		return Max3(MaxLeftSum, MaxRightSum, MaxLeftBorderSum + MaxRightBorderSum);
		// MaxLeftSum - left segment의 sum
		// MaxRighttSum - right segment의 sum
		// MaxLeftBorderSum - 가운데에서 left로 가는 것들 중 최대
		}
		int MaxSubsequenceSum(const int A[], int N)
		{
		    return MaxSubSum(A, 0, N - 1);
		}
		```

		- // 음수가 되는 경우이더라도 양다리가 걸칠 수 있도록 설계할 것
			- 

		![21](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/21.png)


		```c
		int MaxSubSum(const int A[], int Left, int Right)
		{
		    int MaxLeftSum, MaxRightSum;
		    int MaxLeftBorderSum, MaxRightBorderSum;
		    int LeftBorderSum, RightBorderSum;
		    int Center, i;
		    //종료조건if (Left == Right){
		    if (A[Left] > 0)
		        return A[Left];
		    else
		        return 0;
		}
		// divide n conquer
		Center = (Left + Right) / 2;
		//왼쪽, 오른쪽, 중간
		MaxLeftSum = MaxSubSum(A, Left, Center);
		MaxRightSum = MaxSubSum(A, Center + 1, Right);
		
		// 음수가 되는 경우이더라도 양다리가 걸칠 수 있도록 설계할 것
		
		MaxLeftBorderSum = A[i];
		LeftBorderSum = 0;
		// 1. left ending 끝으로 하는 mss
		for (i = Center; i >= Left; i--)
		{
		    LeftBorderSum += A[i];
		    if (LeftBorderSum > MaxLeftBorderSum)
		        MaxLeftBorderSum = LeftBorderSum;
		}
		
		MaxRightBorderSum = 0;
		RightBorderSum = 0;
		
		// 2. right ending 시작으로 하는 mss
		for (i = Center; i <= Right; i++)
		{
		    RightBorderSum += A[i];
		    if (RightBorderSum > MaxRightBorderSum)
		        MaxRightBorderSum = RightBorderSum;
		}
		return Max3(MaxLeftSum, MaxRightSum, MaxLeftBorderSum + MaxRightBorderSum);
		// MaxLeftSum - left segment의 sum
		// MaxRighttSum - right segment의 sum
		// MaxLeftBorderSum - 가운데에서 left로 가는 것들 중 최대
		}
		int MaxSubsequenceSum(const int A[], int N)
		{
		    return MaxSubSum(A, 0, N - 1);
		}
		```

- cost : $T(n) = 2T(\frac n 2) + cn$, $T(1) = d$
- why O(N log N)_O_(_NlogN_) ?
	- $T(n) = 2T(\frac n 2) + cn$
	- $T(1) = d$

		$= 2 [ 2T(\frac n {2^2}) + c \frac n 2 ] + cn$


		$= 2^2 T [ \frac n {2^2}] + 2cn$


		$= 2^3 T [ \frac n {2^3}] + 3cn =...$


		$= 2^i T [ \frac n {2^i}] + icn$


		$= 2^{\log_2 n} T(1) + \log_2 n \cdot cn$


		$=nT(1) + \log_2 n \cdot cn$


		$= O(n) + O(n \log_2 n) = O(n \log_2 n)$


# MSS  4; Kadane’s algorithm

- i번째 원소로 끝나는 가장 합이 큰 subsequence가 얘라면, 다른 나머지를 분리했을 때 i-1로 끝나는 subsequence이다.

	![22](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/22.png)

	- 아니다 → 모순 증명 : 고등학교 proof by contradiction 귀류법으로
	- i원소로 끝나는 합이 제일 큰 subsequence는 얘인데, 합이 제일 큰 subsequence가 되어야 한다.
	- 합이 제일 큰 부분을 찾는데, 나보다 하나 앞애 있는 i-1까지의 sequence로 바뀐다.
		- recursion이랑 비슷 : 같은 문제룰 푸는데 문제 크기가 달라짐. 이를 어떤 형식으로 해결하느냐에 따라서 달라지게 됨.
	- i번째 끝나는 subsequence중에 여러가지 있을 수 있는데, 그 중 가장 합이 큰 것을 Bi라고 할 때
		- $B[i]$ : the sum of the maximum subsequence that ends at index $i$
		- $B[i] = \max \{ B[i-1] + A[i], 0\}$
- Strategy
	- Use the Dynamic Programming strategy.
	- subsequence sum<0인 경우, 논리적으로 최대값이 될 수 없음에 착안한 전략
	- 만약에 sum이 음수라도 무방하고 1개 이상의 원소로 구성된 Subsequence (subarray)를 구하는 문제라면?

		```c
		int MaxSubsequenceSum(const int A[], int N){
		    int ThisSum, MaxSum, i;
		
		    ThisSum = 0; // j번째 원소르 끝나는 것 중 합이 제일 큰 것
				MaxSum = 0; // 지금까지의 원소르 끝나는 것 중 합이 제일 큰 것
		    for(i = 0; i < N; i++){
		        ThisSum += A[i];
		        if(ThisSum > MaxSum)
		            MaxSum = ThisSum;
		        else if(ThisSum < 0)
		            ThisSum = 0;
					// if (ThisSum<0) ThisSum=0; 
					// else if (ThisSum>MaxSum) MaxSum = ThisSum;
		    }
		    return MaxSum;
		}
		```

	- thissum : j 번째 돌 때 j-1번째 원소로 끝나는 것 중 제일 합이 큰 것.
		- `ThisSum += A[j]`
	- ThisSum → 0, j번째 원소로 끝나는 것 중 가장 큰 거보다 크면 바꿔치기하고..
	- 최소한 모든 원소를 한 번씩은 봐야 하기 때문에 linear보다 더 빠른 alg는 없다.
	- Time Complexity : $O(n)$
		- for i, iteration n times, and $ O(1$) for 1 calculation
	- C Implementation
		- Maximum sum rectangle in a 2D matrix (DP-27) by GeeksforGeeks

			```c
			int kadane(int *arr, int *start, int *finish, int n)
			{
			    int sum = 0, maxSum = INT_MIN;
			
			    *finish = -1;
			    int local_start = 0;
			    for (int i = 0; i < n; ++i)
			    {
			        sum += arr[i];
			        if (sum < 0)
			        {
			            sum = 0;
			            local_start = i + 1;
			        }
			        else if (sum > maxSum)
			        {
			            maxSum = sum;
			            *start = local_start;
			            *finish = i;
			        }
			    }
			    if (*finish != -1)
			        return maxSum;
			// at least one non-negative number.
			
			// When all numbers in the array are negative
			    maxSum = arr[0];
			    *start = *finish = 0;
			    for (int i = 1; i < n; i++)
			    {
			        if (arr[i] > maxSum)
			        {
			            maxSum = arr[i];
			            *start = *finish = i;
			        }
			    }
			// Empty subsequence를 허용하면 0을 리턴 (원래 문제)
			// Empty subsequence를 허용하지 않으면 음수 중 가장 큰 원소를 리턴
					return maxSum;
			}
			
			
			
			```


### So, why do we bother with the time complexity?


# [ALG] 1.5. Maximum Sum Subrectangle in 2D Array (1)


# Maximum Sum Subrectangle in 2D Array


= max sum submatrix


2차원 array가 있을 때 합을 제일 최대로 만들게 하는 subrectangle을 찾아라.

- empty subrectangle 허용
	- 모두 음수면 0
- empty subrectangle 비허용
	- 모두 음수라면 절댓값이 제일 작은 것 선택
- 행이 m개, 열이 n개 :
	- n자승개가 존재한다고 햇는데, order로 subrectangle이 몇 개 존재할 것인가?
	- 
- Problem
	- Given an mxn array of integers, find a subrectangle with the largest sum. (In this problem, we assume that a subrectangle is **any contiguous sub-array of size 1x1 or greater** located within the whole array.)
- Note
	- What is the input size of this problem?
		- $(m, n)$
		- If $m = n→n$
		- problem size를 (n,n) 할수도 있고
	- How many subrectangles are there in an mxn array?
	- For the case of $m = n$,
		- Design an $O(n^6)$ algorithm.
		- Design an $O(n^5)$ algorithm.
		- Design an $O(n^4)$ algorithm.
		- Design an _O_(_n_3) algorithm.

			O(n^3)

- 각각의 $(i,j,k,l)$에 의해 하나가 정의 :
- How many subrectangles are there in an mxn array?
	- [1D case] for an m * n_m_∗_n_ rectangle,

		$\sum_{i=0}^{n-1} \sum_{j=i}^{n-1} \sum_{k=0}^{m-1} \sum_{l=k}^{m-1} 1$


		$= (\sum_{k=0}^{m-1} \sum_{l=k}^{m-1} 1)(\sum_{i=0}^{n-1} \sum_{j=i}^{n-1} 1)$


		$= { \sum_{k=0}^{m-1}(m-k)}{\sum_{i=0}^{n-1}{(n-i)}}$


		$= \frac {m(m+1)} {2} \frac {n(n+1)} {2} = O(m^2 n^2) = O(n^4)$ if $m=n$


## A Naïve Approach

- For each subrectangle, find its sum.
- [가정] $n=m$

	$\sum_{i=0}^{n-1} \sum_{j=i}^{n-1} \sum_{k=0}^{m-1} \sum_{l=k}^{m-1} (j-i+1)(l-k+1) = \sum_{i=0}^{n-1} \sum_{j=i}^{n-1} {(j-i+1)} \sum_{k=0}^{m-1} \sum_{l=k}^{m-1} {(l-k+1)}$


	let $A =\sum_{i=0}^{n-1} \sum_{j=i}^{n-1} {(j-i+1)}$


	$A = 1*n + 2*(n-1) +3(n-2) + ... + n*1A=1∗n+2∗(n−1)+3(n−2)+...+n∗1 = \sum_{i=1}^{n} {i(n-i+1)} = n \sum_{i=1}^n i - \sum_{i=1}^n i^2 + \sum_{i=1}^n i = \frac{1}{6} n^3$

	- so $O(\frac{1}{36} n^6 )$
undefined- Time Complexity : $O(n^6)$
- inefficient algorithm

## MSS : Summed Area Table

- memory 자체도 resource이기 때문에 항상 많이 쓰는 것이 좋은 건 아니지만, summed area table이라는 memory를 하나 써서 문제를 풀게 된다.
- Table construction: $O(n^2)$
	- 각 원소는 대응되는 영역의 합이 각 대응되는 위치에 지정한다 : 순서대로 쭉 원소들을 훑으며 계산한다. 이를 계산하면 내가 훑어야 하는 원소의 개수가 n^2만큼 있다. 각각의 원소는 상수 시간에 계산되어야 한다.
	- n^2에 대해서 계산하려고 하는데, 각각을 상수 시간 안에 계산하여야 한다.
	- 
- Sum comparisons:$O(n^4)$
- Time Complexity : $O(n^4)$

	![23](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/23.png)

	- preprocess를 통해 table의 내용을 채울 것이다.
	- $(i,j,k,l)$에 해당하는 것이 $n^4$개만큼 나오는데, 그 영역에 대한 합을 계산해서 사각형의 합 중 제일 큰 것을 선택하면 됨.
	- $S(i,j,k,l) = T(l,j) - T(k-1, j) + T(k, j-1) + T (k-1. i-1)$
		- constant time : 각 사각형에 대한 계산
		- 살펴봐야 할 것들은 $n^4$개 존재하니까.
- 문제 : 지금까지는 time complexity를 따졌지만 문제는 space complexity
	- input data : @n^2 만큼의 자리를 차지함.
		- → 모바일 SW를 개발한다 : input data 말고도 성능이 낮거나 memory size 작거나 access 느린 cpu에 대해서는 안 좋을수 있다. 시스템 부담이 되는 상황 발생 가능
	- time complexity : n인 문제를 푸는 데 걸리는 시간
	- space complexity : 문제 푸는데 걸리는 메모리
		- 문제 사이즈 n에 대해서 $n^4$
	- 

### Maximum Sum Subrectangle: Kadane Algo.-Based


> 💡 n^3에 해보자

- 분명히 MSS인 rectangle이 존재하는데, i에서 시작해서 j로 끝남 : 그러면 이제 어떤 식으로 문제를 바라볼 것이냐 : $0 \leq i \leq j \leq n-1$이 가능한 pair
	- i번째 열에서 j번째로 끝나는 모든 가능한 rectangle을 살펴보자.
	- 가능한 조건을 만족하는 i,j → n^2만큼 존재함.
	- 모든 가능한 i, j에 대해서 i행에서 시작하고 j열에서 끝나는 mss를 찾아보자.
	- column이 i, j번째에 끝나는 : 합이 제일 큰 것을 찾자. 라고 접근
	- 만약
		- temp array를 만들어서 임의의 주어진 i, j에 대해서 첫 번재 원소는 1 행, 2번째 원소는 2행, … 을 모두 저장해 놓은 값을 저장해 두었다고 하자.
		- 주어진 i, j에 대해서 행 열이 i에서 시작해서 j로 끝나는 subrectangle 중 제일 큰 것은 어떻게 찾을 수 있을까.
		- 1차원 sequence에서 합을 제일 크게 하는 mss를 찾으면 된다.

	> 💡 모든 가능한 (i,j) pair에 대해서 볼 것이다.  
	> 바깥에서 for loop이 돌 때 저만큼 존재한다.  
	> 각 행에 있는 것들을 다 더해두면 (temp) → i열에서 시작해서 j로 끝나는 가능한 rectangle을 만든다. 합이 제일 큰 것은 temp가 있기 때문에, linear time에 합이 제일 큰 subsequence를 찾으면 바로 k행부터 l행까지 정의되는 사각형이 Maximum sum이 되더라.

	- 다시 이양기하지만, 조건 만족하는 쌍이 i,j개 존재하니까 linear time에 계산할 수 있으면
	- 각각을 n에 대해서 계산하면 $n^3$이 나온다.
- Idea
	- ref. [geeksforgeeks](https://www.geeksforgeeks.org/maximum-sum-rectangle-in-a-2d-matrix-dp-27/)
	- MSS(2D)의 해당 열은 어디이건 i에서 j까지 임.
	- 가능한 모든 (i, j) 조합에 대하여 MSS(1D)를 Kadane 알고리즘을 사용하여 찾음.
	- 그렇게 하기 위하여, ...

		![24](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/24.png)

- 어떤 식으로 구현할지 보여야 구현할 것인데 자꾸 경험을 통해서 몸에 배면 구구단 외우듯이 간다.
- C Implementation
	- left, right : $n^2$만큼 돈다

		| 1  | 2  | -1 | -4 | -20 |
		| -- | -- | -- | -- | --- |
		| -8 | -3 | 4  | 2  | 1   |
		| 3  | 8  | 10 | 1  | 3   |
		| -4 | -1 | 1  | 7  | -6  |

undefined
	```c
	// Program to find maximum sum subarray
	// in a given 2D array
	#include <stdio.h>
	#include <iostream>
	#include <string.h>
	using namespace std;
	#define INT_MAX 2147483647
	#define INT_MIN 2147483648
	#define ROW 4
	#define COL 5
	
	// Implementation of Kadane's algorithm for
	// 1D array. The function returns the maximum
	// sum and stores starting and ending indexes
	// of the maximum sum subarray at addresses
	// pointed by start and finish pointers
	// respectively.
	int kadane(int *arr, int *start, int *finish, int n)
	{
	    // initialize sum, maxSum and
	    int sum = 0, maxSum = INT_MIN, i;
	
	    // Just some initial value to check
	    // for all negative values case
	    *finish = -1;
	
	    // local variableint
	    local_start = 0;
	
	    for (i = 0; i < n; ++i)
	    {
	        sum += arr[i];
	        if (sum < 0)
	        {
	            sum = 0;
	            local_start = i + 1;
	        }
	        else if (sum > maxSum)
	        {
	            maxSum = sum;
	            *start = local_start;
	            *finish = i;
	        }
	    }
	
	    // There is at-least one
	    // non-negative number
	    if (*finish != -1)
	        return maxSum;
	
	    // Special Case: When all numbers
	    // in arr[] are negative
	    maxSum = arr[0];
	    *start = *finish = 0;
	
	    // Find the maximum element in array
	    for (i = 1; i < n; i++)
	    {
	        if (arr[i] > maxSum)
	        {
	            maxSum = arr[i];
	            *start = *finish = i;
	        }
	    }
	    return maxSum;
	}
	
	// The main function that finds
	// maximum sum rectangle in M[][]
	void findMaxSum(int M[][COL])
	{
	    // Variables to store the final output
	    int maxSum = INT_MIN,
	        finalLeft,
	        finalRight,
	        finalTop,
	        finalBottom;
	
	    int left, right, i;
	    int temp[ROW], sum, start, finish;
	
	    // Set the left column
	    for (left = 0; left < COL; ++left)
	    {
	        // Initialize all elements of temp as 0
	        memset(temp, 0, sizeof(temp));
	
	        // Set the right column for the left
	        // column set by outer loop
	        for (right = left; right < COL; ++right)
	        {
	
	            // Calculate sum between current left
	            // and right for every row 'i'
	            for (i = 0; i < ROW; ++i)
	                temp[i] += M[i][right];
	
	            // Find the maximum sum subarray in temp[].
	            // The kadane() function also sets values
	            // of start and finish. So 'sum' is sum of
	            // rectangle between (start, left) and
	            // (finish, right) which is the maximum sum
	            // with boundary columns strictly as left
	            // and right.
	            sum = kadane(temp, &start, &finish, ROW);
	
	            // Compare sum with maximum sum so far.
	            // If sum is more, then update maxSum and// other output values
	            if (sum > maxSum)
	            {
	                maxSum = sum;
	                finalLeft = left;
	                finalRight = right;
	                finalTop = start;
	                finalBottom = finish;
	            }
	        }
	    }
	
	    // Print final values
	    cout << "(Top, Left) ("
	         << finalTop << ", "
	         << finalLeft
	         << ")" << endl;
	    cout << "(Bottom, Right) ("
	         << finalBottom << ", "
	         << finalRight << ")" << endl;
	    cout << "Max sum is: " << maxSum << endl;
	}
	
	// Driver Codeint
	main()
	{
	    int M[ROW][COL];
	
	    // Function call
	    findMaxSum(M);
	
	    return 0;
	}
	```

- 결과는 아래와 같다.

	```c
	(Top, Left) (1, 1)
	(Bottom, Right) (3, 3)
	Max sum is: 29
	```


## Mathematical Induction & Proof of Correctness

- Proof by Induction

	![25](/assets/img/2022-09-02-[ALG]-1.-Introduction.md/25.png)

- Proof of Correctness : MSS (1D)

	```c
	int ThisSum = MaxSum = 0;
	
	for (j = 0; j < N; j++)
	{
	    ThisSum += A[j];
	
	    if (ThisSum > MaxSum)
	        MaxSum = ThisSum;
	    else if (ThisSum < 0)
	        ThisSum = 0;
	}
	
	return MaxSum;
	```

	- P(j) : for-loop가 j번 수행한 직후에 ThisSum 변수는 ( )값을, MaxSum 변수는 ( )값을 가지고 있다.
