---
layout: post
date: 2022-09-28
title: "[ALG] 4.1. DP - Concepts"
tags: [Algorithm, ]
categories: [Notes, ]
use_math: true
---

- divide and conquer: top - down
	- 효율적이기도 하나 매우 비효율적이 되기도 함
	- splitted된 사례들이 서로 관련 없는 문제를 풀때 잘 통함
- dynamic programming : bottom -up
	- 아래에서 위로 올라가며 효율을 추구하자는 방식
- NOW
	- Divide-and-Conquer Method
	- **Dynamic Programming Method**
	- Greedy Method
	- Backtracking Method
	- Local Search Method
	- Branch-and-Bound Method
	- Etc.
- From [Wikipedia](https://en.wikipedia.org/wiki/Dynamic_programming): Dynamic programming is both a
	- <u>mathematical optimization method and a computer programming method.</u>
- A complicated problem is **broken down into simpler sub-problems in a recursive manner**.
- Overlapping subproblems
	- A problem is broken down into subproblems which are reused several times or a recursive algorithm for the problem solves the same subproblem over and over rather than always generating new subproblems.
- Optimal substructure
	- A solution to a given optimization problem can be constructed efficiently from optimal solutions of its subproblems.
- When applicable, the method <u>**takes far less time than other methods**</u> that don't take advantage of the subproblem overlap **like the divide- and-conquer technique**.

→ 문제 몇개 풀어보고, 이 고상한 말들이 별 것 아닌 자연스러운 원리임을 체득하자!


# [ALG] 4.2. Approaches for Recursive Formulation (1)


Two Approaches for Recursive Formulation

- Top Down Approach
- Bototm up Approach

## 4.2.1. Top Down Approach

- $T(i,j) = T(i-1,j) + T(i, j-1) + C \cdot (2i + j), i,j \geq 1$
- $T(i,0) = T(0,j) = 1$ for $i,j≥0$
- recursive하게 똑같이 문제 두개를 푼다 : 빨간 것 하나, 녹색 하나. 그리고 그 결과를 combine하여 원래 문제를 푼다. 문제가 겹치는게 보인다.
	- divide and conquer : 상당히 많이 overlap됨을 확인할 수 있다.
	- 
undefined- Easily becomes exponential!

	![0](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/0.png)


recursive function call : 내려갔다 올라갔다 depth first search하다가 하염없이 돌아오는 것을 의미한다.


## 4.2.2. Bottom Up Approach

- $T(i,j) = T(i-1,j) + T(i, j-1) + C \cdot (2i + j), i,j≥1$
- $T(i,0) = T(0,j) = 1$ for $i,j \geq 0$
- Often much more efficient!

	![1](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/1.png)

- 그러나 bottom up은 Top Down과 대비하여 쭉 쭉 쭉 한 줄로 내려가며 잘 풀리게 된다.
	- bottom up으로 올라오면서, 그리고 모든 경우에 divide n conquer에 비효율적이고 dp가 효율적인건 아니다.
- Bottom up vs. Top down 공통: 둘다 어떤 문제가 재귀적인, recursive한 형태로 문제가 풀리게 된다.
	- 작게 똑같이 풀어서 합치자 : recursion 한 solution이 나타나게 된다
	- solution을 만드는데 재귀적으로 나타난다.
- 몇 개 안 되는 것을 풀면 되는데, 똑같은것을 반복적으로 보나?
	- 이를 계산하는 프로그램: 이를 풀기 위해서 필요한 것은 왼쪽 하부, 오른쪽 하부
	- 거꾸로 생각해보면 : 왼쪽 아래 + 오른쪽 아래 활용해서 그 위 가운데 노드를 구할 수 있다. (아래에서 위로)
- 아무리 부정하려고 하더라도 인정할 수밖에 없는 원리.

## 4.2.3. Examples


### 4.2.3.1. [ex1] World Series Odds

- Problem
	- Dodgers and Yankees are playing the World Series in which either team needs to win _n_ games first.
	- Suppose that each team has a $50%$ % chance of winning any game.
	- Let _P_(_i_,_j_) be the probability that if Dodgers needs _i_ games to win, and Yankees needs _j_ games, Dodgers will eventually win the Series.
		- i번을 더 이겨야 다저스는 우승할 수 있구 양키스는 세번 이기는데 이 때 다져스기 우승할 확률은
		?
	- Ex: $P(2, 3) = \frac {11}{16}$야
		- 키스는 두번, 다저스는 3번
	- Compute $P(i,j) 0≤i,j≤n ∀n$

		![2](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/2.png)

		- 임의의 n에 대해서 확률을 계산하라 : 그림을 보고, recursion 구조가 떠오르는가?
			- 문제 사이즈 $( i,j) = (i-1,j) + (i, j-1)$
			- 0.5, 0.5 : dodgers이거나 yankees인데 dodgers가 이기면 $(i-1,j)$
			- 조건부 확률 : $P(i,j) = 0.5 P(i-1,j) + 0.5P(i, j-1)$ rl기본적인수식

![3](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/3.png)


### 4.2.3.2. [Worse] A Divide-and-Conquer Approach

- Recursive formulation
	- $P(i,j) =1 if i=0,j>0$
	- $P(i,j) =0 if i=0,j=0$
	- $P(i,j)= \frac{P(i-1,j)+P(i,j-1)}{2}=2P(i−1,j)+P(i,j−1)$

		if $i>0, j>0$

- overlap subproblem : overlapping하지 않으면서 size가 줄었던 dnc와 달리 overlapping된다. 굉장히 안 좋은 상황. 그래서 이를 recursive fn call 함수를 짜서 $P(100,100), P(50,50)$짜보라
	- → 사실 돌려지지도 않는다. 시간이 너무 걸려 컴퓨터가 죽어버린다.
- If we solve this recurrence relation in the divide-and-conquer way,
	- Let _T_(_n_) be the maximum time taken by a call to _P_(_i_),where _i_+_j_ =_n_.
	- Then we can prove that _T_(_n_) is exponential!
	- $T(1)=1, T(n) = 2T(n-1) + c \rightarrow O(2^n)$
- What is the problem of this approach?

![4](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/4.png)


### 4.3.2.3. [Better] A Dynamic Programming Approach

- 핵심 개념 Table
	- 1D, 2D, 3D
- $T(4,4) $: table setup 후 이를 채워나가서 (fill)
	- 단ㄷ순하게 생각하면 2 중 for loop 활용하여 진행한다.
	- 0,0은 양쪽 다 우승한 것이기에 고려할 필요 없다.
- 한칸 여펴 왼쪽에 있는 애와, 한칸 아래 밑쪽에 잇는 애를 통해 계싼할 수 있다.
- $P(i,j) = 1 $ if $i=0, j>0$
- $P(i,j) = 0$ if $i>0, j=0$
- $P(i,j) = \frac{P(i-1,j) + P(i, j-1)}{2}$ if $i>0, j>0$
- fill 하는 방식
	- 좌→우 (밑에서 위로): 가능
	- 밑→위 (좌에서 위로) : 가능
	- 기존의 플로우는 대각선 우상향이기때문에 가능!
	- 기교를 부리고 싶으면 ㄹor loop을 복잡하게 해서 구현할 순 있다.
		- 그러나 단순하면서 잘 작동하는것이 더 중요하다.
- $T(n,n) = O(n^2)$d임을 바로 확인해야한다.
	- table 원소가 가로 n, 세로 n일 때
	- n+1, n+1개가 있고
	- 상수시간이므로 시간 복잡도는 n자승이 된다. → 시간복잡도는
- Instead of computing the same repeatedly, fill in a table as suggested below:
	- 

		![5](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/5.png)

- Time Complexity
	- For input size $(m, n)$, computing $P(m, n)$ takes $O(mn)$-time.
	- By far better than the Divide-and-Conquer approach.

		![6](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/6.png)

undefined
![7](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/7.png)

- DP 문제를 푸는데 이러한 recursive structure가 존재하고, 이를 divide and conquer 로 top down으로 풀어야 한다면 overlapping subproblem의 문제가발생한다.
	- 상당한 양의 문제가 있다 : divide and conquer로 가지 말고 dp로 가는건 어떨까?
	- 어떤 문제를 subproblem을 통해 recursive하게 풀려 하는데 문제가 어떻게 풀리더라: dnc가 아니라 bottom up 방식으로 풀도록 생각하고
	- table을 1차-3ㅏ차원으로 구성하고, 초기화하고, 일반화된 공식으로부터 fill 하느 방식을 알아 원소를 채워 나간다
- 각각의 subproblem
	- 문제를 각각 한 번씩만 푼다 : bottom up 방식으로 table을 채워나가서 목적을 달성하는 것 : DP의 시작과 끝이다
	- overlapping substructure 등 복잡한 거 생각할 필요 없이, 이것이 전부!

# [ALG] 4.3. Concepts of Dynamic Programming (1)


# Dynamic Programming


> Top-down → Bottom-up

- When the **divide-and-conquer** approach produces an **exponential algorithm** where **the same sub-problems are solved iteratively**,
	- Take the recursive relation from the divide-and-conquer algorithm, and
	- replace **the recursive calls with table lookups** by recording a value in a table entry instead of returning it.
- master theorem과도 연계
	- overlapping 나쁜거 (a>c)
- Three elements to consider in designing a dynamic programming algorithm
	- Recursive relation
		- Optimal substructure
	- Table setup
	- Table fill order
	- $B(i,j)=B(i-1,j-1) + B(i-1,j)$ if $0<j<i$
	- $B(i,j)=1$ if $j=0$ or $j=i$
- [Neapolitan] DP Procedure
	- input case에 대해 solution을 계산하는 recursive property 세우기
	- 작은 input case부터 먼저 해결하는 bottom up을 통한 전체 Input에 대해 Solution 구축

# Application of DP


# 4.3.1. The Manhattan Tourist Problem

- Courtesy of [Jones & Pevzner 6.3]

	![8](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/8.png)

- Problem:
	- Given two street corners in the borough of Manhattan in New York City, find the path between them with the maximum number of attractions, that is, a path of maximum overall weight.
	- Assume that a tourist may <u>**move either to east or to south only**</u>

> 🏝️ 어떻게 하면 많은 관광지를을 최대로 방문할 수 있겠는가?

- (1) A <u>brute force</u> approach
	- 모든 경로 다 따져보기 : 몇개 나올까? 각각 n, m칸이라고 할때(세로, 가로)
		- 이를 따져보면 : $2^n, 2^m, n!, m!$이 나온다 → 모든 경우를 따지면 exponential, factorial time이 나오기에 풀 수 없다.
	- Search among all paths in the grid for the longest path!
	- n이 조금 커도 알 수 있다.
- (2) A greedy approach
	- 다음 강의 주제
- <u>A formal description of this problem</u>
	- Given a weighted graph (grid) _G_ of size (_n_,_m_) with two distinguished vertices, a source (0,0) and a sink (_n_,_m_), <u>**find a longest path between them**</u> in its weighted graph. (0,0)
		- find ‘a’ : 하나만 찾기
	- graph : vertex-vertex 간 관계를 나타내주는 edge로 edge는 directional/nondirectional일 수 있다
		- undirected / directed edge : arc
			- directed graph : digraph
			- edge에 방향성이 있는가 없는가는 vertex 관계를 나타낸다.
			- directed : ex. a는 b를 좋아하고, b는 c를 좋아하고,, : 방향성 존재
	- weighted : 각 edge에 값이 잇는경우
	- → weighted digraph
- 원래 문제에 대해서 두 개의 subproblem 으로 푸는 것

	![9](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/9.png)

- 경로는 달라도 길이는 같은 longest path는 존재할 수 있다.
	- 둘중에 하나로 출발하거나 도착함
		- 1) 아래로 출발하거나
		- 2) 오른쪽으로 출발하거나
	- 알고리즘을 어떻게 생각해냈을까에 대하여 접근해보자!
	- 둘 중에 하나인데, 오른쪽에서 오는 것이 최종 longest path라면
		- (4,4) 까지 이르는 방법에는 (4,3) - (3,4)이므로 각각에 대한 ㅣongest path를 구해보면 된다
		- → divide and conquer로 풀이
- 생각의 흐름
	- divide and conquer를 썼을 때, overlapping subproblem을 활용햇기에 worse 됨
	- recursive top-down 이면 똑같은 식으로 (4,2) 혹은 (3,3)의 형태의 longest path를 찾아야 한다
	- → 심각해지는 overlapping problem
- solution : DP (bottom up)
	- 0,0 에서 4,3 에 이르기까지의 문제를 한 번씩만 풀고 밑에서부터 위로 올라가자.
- divide and conquer의 overlapping subproblem으로 상당히 매칭
	- top down: overlapping subproblem → 상당히 많이 겹치는 포인트
	- bottom up : 서로 서로를 계싼하며 결괏값 산출
- An example grid of size (4,4)
	- GRID : 특수한 형태의 격자처럼 생긴 graph

		![10](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/10.png)

- shortest path가 아닌 longest path 문제
	- DP 문제와 어떤 관계가 있을까?
	- recursive solution이 보이는가?
- A possible selection determined by a greedy approach

![11](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/11.png)

- <u>**Basic idea**</u>
	- How can you use the solutions of smaller problems to build a solution of a problem?
		- 

			![12](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/12.png)

	- $s_{i,j} = \max\{s_{i-1,j}+ w_{i,j} , \}$
	- directed edge = arc
	- 위에서 i,j로 내려올 때의 weight,
	- 왼쪽에서 i,j로 올 때의 weight
	- A given optimization problem can be constructed efficiently from optimal solutions of its subproblems.
		- 최적화 문제
			- 리턴값을 최대로 해 주는 solution을 찾아라,
			- solution을 극대화해주는/극소화해주는 solution을 찾아라
		- 최적화가 아니나 DP를 활용
			- 다저스 문제 : 최적화 문제가 아니지만 DP를 사용함
		- 최적의 solution을 얻기 위해 문제를 풀어감
		- → optimal substructure

![13](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/13.png)

- Optimal substructure : $S_{n,m} =?$
	1. $i,j \geq 1$
		- $S_{i,j} = \max(S_{i-1,j}+W({(i-1,j)},{(i,j)}), S_{i,j-1}+W({(i,j-1)},{(i,j)}))$
	2. $i=0, j=1,2,...,n$
		- $S_{0,j} = S_{0,j-1}+W({(0,j-1)},{(0,j)})$
	3. $j=0, i=1,2,...,m$
		- $S_{i,0} = S_{i-1,0}+W({(i-1,0)},{(i,0)})$
	4. $i=j=0$
		- $S_{0,0} = 0$

> 💡 Induction, Base step에 관한 것들도 정확하게 기술해주어야 함.

- Table setup and fill
	- 맨 위, 맨 옆 line에서는 unique한 path cost가 나옴
	- divide and conquer = top down → 큰 문제부터 작은 문제로 (merge sort : 큰 것을 반으로 반으로 쪼개가며 merge) ↔ DP
	- 정보의 흐름 : 내 값을 계산하기 위해서 j 인덱스가 작은 것, i 인덱스가 작은 것을 계산해두면 됨
	- 각각의 Node가 subproblem을 나타낸다.
	- 어떻게 각각의 원소를 채울 것인가: 한 원소 값을 계산하기 위해서는 나보다 왼쪽에 있는 애와 위쪽에 잇는 애의 값을 알고 있어야 함.
	- 

		![14](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/14.png)

- Pseudocode
	- 

		![15](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/15.png)


		```c
		MANHATTANTOURIST(w,w,n,m)
		
		
		```

- Given a (_n_,_m_) grid, what is the time complexity T(n, m)?
undefined- So far, we have found the **cost of the longest path** from source to each vertex in the grid.
- 길이가 34인 longest path는 어떻게 출력할 수 있을까?
	- 조금만 더 노력하면 longest path 길이 + 대각선 까지의 거리를 출력할 수 있는 정보를 추출해낼수 있음
	- 알고리즘에서 정보를 더 끄집어 낼 수 있는 부분 :
		- $S_{i,j} = \max(S_{i-1,j}+W({(i-1,j)},{(i,j)}), S_{i,j-1}+W({(i,j-1)},{(i,j)}))$
			- 둘 중에 큰 것을 선택하는 statement
			- 왼쩍 것이 더 크다면 → 위에서부터 내려온 것
			- 오른쪽 것이 더 크다면 → 왼쪽에서 내려온 것
		- optimal substructure와 연관
			- 나의 optimal solution은 나보다 작은 subproblem들의 optimal solution을 통해 출력
			- 거기서로부터 수식이 나타난다:이를 program화하여 각 table 원소를 계산할 때 선택됨에 따라서 각 또 다른 table 하나를 기록해두면 +1, -1 등을 줄줄 쫓아가면 됨
		- recursion : 굉장히 compact하게 표현해주는 좋은 방식
			- 물론 overlapping subproblem의 경우 개념을 compact하게 햐해주지만 조심하면서 써야지 안 복잡해짐
		- 최종 것까지 가는 길 : (-1→ 1) + (이전 노드까지의 최단거리)
- Time complexity
	- Input size (m,n)
	- Time Complexity : O(mn)
		- 각 노드마다 계산하는데 걸리는 상수시간
		- node의 복잡도가 시간 복잡도
	- Space Complexity : O(mn)
		- 50.50으로 divide and conquer하면, 과연 실행의 끝을 볼 수 있을가 모르겠다!
- Then, how can you print out the **actual optimal path** from source to sink?
undefined
		![16](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/16.png)


# 4.3.2. Chained Matrix Multiplication


[Neapolitan 3.4] dp의 대표적인 문제

- In general, to multiply an _a_ x _b_ matrix with a _b_ x _c_ matrix using the standard method, it is necessary to do _abc_ elementary multiplications.
	- a*b, b*c 행렬을 곱하면 a*c 행렬이 나오는데 가장 단순하게 연산하면 a*b*c만큼의 곱셈이 수행
	- matrix multplication
		- $A_1 \times A_2 \times ... \times A_n$
			- 1번, 2번 곱셈, … n-1번 곱 : 누구를 제일 마지막에 연산할것인가?
			- 최소비용으로 곱한 다음 곱하는 데 활용된 비용을 더하면 결과 비용
				- 3번 이전 + 3번 이후
			- 이 중에 제일 작은 것을 선택한다.
			- matrix multiplication에는 결합법칙 성립 : 어떤 것을 먼저 곱해도 상관 없으나 비용이 달라짐
		- $A_i = d_{i-1} \times d_i$

![17](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/17.png)

- Problem
	- Determine the minimum number of elementary multiplications, needed to multiply $n$ matrices where $A_i \in R^{d_{i-1} \times d_i}$
	- optimal substructure를 통해 최적의 solution을 도출
- Examples:  $A_1 (20 \times 2) \cdot A_2 (2 \times 30) \cdot A_3 (30 \times 12) \cdot A_4 (12 \times 8)$해
	- 행렬의 곱셈에서는 결합법칙이 성립한다
		- $(a+b)+c = a+(b+c) $: a+b+c
		- binary operation (이진 연산 : 두 피연산자에 대해 연산하면 한 연ㅅ나)
		- 빼기는 결합법칙 성립 x → 어떤 빼기를 먼저 하느냐에 따라 결과 달라짐
		- 행렬의 곱셈의 교환법칙 성립 X, 결합법칙은 성립 O
	- 제일 먼저 곱하는 게 몇 번이냐고 생각할 수 있고,
	- 최소 횟수를 구하는 것이니 minimization problem : 최소 횟수의 곱셈 → 최적화 문제로 대입
	- 어떤 친구를 제일 먼저 곱할 것인가 생각할 수 있다.
	- 곱셈을 곱하는 순서 : 곱셈을 순서대로 나열한 것과 동일
		- 최적의 해 : 곱셈의 개수가 작은 것으로 선택할 것이다.
	- $A_1: 20 \times 2, A_2: 2 \times 30$
	- $A_1(A_2(A_3 A_4)) : 30 \times 12 \times 8 + 2 \times 30 \times 8 + 20 \times 2 \times 8 = 3,680$ multiplications
		- 3, 2, 1
	- $(A_1 A_2)(A_3 A_4) : = 8,880$ multiplications
	- $A_1((A_2 A_3 )A_4) : = 1,232$ <u>multiplications</u>
		- 2, 3, 1
	- $((A_1 A_2)A_3 )A_4 := 10,320$ multiplications
	- $(A_1(A_2 A_3 ))A_4 := 3,120$ multiplications
	- The order of multiplication is very important!
		- $(a \times b) \times c = a \times (b \times c)$
	- $O((n-1)!)=O(n!)$ : 프로그램 열심히 설계하는 데에는 얼마 안 걸릴지 모르지만 n factorial만큼 기다려야 결과가 나온다
		- 곱셈을 할 수 있는게 $(n-1)!$의 경우의 수인데 이들을 어떻게 분류해서 exponential보다 무시무시한 factorial을 polynomial time으로 변환하여 어떻게 잘 분리해 판단할것인가?
		- 분류 방법 : Ex. $A_1 \cdot A_2 \cdot A_3 \cdot A_4 \cdot A_5 \cdot A_6 \cdot A_7$
			- (1) 어떤 애를 가장 먼저 나눌 것인가
				- 
			- (2) 어떤 애를 가장 나중에 나누어 곱할 것인가
				- 최소 곱셈을 하고자 하는데, 만일 제일 마지막에 곱하는 것이라면 앞의 것을 다 곱하고 뒤의 것을 나중에 곱해야 하는데 우리의 목적이 최소 곱셉을 원하는 것이므로 각각의 partition에 대해서 최소 횟수로 곱하게 됨
					- → 자연스로운 recursive 사고방식
				- $(A_1 \cdot A_2 \cdot A_3) \cdot (A_4 \cdot A_5 \cdot A_6 \cdot A_7) = A_{13} \cdot A_{37}$

	![18](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/18.png)

- Divide and Conquer, Dynamic Programmping
	- problem → <u>**recursive structure**</u> → optimal substructure → dynamic programming
	- ~를 최대로 해 주는 최적화 문제에 많이 쓰이는 DP
	- 최적의 구조 이런 것들이 있을 경우, 경우에 따라서는 divide and conquer가 유리할 수 있다
	- exponential alg이 나오기 때문에 dp를 한 번 써보자.
- Divide and Conquer → Top-down
- Dynamic Programming → Bottom-up
- Recursive : 나랑 같이 생겼는데, 나보다 사이즉 작은 문제를 해결한다.
	- 작은 문제부터 풀 것인가 (Bottom Up), 큰 문제부터 내려올 것인가 (Top Down)
- directed graph라고 봤을 때, 최소 횟수로 건너가는 문제
	- n에서 1까지의 shortest path 찾는 문제
	- 분명 shortest path는 존재하는데, 6→ 5,3,2
	- $P_n = \min\{ P_{n-1}, P_{\frac n 2}, P_{\frac n 3}\}+1$
		- if $n\%2 ==0$ → $P_{\frac n 2}$
		- if $n\%3 ==0$ → $P_{\frac n 3}$
	- 나보다 사이즈 작은 것들의 최적의 solution을 찾느다 : optimal substructure
	- 문제 사이자 즉은 거부터 값을 계산해본다. 이러한 P_n의 식을 통해서 계산
		- n을 k로 대치하여 생각

	![19](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/19.png)


# 4.3.3. Dynamic programming approach

- Definition
	- $M(i, j)$
		- the minimum number of multiplications needed to multiply $A_i$ through $A_j (i \leq j )$
		- 랑 같이 행렬 i부터 j까지 최소 횟수를 곱할 때, 그 때 필요한 곱셈의 홋수를 M(i,j)로 정의
- Optimal subtructure
	- 지금까지 본 것이랑 조금 다른 형태의 substructure가 나오더라
	- 최적화 문제의 경우 dp 느낑인데 그렇지 않을수도 있더라 : 경우의 수를 따지고 recursive한 개념이 들어가는 경우
		- i, j가 같으면 곱셈이 필요 없다.
		- i<j이면
			- i에서 k까지 최소횟수 → $M(i,k) = d_{i-1} \cdot d_k $
			- k에서 j까지 최소횟수 → $M(k+1, j) = d_k \cdot d_j$
	- → $M(1,n) = ?$

![20](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/20.png)

- Example: $M(2, 7)$
	- $M(2,7) = \min_{2\leq k \leq 6}{\{ M(2,k) + M(k+1,7)+d_1 d_k d_7}\}$

		![21](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/21.png)

	- dp : 작은 문제부터 풀어감
	- table을 만들어서 동일한 subproblem을 딱 한 번만 푸는 것: table을 어떻게 만들 것인가?
	- 우리가 필요한 것 : 세로 i, 가로 j → 필요한 subproblem을 다 모아두면, M(i,j)이다. $M(i,j) i\leq j$
		- 대각선 우하향으로 내려갈수록 작은 문제이다
		- table을 어떻게 훑으며 작은 문제에서 큰 문제로 변환할 것인가?
		- optimal substructure의 구조가 어떻게 table을 쫓아갈 것인가 고민해보는 문제
- M(2,7)
	- 가로로 시작하면 안 됨 : 가로의 M(2,2,) M(2,3) .. 은 다 되지만 세로의 것들은 한번에 못 채우기 때문
	- 세로로 시작하면 될까? : 세로로 순서대로 이 식을 활용해 계싼할 것인데 왼쪽의 것들과 밑의 쪽의 것들이 계산될 것 같다.
- Table fill order

	![22](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/22.png)


	```c
	for (i = 1; i <= n; i++)
			M[i][i] = 0;
	for (g = 1; g <= n - 1; g++){
			for (i = 1; i <= n - g; i++) {
							j = i + g;
							M[i][j] = BIG_NUM;
							for (k = i; k <= j - 1; k++){
	        		        if ((tmp = M[i][k] + M[k + 1][j] +
	                           d[i - 1] * d[k] * d[j]) < M[i][j]) {
	            				        M[i][j] = tmp;
	                    				P[i][j] = k;
			                }
	            }
	        }
	    }
	```

- Time complexity
	- $n + (n-1) \cdot 1 + (n-2) \cdot 2 + ... + (n-(n-1))\cdot (n-1)n+(n−1)⋅1+(n−2)⋅2+...+(n−(n−1))⋅(n−1)\\= n + \Sigma_{g=1}^{n-1}{(n-g)g} \\= O(n^3)$
undefined- Chained matrix multiplication problem
	- $O(n^3)$ by Godbole (1973)
	- $O(n^2)$ by Yao (1972)
	- $O(n \log n)$ by Hu and Shing (1982, 1984)
- Printing optimal order
	- $M(2,7) = \min_{2\leq k \leq 6}{\{ M(2,k) + M(k+1,7)+d_1 d_k d_7}\}$

	```c
	void order(int i, int j)
	{
	    int k;
	    if (i == j)
	        printf(“A_ % d”, i);
	    else
	    {
	        k = P[i][j];
	        printf("(");
	        order(i, k);
	        order(k + 1, j);
	        printf(")");
	    }
	}
	```


	![23](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/23.png)


→ $O(n)$ time


![24](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/24.png)


# [ALG] 4.4. Principles of Dynamic Programming (1)


# 4.4. Principles of Dynamic Programming

- $C_{ij}$ = the cost of the shortest path from (0,0) to (_i_,_j_)
	- 각 directed edge에서 shortest path를 찾아라
	- Then $C_{ij} = min \{C_{i-1,j} + w_{i-1, j} ^{s},C_{i-1,j-1} + w_{i-1, j-1} ^{se},C_{i,j-1} + w_{i, j-1} ^{e} \}$rkr

		![25](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/25.png)

- Recursive formulation
- Optimal substructure
	- 나의 최적의 해를 구하기 위해서 나보다 크기가 작은 subproblem들의 optimal solution을 통해서 최적의 해를 구하는 과정을 가능케해주는 구조
- Overlapping subproblems
	- 굉장히 안 좋은 형태로 풀이될수 있음(무한 loop)
	- subproblem의 개수는 각 node만큼 있으니가
- Bottom-up approach
	- 작은 문제부터 풀자
- Table Fill-up
	- 각 node에 대한 최단 거리를 table에 계산해두고 기록되어 있는 것들에 대해 채워가며 수행하자

## 4.4.1. Optimal Substructure [(wiki)](https://en.wikipedia.org/wiki/Optimal_substructure)


쭉 읽고 아는척 해봐자 !! (dynamic programming)

- 문제에 대해서 DP를 적용하기 위해서는 optimal substructure를 찾아내야 한다
	- 나의 optimal solution을 찾는 구조 : recursion이 들어가 있음
	- recursion을 divide and conquer로 top-down으로 하던가, bottom-up으로 올라가던가
- Dynamic programming algorithms are often **used for optimization**.
	- ~를 최대로 해 주는 optimal problem을 푸는 데에 주로 쓰인다
- A problem is said to have **optimal substructure**
	- if a solution to a given optimization problem can be constructed efficiently from optimal solutions of its subproblems.
- Consequently, the first step towards devising a dynamic programming solution is to check whether the problem exhibits such optimal substructure.
	- Such optimal substructures are **usually described by means of recursion**.
	- $C_{ij} = min \{C_{i-1,j} + w_{i-1, j} ^{s},C_{i-1,j-1} + w_{i-1, j-1} ^{se},C_{i,j-1} + w_{i, j-1} ^{e} \}$

## 4.4.2. Overlapping Subproblems [(wiki)](https://en.wikipedia.org/wiki/Overlapping_subproblems)


> 💡 큰 문제를 푸는데, recursive하게 작은 문제를 계속해서 top down식으로 풀 때 같은 식으로 반복적으로 나오는 경우 : overlapping problem 문제가 심각할 때

- To solve a problem, we often need to **solve different parts of the problem (subproblems), then combine the solutions of the subproblems to reach an overall solution**.
- A problem is said to have <u>**overlapping subproblems**</u> if
	- the problem can be broken down into subproblems which are reused several times or
	- a recursive algorithm for the problem solves the same subproblem over and over rather than always generating new subproblems.
	- 한 번만 풀고 이를 table에 집어넣어 점차 size를 키워 문제 원래 것을 푸는 방식
	- $C_{ij} = min \{C_{i-1,j} + w_{i-1, j} ^{s},C_{i-1,j-1} + w_{i-1, j-1} ^{se},C_{i,j-1} + w_{i, j-1} ^{e} \}$
- The dynamic programming approach seeks to **solve each subproblem only once**, thus reducing the number of computations:
	- (i) once the solution to a given subproblem has been computed, it is stored or "**memoized**":
	- (ii) the next time the same solution is needed, it is simply **looked up**.
- This approach is **especially useful when the number of repeating subproblems grows exponentially** as a function of the size of the input.
- **If a problem can be solved by combining optimal solutions to non-overlapping sub-problems**, the strategy is called "divide-and- conquer" instead. This is why merge sort and quick sort are not classified as dynamic programming problems.
	- overlapping subproblem이 거의 발생하지 않음 : merge sort, selection
		- merge sort : 큰 문제를 반으로 반으로 나누고 해당 subproblem들이 overlap되지 않음
		- selection : 큰 부분들에 대해서 부분을 선택하고 한 부분은 다른 것과 겹치지 않음
		- quick sort : pivot을 제외한 나머지 부분들은 overlap하지 않음
			- 굳이 DP로도 갈 필요 없이 divide and conquer로 쉬이 풀리게 됨
			- 이분법적 사고 지양 :
				- <u>위에서 아래로 내려가는데 subproblem이 반복적으로 나타나는 경우 exponentially 한 시간 복잡도가 걸릴 수 있기에 이럴 때는 dp를 써라</u>
- $C_{ij} = min \{C_{i-1,j} + w_{i-1, j} ^{s},C_{i-1,j-1} + w_{i-1, j-1} ^{se},C_{i,j-1} + w_{i, j-1} ^{e} \}$

## 4.4.3. The Checkerboard Problem


[Courtesy of Wikipedia]

- 체스판
- Restrictions
	- A checker can start at any square on the first row (i= 1).
	- It can move only diagonally left forward, diagonally right forward, or straight forward.
		- 내려가는 방법 제한 : 남서쪽으로만 내려가던가, 남쪽으로 내려가던가, 남동쪽으로 내려가던가
	- It must pay the cost _c_[i] when visiting the (i, j)-position.
- Cost table $c [i] [j]$

	![26](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/26.png)

- Problem
	- Given a checkerboard with $n \times n$ squares, and a cost function `c[i][j]`, **find the minimum-cost path from the first row to the last row**.
	- 내가 어떤 지점을 방문했을 때에는 화살표가 지나간 cost를 summation한 것
		- 가장 길이가 짧은 적은 비용의 path 찾는것이 목표
	- recursive 구조, optimal substructure을 찾아보자
		- 가장 작게 해주는 minimization problem
- Ex. 1 까지의 최소비용 [4][4]
	- 최소 비용의 path는 셋 중 하나 : 남쪽으로 오거나, 남서쪽에서 오거나, 남동쪽에서 오거나
	- 내가 최소 비용을 찾고자 하는 것이니 각각에 이르기까지의 최소 비용 path의 총 비용의 계산
		- 각각 상황에 대한 총 비용을 안다면, ㅐptimal substructure로 어떻게 나타낼까?
		- minimum cost path에 대한 총 비용은 올 수 있는건 세 가지 경로인데 가장 작은 것에다가 이를 선택해서
		- 나를 방문할 때 1을 더하면 되더라
	- 
- Optimal substructure
	- $q(i,j) = \min \{ q(i-1, j-1), q(i-1,j), q(i-1, j+1)\} + c(i,j)$
		- $c(i,j)$ :
		- table size는 어떻게 할 것인가 : 각 subproblem마다 원소에 대응되게 table을 잡으면 됨
		- 총 비용에 해당하는 q(i,j) : (i,j) 까지 위치 까지의 총 비용 계산
			- min (남쪽으로 내려오는, 남동쪽, 남서쪽)
	- $q(i,j) = c(i,j)$
		- i=1일 때 : 자기 자신 - 맨 윗줄
			- 그 지점까지 오는 최소 비용은 자기 자신 cost만 지불하면 됨
	- dummy
		- 수학적으로 무한대 값을 설정해 둠
		- 이런식으로 설정하고 programming하면 각 끝에 값들에 선택되지 않음
		- 사실 수학적으로 쓸 때 필요는 없지만, dummy값을 넣어주는 게 편리
			- boundary 체크해도 상관은 없지만 각 왼쪽, 오른쪽 끝에서 boundary로부터 오는 값들을 계산하기 곤란함
		- 각 cost table 위치마다 subproblem이 하나 생성됨
	- table setup & table fill
		- 어떤식으로 loop을 돌면서 할까
	- (if) 수직으로 for loop를 돌겠다고 하면
		- 남동, 남서로 내려오는 것들에 대해서는 고려하지 못하므로 안됨
	- (if) 수평으로 for loop를 돌겠다고 하면
		- 특정 원소를 계산하고자 할 때, 나에게 필요한 정보가 미리 준비되어 있음
		- q table이 계산되더라
	- q table이 계산된 후 할일 : 아무데서나 시작해도 상관없으니 위에서 내려와서 최소비용으로 가게하자
		- 아무데서나 시작해서 가는 minimum cost path
		- → 8
	- q table을 계싼함과 동시에 p table 계산
		- 어느 방향에서 왔는지
			- 가장 작은 것을 선택하는 경우
		- -1 : 북서에서 내려온거다 / 0 : 북에서 내려온거다 / 1 : 북동에서 내려온거다
	- optimal substructure를 찾은 다음 table을 setup하고 base step 정보를 가지고 initialize하고 table을 적당한 순서로 정리한 다음 적정한 최단 optimal path를 찾는다.
	- 이후 table fill을 할 때 table을 하나 잡아서 어떤 node를 선택해서 내려왔음을 표기함 (p table)
	- → shortest path를 알게 된다.

	![27](/assets/img/2022-09-28-[ALG]-4.1.-DP---Concepts.md/27.png)

	- 나보다 사이즈가 작은 최적의 솔루션들로 표현하는 것
	- code
		- c/c++는 recursion이 좋은 tool이지만 보편적으로 굉장히 개념을 compact하게 잘 표현해준다.

	```c
	#include <stdio.h>
	#define N 5
	#define INFTY 100000
	int c[N + 1][N + 2] = {-1, -1, -1, -1, -1, -1, -1, -1, 7, 3, 5, 6, 1, -1, -1, 2, 6, 7, 0, 2, -1, -1, 3, 5, 7, 8, 2, -1, -1, 7, 6, 1, 1, 4, -1, -1, 6, 7, 4, 7, 8, -1};
	int p[N + 1][N + 2], q[N + 1][N + 2];
	
	int min3(int a, int b, int c)
	{
	    ...
	}
	
	void ComputeCBCosts(int n)
	{
	    int i, j, min;
	    for (i = 1; i <= n; i++)
	        q[1][i] = c[1][i];
	    for (i = 1; i <= n; i++)
	    {
	        q[i][0] = INFTY;
	        q[i][n + 1] = INFTY;
	    }
	    for (i = 2; i <= n; i++)
	    {
	        for (j = 1; j <= n; j++)
	        {
	            min = min3(q[i - 1][j - 1], q[i - 1][j],
	       for (i = 2; i <= n; i++)
	    {
	        for (j = 1; j <= n; j++)
	        {
	            min = min3(q[i - 1][j - 1], q[i - 1][j],
	                    q[i - 1][j + 1]);
	            q[i][j] = min + c[i][j];
	            if (min == q[i - 1][j - 1])
	                p[i][j] = -1;
	            else if (min == q[i - 1][j])
	                p[i][j] = 0;
	            else
	                p[i][j] = 1;
	        }
	    }
	}
	
	void PrintShortestPath(int n, int imin)
	{
	    printf(" (%d, %d) <-", n, imin);
	    if (n == 2)
	        printf(" (%d, %d)\n", 1, imin + p[n][imin]);
	    else
	        PrintShortestPath(n - 1, imin + p[n][imin]);
	}
	
	void ComputeCBShortestPath(int n)
	{
	    int i, imin, min;
	    ComputeCBCosts(n);
	    imin = 1;
	    min = q[n][1];
	    for (i = 2; i <= n; i++)
	    {
	        if (q[n][i] < min)
	        {
	            imin = i;
	            min = q[n][i];
	        }
	    }
	    printf("*** The cost of the shortest path is %d.\n", q[n][imin]);
	    PrintShortestPath(n, imin);
	}
	
	void main(void)
	{
	    int n;
	    n = N;
	    ComputeCBShortestPath(n);
	}
	```

