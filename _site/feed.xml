<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-02-04T11:34:59+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">KyuHwan Shim</title><subtitle>Undergrad. HAI</subtitle><author><name>KyuHwan Shim</name><email>skh7343@cnsh.hs.kr</email></author><entry xml:lang="en"><title type="html">[SP] 13. Virtual Memory: Concepts</title><link href="http://localhost:4000/blog/13-sp-vm/" rel="alternate" type="text/html" title="[SP] 13. Virtual Memory: Concepts" /><published>2022-06-18T12:26:09+09:00</published><updated>2022-06-18T12:26:09+09:00</updated><id>http://localhost:4000/blog/13-sp-vm</id><content type="html" xml:base="http://localhost:4000/blog/13-sp-vm/">&lt;h1 id=&quot;13-virtual-memory-concepts&quot;&gt;13. Virtual Memory: Concepts&lt;/h1&gt;

&lt;h1 id=&quot;address-spaces&quot;&gt;Address spaces&lt;/h1&gt;

&lt;h2 id=&quot;a-system-using-physical-addressing&quot;&gt;A System Using Physical Addressing&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/underthelights/underthelights.github.io/main/_posts/SP/13/Untitled.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;address space : 주소 공간
    &lt;ol&gt;
      &lt;li&gt;process가 보는 address space -&amp;gt; virtual address&lt;/li&gt;
      &lt;li&gt;Physical memory가 보는 -&amp;gt; physical address&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CPU입장에서 보자.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CPU가 main memory 접근을 하게 되면 CPU가 addressing하는 주소는 physical address에 해당하는 주소에 있는 data를 load/store할 수 있게 한다
    &lt;ul&gt;
      &lt;li&gt;ex. Physical memory고 load 를 통해 word를 가지고 옴&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;→ Used in “simple” systems like embedded microcontrollers in devices like cars, elevators, and digital picture frames Physical address (PA) CPU 4 3 …
CPU가 볼 때 물리적으로 load/store하며 수행하는 simple한 system에서 활용&lt;/li&gt;
  &lt;li&gt;VM지원하지 않는 경우에는 physical memory로 활용 (VM 개념자체가 없다)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;a-system-using-virtual-addressing&quot;&gt;A System Using Virtual Addressing&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/underthelights/underthelights.github.io/main/_posts/SP/13/Untitled%201.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CPU에서 virutal addreessing : 접근하는 주소가 virtual address (Not Physical addressing)&lt;/li&gt;
  &lt;li&gt;MMU : (memory managing unit) : 4100번지에서 load/store한다고 하면 physical address로 변환해 주는 HW (CPU안에 들어가 잇음)
    &lt;ul&gt;
      &lt;li&gt;Microcontrolloer 처럼 사실 CPU가 굉장히 간단했는데 VM 해주는 system에서는 CPU chip 자체가 앞에 있는 것 보다 복잡해졌는데, virtual address를 physical address로 변환해주는 역할을 MMU에서 수행(4100(VA) - 4(PA))&lt;/li&gt;
      &lt;li&gt;Used in all modern servers, laptops, and smart phones&lt;/li&gt;
      &lt;li&gt;One of the great ideas in computer science M-1: …&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;address-spaces-1&quot;&gt;Address Spaces&lt;/h2&gt;

&lt;p&gt;어떻게 va-&amp;gt; pa 변환될까?일단 정의부터 살펴보자.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Linear address space:
    &lt;ul&gt;
      &lt;li&gt;순서화 되어 있는 음수가 아닌 continguous한 정수 주소&lt;/li&gt;
      &lt;li&gt;Ordered set of contiguous non-negative integer addresses&lt;/li&gt;
      &lt;li&gt;{0, 1, 2, 3 … }&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Virtual address space:
    &lt;ul&gt;
      &lt;li&gt;n개의 bit로 표현한다고 하면 N = 2^n만큼으로&lt;/li&gt;
      &lt;li&gt;Set of N = 2n virtual addresses&lt;/li&gt;
      &lt;li&gt;{0, 1, 2, 3, …, N-1}
        &lt;ul&gt;
          &lt;li&gt;ex. n=4면 N = 2^4 = 16이므로 {0 ~ 15}까지 VA로 표현됨&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Physical address space:
    &lt;ul&gt;
      &lt;li&gt;물리적인 주소로 표현&lt;/li&gt;
      &lt;li&gt;VA&amp;gt;PA인 경우가 많음 (일반 modern PC에서는) - VA를 PA로 표현하기 위한 N &amp;gt; M (N!=M)&lt;/li&gt;
      &lt;li&gt;Set of M = 2m physical addresses&lt;/li&gt;
      &lt;li&gt;{0, 1, 2, 3, …, M-1}&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;why-virtual-memory-vm&quot;&gt;Why Virtual Memory (VM)?&lt;/h2&gt;

&lt;p&gt;(의문) Linear address 그냥 쓰면 되는데 왜 VA/PA 쓰는 것일까?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Uses main memory efficiently 
 DRAM을 좀 더 효과적으로 사용하기 위하여 VM 사용&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Use DRAM as a cache for parts of a virtual address space&lt;/li&gt;
      &lt;li&gt;VA의 일부만 DRAM에 올려 둔다 : process 공부할 때 text/ data /heap/ stack도 있고, 실제 process가 보는 virtual한 space&lt;/li&gt;
      &lt;li&gt;실제 program이 수행되면 .text, .data, .heap, .stack이 있을 것이고 중간에 memory map이 존재할 것이다.&lt;/li&gt;
      &lt;li&gt;프로그램이 실행되면 text나 data의 경우에도 time의 축에서 VM의 모든 구역을 다 memory에 올려둘 필요 없이 필요에 따라 DRAM에 올려 둔 main memory 공간을 cache: 특정 w time 구간동안 접근.&lt;/li&gt;
      &lt;li&gt;VA에 해당하는 모든 주소 공간에 있는 것들을 모드 memory에 올려놓을 필요는 없고, 자주/많이 접근되는 부분들만 VA일부로 하여 올려두겠다. DRAM은 정말 비싼 자원이기에 정말 필요한 것만 올려두는 역할을 수행하도록 한다.&lt;/li&gt;
      &lt;li&gt;그냥 물리적 주소였다면 그냥 memory mapping을 하면 됨&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Simplifies memory management
    &lt;ul&gt;
      &lt;li&gt;Each process gets the same uniform linear address space&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;0~특정한 값까지 동일하게&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;모든 process가 자기가 접근하는 VA의 값을 0~특정 공간까지 관리할 수 있도록 해 주자&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Isolates address spaces
    &lt;ul&gt;
      &lt;li&gt;One process can’t interfere with another’s memory&lt;/li&gt;
      &lt;li&gt;User program cannot access privileged kernel information and code 6&lt;/li&gt;
      &lt;li&gt;address space를 각 process마다 자신의 address space만 사용하게 고립시키자 :서로 isolate되어 있어 서로의 영역에 대해 접근할 수 없게 한다.
        &lt;ul&gt;
          &lt;li&gt;→ 다른 process의 memory와 interference (접근 못하게) 방지&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;kernel은 접근할 수 있지만 process끼리는 서로 접근 못하게 하고 process는 kernel 정보를 touch하지 못하게 하여 access/modify 못 하게 해주기 위해 필요한 기술 중 하나.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;vm-as-a-tool-for-caching&quot;&gt;VM as a Tool for Caching&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Conceptually, &lt;strong&gt;virtual memory&lt;/strong&gt; is an array of N contiguous bytes stored on disk.&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;개념적으로 어떻게 표현할 것인가&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;process가 보는 memory = VM&lt;/li&gt;
      &lt;li&gt;conceptually, process가 실제 memory에 올라와 구동되게 되는데, 개념적으로 VM이라는 것은 disk 공간에서 n개의 연속된 byte array로 보겠다는 것이다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;= 어떤 process가 있다고 하면 contiguous한 linear addreess (0~)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;4KB/8KB page : 동일한 page들을 가상 주소가 disk에 mapping되어 있는 연속된 n개의 byte array로 표현한다고 가정하고 생각을 해 보면 실제 main memory에 올라온 physical memory 영역에서는 cached 부분만 올라옴&lt;/li&gt;
      &lt;li&gt;그리고 실제 main memory에 있는 공간은 : VM에 0번지 ~ N-1번지 까지 N개의 page가 있었다고 하면, PM에 0 ~ M-1번지, M&amp;lt;N&lt;/li&gt;
      &lt;li&gt;
        &lt;blockquote&gt;
          &lt;p&gt;실제 가상 memory의 특정 page들이 사용되서 main meory에 mapping되어 올라와 있는 경우에 다음처럼 보인다. 나머지는 empty된 상태이다.&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;물리적 메모리를 가져다 가상 메모리의 cache처럼 본다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The contents of the array on disk are cached in &lt;strong&gt;physical memory (DRAM cache)&lt;/strong&gt;&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;These cache blocks are called pages (size is P = 2p bytes)&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;DRAM Cache : disk에 있다고 하면 (virtual page )&lt;/p&gt;

    &lt;p&gt;main memory에 있는 건 DRAM에 있는 disk 주소 공간의 cache (physical page)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;활성화된 active page들만 memory에 올라와 있음&lt;/li&gt;
      &lt;li&gt;
        &lt;blockquote&gt;
          &lt;p&gt;virtual memory를 cacheingg하기 위한 tool이라고 볼 수 있다!&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/underthelights/underthelights.github.io/main/_posts/SP/13/Untitled%202.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;dram-cache-organization&quot;&gt;DRAM Cache Organization&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Fixed 크기의 block : page / block이라고 이야기함&lt;/li&gt;
  &lt;li&gt;PP에서 cached page 제외 나머지 empty공간을 내가 못 쓴다고 하면 다른 녀석을 가져다 caching하게 될 때 누군가를 쫓아내야 함 -&amp;gt; 굉장히 복잡하지만 그 알고리즘도 overhead가 됨&lt;/li&gt;
  &lt;li&gt;cached page에 대해 mapping function 관리&lt;/li&gt;
  &lt;li&gt;DRAM cache organization driven by the enormous miss penalty
    &lt;ul&gt;
      &lt;li&gt;DRAM is about 10x slower than SRAM&lt;/li&gt;
      &lt;li&gt;Disk is about 10,000x slower than DRAM&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Consequences
    &lt;ul&gt;
      &lt;li&gt;Large page (block) size: typically 4 KB, sometimes 4 MB
        &lt;ul&gt;
          &lt;li&gt;page는 통상적으로 4KB (가끔 4MB)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Fully associative
        &lt;ul&gt;
          &lt;li&gt;Any VP can be placed in any PP&lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Requires a “large” mapping function – different from cache memories&lt;/p&gt;

            &lt;p&gt;virtual page들을 physical page로 mapping할 수 있는데 어느 VP도 어느 PP로 들어갈 수 있다.  = CPU Cache는 VP가 물리적 slot에 어디나 들어가도 된다&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Highly sophisticated, expensive replacement algorithms
        &lt;ul&gt;
          &lt;li&gt;Too complicated and open-ended to be implemented in hardware&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Write-back rather than write-through 9
        &lt;ul&gt;
          &lt;li&gt;write 하게 되면 cache에 있는 page가 있어 실제 disk공간에 있는 page들인데&lt;/li&gt;
          &lt;li&gt;(1) write through : PP를 씀과 동시에 같이 쓸 것이냐&lt;/li&gt;
          &lt;li&gt;(2) write back
            &lt;ul&gt;
              &lt;li&gt;PP에 먼저 쓰고 나중에 evict할 때 VP와 동기화 할 것이냐&lt;/li&gt;
              &lt;li&gt;먼저 DRAM(cache)에 있는 것을 써 놓고 나중에 disk 공간에 있는 page가 evict될 때 VP와 동기화하여 씀&lt;/li&gt;
              &lt;li&gt;VM 개념을 도입했는데 실제 구현하려면&lt;/li&gt;
              &lt;li&gt;CPU 밖의 main memory를 이야기 중.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;SRAM Cache는 CPU안에 있음
    &lt;ul&gt;
      &lt;li&gt;HW로도 구현 : main memory중 어떤 memory에 cache한다고 할 때 누구를 쫓아내는가 등은 실제 program이 실행 될 때 cycle을 많이 소요 -&amp;gt; HW로 faster 구현&lt;/li&gt;
      &lt;li&gt;SRAM&amp;gt;DRAM&amp;gt;Disk&lt;/li&gt;
      &lt;li&gt;SRAM Cache : CPU chip안에 있는 processor cache가 hw적으로 설계됨 -
  CPU안에서 instruction fetch할 때 활용
  (L1, L2) : cpu chip 안에 있어서 on chip cache
  (L3) : off chip cache - 바로 밖에 붙어 있음&lt;/li&gt;
      &lt;li&gt;DRAM : CPU 밖 memory, l3 옆 가장 붙어 있는 memory&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;enabling-data-structure-page-table&quot;&gt;Enabling Data Structure: Page Table&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;A &lt;strong&gt;page table&lt;/strong&gt; is an array of page table entries (PTEs) that maps virtual pages to physical pages.
    &lt;ul&gt;
      &lt;li&gt;앞에 있었던(8) : VA-&amp;gt;PA로 mapping function&lt;/li&gt;
      &lt;li&gt;무언가 어쨌든 이 주소를 VP1이 PP1에 mapping되어있다는 정보 + page들의 mapping 정보. 다시 말하면 어떤 page들이 어떤 물리적 page에 mapping되어 있는가에 대한 정보가 필요함. 이를 관리하기 위한 table이 page table&lt;/li&gt;
      &lt;li&gt;inear table의 entry가 VA를 PA로 변환해주는 역할을 수행(translator) - page : 각각의 memory에서의 물리적인 공간&lt;/li&gt;
      &lt;li&gt;일정 크기의 page (block)을 mapping하기 위한 entry가 table에 들어가 있음&lt;/li&gt;
      &lt;li&gt;Entry는 가상 주소에 해당하며 이를 보게 되면 0번부터 N에 해당하는 index에서 N=8이라고 하면 PTE 0~7,&lt;/li&gt;
      &lt;li&gt;page : unallocated/ cached / uncached … - process 공간에서 data와 text로 보게 되고 heap을 쓰게 되면 위로 올라감/ 중간에 allcoate되지 않는 공간이 있을 것임. 영역을 할당하게 되면 위쪽PTE=0이 text/code, n-1쪽으로부터 heap이 쭉 올라간다고 보면 됨&lt;/li&gt;
      &lt;li&gt;entry안의 내용을 보게 되면 실제 physical page number가 들어가 있음&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;process마다 가지고 있는 OS의 data structure: OS Kernel DS로서 10개 프로세스에 해당하는 다음과 같은 table을 process마다 가지고 있음&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;Per-process kernel data structure in DRAM&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/underthelights/underthelights.github.io/main/_posts/SP/13/Untitled%203.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;질문
    &lt;ul&gt;
      &lt;li&gt;CPU 개수랑은 완전히 orthogonal : process 개수 만큼&lt;/li&gt;
      &lt;li&gt;page table size : 1MB/4MB (OS시간에 배움)&lt;/li&gt;
      &lt;li&gt;page table 자체가 DRAM에 저장됨. 자체 주소는 process의&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;process마다 process control block이라고 해서 자료구조가 있는데 여기서 page table에 대한 주소를 가지고 있음. 그 주소에 대한 page table이 선형적으로 들어가 있고, 나중에는 base line register에다가 process가 context switch될 때 주소를 가져다 넣는다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;blockquote&gt;
          &lt;p&gt;Page Table은 kernel이 보는 것이고, kernel은 physical 주소를 본다. Virtual 주소도 보기는 하지만 physical 주소와도 1대1 대응하기에 Page table자체의 주소는 물리주소로 저장된다고 봐도 될 듯.&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;fork하면 child process는 parent process와 같은 page table을 공유하는가? 그럼 같은 virtual memory가 서로 다른 physical memory를 가리키게 되는가? -&amp;gt; page table이 복제되는데 새로은 page table로 update됨 (공유하지 않음) 부모 것 하나, 자식 것 하나 각각 따로따로 가지고 있음. 즉, 서로 다른 physical memory를 가리키게 됨.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;(PM) 실제 physically mapped : cached 영역 (1,2,7,4) to PP 0,1,2,3&lt;/li&gt;
  &lt;li&gt;(VM) unallocate / allocate되어 있지만 아직 cached 안 됨&lt;/li&gt;
  &lt;li&gt;page table을 통해서 주소 변환&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;→Disk공간이라고 봐도 되고&lt;/p&gt;

&lt;p&gt;page table을 통하여 주소 변환을 해 주는 역할을 감당하게 된다.&lt;/p&gt;

&lt;h2 id=&quot;page-hit&quot;&gt;Page Hit&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/underthelights/underthelights.github.io/main/_posts/SP/13/Untitled%204.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Page hit: reference to VM word that is in physical memory (DRAM cache hit)&lt;/li&gt;
  &lt;li&gt;나중에 VM을 가지고 mem copy를 한다고 하면 다른 VM으로 copy하게 되는데 그 주소는 ‘VA’
    &lt;ul&gt;
      &lt;li&gt;결국 내부적으로는 PA를 접근해야 한다. OS기저로 들어가면 내부 변환 작업을 수행해주어야 한다.&lt;/li&gt;
      &lt;li&gt;가상 주소가 DRAM에 있는가, Disk에 있는가는 page table 앞의 validity를 본다.
        &lt;ul&gt;
          &lt;li&gt;1인경우에만 main memory에 올라가 있는 형태: DRAM Cache에서 hit가 일어나서 DRAM에 접근하면 됨&lt;/li&gt;
          &lt;li&gt;0인경우: allocate 안 되어 있거나 VA가 실제 disk에 연결&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;해당하는 Validty를 확인한 후 DRAM Cache를 뒤져봄
    &lt;ul&gt;
      &lt;li&gt;Fault 발생&lt;/li&gt;
      &lt;li&gt;실제 접근했는데 접근하는 Page의 validity가 0으로 되어 있음 : physical하게 dram cache에 있는 게 아니라 dram cache에 있음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;page-fault&quot;&gt;Page Fault&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Page fault: reference to VM word that is not in physical memory (DRAM cache miss)
    &lt;ul&gt;
      &lt;li&gt;Page가 없기 때문에 page missing →fault handling 필요&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/underthelights/underthelights.github.io/main/_posts/SP/13/Untitled%205.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;handling-page-fault&quot;&gt;Handling Page Fault&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/underthelights/underthelights.github.io/main/_posts/SP/13/Untitled%206.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Page miss causes page fault (an exception)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;Page Fault Handler가
    &lt;ul&gt;
      &lt;li&gt;PP 0~3 중 모종의 이유로 PP3을 쫓아내겠다고 결정 (evict)&lt;/li&gt;
      &lt;li&gt;evict하게 될 때 VP4는 VM으로, VP3은 PM으로 이동&lt;/li&gt;
      &lt;li&gt;3번이 올라왔으니깐 virtual page number 3번으로 이동하게 된다. 이러한 어떤 작업을 수행해주어야 한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;→ Fault가 나오게 되면 누군가를 evict시켜주고 page table 을 update해주어야 한다. (4를 disk mapping, 3은 DRAM에 mapping)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;demand paging&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;누군가를 evict하고 누군가를 가져와야 함&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Page miss causes page fault (an exception)&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/underthelights/underthelights.github.io/main/_posts/SP/13/Untitled%207.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Page fault handler selects a victim to be evicted (here VP 4)&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/underthelights/underthelights.github.io/main/_posts/SP/13/Untitled%208.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/underthelights/underthelights.github.io/main/_posts/SP/13/Untitled%209.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Offending instruction is restarted : page hit&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/underthelights/underthelights.github.io/main/_posts/SP/13/Untitled%2010.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;allocating-pages&quot;&gt;Allocating Pages&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Allocating a new page (VP 5) of virtual memory.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/underthelights/underthelights.github.io/main/_posts/SP/13/Untitled%2011.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;locality-to-the-rescue-again&quot;&gt;Locality to the Rescue Again!&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Virtual memory seems terribly inefficient, but it works because of locality.&lt;/li&gt;
  &lt;li&gt;At any point in time, programs tend to access a set of active virtual pages called the &lt;strong&gt;working set&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Programs with better temporal locality will have smaller working sets&lt;/li&gt;
      &lt;li&gt;process 관점에서 봤을 때, VA를 PA로 바꾸어 주는 과정 자체가
  내가 접근되는 memory주소에 따라서 어떤 놈은 DRAM, 어떤 놈은 DIsk에 있기 때문에 handling overhead가 상당히 큼
        &lt;ul&gt;
          &lt;li&gt;→ working set : 가상 메모리 페이지들의 집합.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;If (working set size &amp;lt; main memory size)
Working set &amp;lt; 내가 가진 main memory size
    &lt;ul&gt;
      &lt;li&gt;Good performance for one process after compulsory misses
  (Page fault가 발생하지 않을 것이니까)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;If ( SUM(working set sizes) &amp;gt; main memory size )
Working set &amp;gt; 내가 가진 main memory size
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Thrashing:&lt;/strong&gt; Performance meltdown where pages are swapped (copied) in and out continuously 18&lt;/li&gt;
      &lt;li&gt;working set이 커지게 되면 thrashing문제 발생 : 자꾸 disk mapping / dram 이랬다 저랬다 하면 disk 접근 때문에 발생하게 된다. (어떤 페이지가 in and out from disk -&amp;gt; 성능이 완전히 melt down된다)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;cache size라는 것은 어느정도 적당한 크기로 보장되어야 함.&lt;/p&gt;

    &lt;p&gt;CPU 성능도 중요하지만 메모리 성능이 중요한 이유이다: 여러 프로그램을 돌리기 때문에 각 process마다 지금과 같은 process마다 dram cache영역이 확보되어야 한다. 구동시키는 프로그램(웹/다양한 프로그램)들로 인한 in n out으로 인해  thrashing 이 발생하여 속도가 완전히 죽어버림.&lt;/p&gt;

    &lt;p&gt;→ 가급적이면 memory 큰 pc를 구입&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;vm-as-a-tool-for-memory-management&quot;&gt;VM as a Tool for Memory Management&lt;/h1&gt;

&lt;h2 id=&quot;key-idea-each-process-has-its-own-virtual-address-space&quot;&gt;Key idea: each process has its own virtual address space&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;It can view memory as a simple linear array&lt;/li&gt;
  &lt;li&gt;Mapping function scatters addresses through physical memory
    &lt;ul&gt;
      &lt;li&gt;Well-chosen mappings can improve locality&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/underthelights/underthelights.github.io/main/_posts/SP/13/Untitled%2012.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;VM as a Tool for Memory Management&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Simplifying memory allocation&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Each virtual page can be mapped to any physical page&lt;/li&gt;
      &lt;li&gt;A virtual page can be stored in different physical pages at different times&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Sharing code and data among processes
    &lt;ul&gt;
      &lt;li&gt;Map virtual pages to the same physical page (here: PP 6)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/underthelights/underthelights.github.io/main/_posts/SP/13/Untitled%2013.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;simplifying-linking-and-loading&quot;&gt;Simplifying Linking and Loading&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/underthelights/underthelights.github.io/main/_posts/SP/13/Untitled%2014.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Linking
    &lt;ul&gt;
      &lt;li&gt;Each program has similar virtual address space&lt;/li&gt;
      &lt;li&gt;Code, data, and heap always start at the same addresses.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Loading
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;execve&lt;/code&gt; allocates virtual pages brk for .text and .data sections &amp;amp; creates PTEs marked as invalid&lt;/li&gt;
      &lt;li&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.text&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.data&lt;/code&gt; sections are copied, page by page, on demand by the virtual memory system&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;vm-as-a-tool-for-memory-protection&quot;&gt;VM as a Tool for Memory Protection&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Extend PTEs with Permission bits&lt;/li&gt;
  &lt;li&gt;MMU checks these bits on each access&lt;/li&gt;
&lt;/ul&gt;</content><author><name>KyuHwan Shim</name><email>skh7343@cnsh.hs.kr</email></author><category term="system-programming" /><category term="CS" /><category term="os" /><category term="system-programming" /><summary type="html">Chap 13.</summary></entry><entry xml:lang="en"><title type="html">ML SG Repackage (Chapter 7-13)</title><link href="http://localhost:4000/blog/ML-SG-REPKG/" rel="alternate" type="text/html" title="ML SG Repackage (Chapter 7-13)" /><published>2022-06-16T12:26:09+09:00</published><updated>2022-06-16T12:26:09+09:00</updated><id>http://localhost:4000/blog/ML-SG-REPKG</id><content type="html" xml:base="http://localhost:4000/blog/ML-SG-REPKG/">&lt;h1 id=&quot;final-repkg-for-ml&quot;&gt;[Final Repkg. for ML]&lt;/h1&gt;

&lt;h1 id=&quot;7-knn&quot;&gt;7. kNN&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/7-k-Nearest-Neighbor-abad63e2757e4de39af29914c4c63e82&quot;&gt;7. k-Nearest Neighbor&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;kNN = Instance based learning&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;주어진 test sample X에 대하여, kNN samples (xn1, yn1) … (xnk, ynk)를 위치시켜 majority class label yn1, .. ynk를 xt에 assign한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;kNN pros and cons&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;pros :
        &lt;ul&gt;
          &lt;li&gt;training is very fast : feature extraction and save&lt;/li&gt;
          &lt;li&gt;learn complex target fn&lt;/li&gt;
          &lt;li&gt;doesn’t lose info&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;cons :
        &lt;ul&gt;
          &lt;li&gt;slow at test  → not goot&lt;/li&gt;
          &lt;li&gt;requires large storage&lt;/li&gt;
          &lt;li&gt;not robust against irrevalent attributes, outliers&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Distance Metrics&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;kNN - test 시점 ) data와 Near한지 distance 계산&lt;/li&gt;
      &lt;li&gt;distance : 모든 Classification , regression에서 중요
        &lt;ul&gt;
          &lt;li&gt;단 Nominal data다루는 DT에서는 불필요&lt;/li&gt;
          &lt;li&gt;similiarity와 반비례&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;table&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;Euclidean distance : $\sqrt{\Sigma_{d=1}^{D}&lt;/td&gt;
              &lt;td&gt;x_{td} - x_{nd}&lt;/td&gt;
              &lt;td&gt;^2}$&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;table&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;Manhattan distance : ${\Sigma_{d=1}^{D}&lt;/td&gt;
              &lt;td&gt;x_{td} - x_{nd}&lt;/td&gt;
              &lt;td&gt;}$&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;table&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;$L^n$-norm : $\sqrt{\Sigma_{d=1}^{D}&lt;/td&gt;
              &lt;td&gt;x_{td} - x_{nd}&lt;/td&gt;
              &lt;td&gt;^n}$&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
      &lt;/li&gt;
      &lt;li&gt;When we say ‘nearest’, it depends on the distance metric :
        &lt;ul&gt;
          &lt;li&gt;
            &lt;table&gt;
              &lt;tbody&gt;
                &lt;tr&gt;
                  &lt;td&gt;Euclidean distance : $\sqrt{\Sigma_{d=1}^{D}&lt;/td&gt;
                  &lt;td&gt;x_{td} - x_{nd}&lt;/td&gt;
                  &lt;td&gt;^2}$&lt;/td&gt;
                &lt;/tr&gt;
              &lt;/tbody&gt;
            &lt;/table&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;table&gt;
              &lt;tbody&gt;
                &lt;tr&gt;
                  &lt;td&gt;Manhattan distance : ${\Sigma_{d=1}^{D}&lt;/td&gt;
                  &lt;td&gt;x_{td} - x_{nd}&lt;/td&gt;
                  &lt;td&gt;}$&lt;/td&gt;
                &lt;/tr&gt;
              &lt;/tbody&gt;
            &lt;/table&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;table&gt;
              &lt;tbody&gt;
                &lt;tr&gt;
                  &lt;td&gt;$L^n$-norm : $\sqrt{\Sigma_{d=1}^{D}&lt;/td&gt;
                  &lt;td&gt;x_{td} - x_{nd}&lt;/td&gt;
                  &lt;td&gt;^n}$&lt;/td&gt;
                &lt;/tr&gt;
              &lt;/tbody&gt;
            &lt;/table&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Each dimension can be differently &lt;strong&gt;scaled&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;Each dimension may have different impact&lt;/li&gt;
          &lt;li&gt;
            &lt;table&gt;
              &lt;tbody&gt;
                &lt;tr&gt;
                  &lt;td&gt;May &lt;strong&gt;bias&lt;/strong&gt; the performance of the classifier $\sqrt{\Sigma_{d=1}^{D} w_d&lt;/td&gt;
                  &lt;td&gt;x_{td} - x_{nd}&lt;/td&gt;
                  &lt;td&gt;^2}$&lt;/td&gt;
                &lt;/tr&gt;
              &lt;/tbody&gt;
            &lt;/table&gt;
            &lt;ul&gt;
              &lt;li&gt;동일한 기준 측정 X → performance bias 발생 가능&lt;/li&gt;
              &lt;li&gt;weight를 특정 feature에 넣어 거리의 상대적인 크기를 feature에 따라서 넣는다&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;VDM&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;provide d measurements for nominal attributes&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Problem from Euclidean distance&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;High dim data - curse of dimensionality
        &lt;ul&gt;
          &lt;li&gt;너무 많이 feature, attrib 증가시킬 경우 dim이 너무 많이 증가해 차원의저주&lt;/li&gt;
          &lt;li&gt;sample로부터 available info 가 많고 정확하다면 dim 높아도 괜찮음&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;보통 sparse하고 density를 shrink하여 적용한다.&lt;/li&gt;
      &lt;li&gt;과연 d가 동일하다고 data feature를 잘 나타낼까?
        &lt;ul&gt;
          &lt;li&gt;MSB, LSB 등 bit 연산으로부터 잘 표현이 안될수도 있음&lt;/li&gt;
          &lt;li&gt;Hamming d.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Behavior of limit&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;$\lim _{n \rightarrow \infty} \leq 2 \epsilon ^*$&lt;/p&gt;

    &lt;p&gt;pf) goodnote 참고&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Standardization&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;z = x - mu / sigma&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;how to choose k&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;k is too small → sensitive to noise points&lt;/li&gt;
      &lt;li&gt;k is too big → neighborhood may include pts from other classes
        &lt;ul&gt;
          &lt;li&gt;smoother when k get bigger&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;보통 $k = \sqrt N$&lt;/li&gt;
      &lt;li&gt;$n \rightarrow \infty$, k gets larger → good performance as good as bayes classifier&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cross Validation !!!&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;N fold cross validation → k to minimize cross valid error&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;overfitting에 의해 - train error를 줄이는 것이 무작정 좋지는 않다&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Condensing!!!&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;[Aim] reduce the number of training samples&lt;/li&gt;
      &lt;li&gt;Decision boundary consistent : same with entire training set
        &lt;ul&gt;
          &lt;li&gt;min. consistent set : smallest subset of samples&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;1) init subset with single ex. 
  → 2) nearest neighbor 생성, epsilon나오는 incorrected samples 선택 
  → 3) 2)반복 Until no transfers or subset is full → result 구하기&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Voronoi Diagram&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Voronoi Diagram : div space into such cells : 구획으로 나누고 boundary 영향없는 sample del&lt;/li&gt;
      &lt;li&gt;Delaunary triagulation 생성 → circumcircle center pt 끼리 연결 : 
  각 sample pt class에 따라 전체 영역 Class 결정
        &lt;ul&gt;
          &lt;li&gt;Delaunary triagulation : 삼각형의 세 점에 외접하는 삼각형, 각도 최대화&lt;/li&gt;
          &lt;li&gt;not unique&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;8-ann&quot;&gt;&lt;strong&gt;8. ANN&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/8-ANN-2866fb8a17b645a1af86f8a713f28c3d&quot;&gt;8. ANN&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Differences with&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Similar : SVM처럼 high dimension mapping과 유사한 input layer to hidden layer
        &lt;ul&gt;
          &lt;li&gt;원래 feature space에서는 not linearly separable → phi fn(high dim) 으로 sol&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Bitwise Calc.&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;perceptron : AND, OR연산 가능하나 XOR 불가능&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;sol: XOR이 nonlinear해서 생긴 문제 : 2 Decision boundary&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ANN Training&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;input - hidden - output : hidden layer 수에 따라 네트워크 구조가 좌우되며 linearly nonsolvable 문제도 해결해낼 수 있다&lt;/li&gt;
      &lt;li&gt;1) decide input /output / hidden layer node number 
  → 2) find weight using training alg (backpropagation)&lt;/li&gt;
      &lt;li&gt;#class = #node&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Backpropagation&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;(등장배경) NN-SVM-DNN에서 SVM이 많이 쓰이는 경우였음. NN에서 overfitting / XOR문제&lt;/li&gt;
      &lt;li&gt;(Idea) Weight w를 Error 감소하는 방향으로 Update - between prediction vs ground truth val&lt;/li&gt;
      &lt;li&gt;(prob. similar to perceptron) stuck in local minima, iteratively get w, many w to get y&lt;/li&gt;
      &lt;li&gt;chain rule&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Vanishing Gradient Problem&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;error들이 backpropagate하면 gradient가 vanish하는 현상 : layer에서 소수점이 곱해질수록 0으로 수렴하기 때문이다. w = w - eta dE/du&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;sol : requires lots of data&lt;/li&gt;
      &lt;li&gt;nonlinear ReLU&lt;/li&gt;
      &lt;li&gt;Layerwise learning : 충분히 학습되면 넘어감&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Overfitting&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Only get good result for train data only&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;get stuck in local minima&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;solution : randomly set initial val +many data + much computation power→ train many times → avg 추출&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;good model check&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;solution : train data, test data 변화시키며 stable result를 보이는지 확인한다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;9-dnn&quot;&gt;9. DNN&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985&quot;&gt;9. DNN&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Why is better than traditional ML&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;SVM) Manual, Human supervised, div and conquer
        &lt;ul&gt;
          &lt;li&gt;기존에 human이 feature extraction한 후 classification함.&lt;/li&gt;
          &lt;li&gt;SVM에서는 Hand-crafted phi fn을 활용해서 alg에서 Pattern이 더 잘 보이도록 수정했다&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;DL) Automatical, end-to-end NN
        &lt;ul&gt;
          &lt;li&gt;end-to-end joint system : NN이라는 hierarchical structure로 feature extract + classification 과정 수행
            &lt;ul&gt;
              &lt;li&gt;→ data를 지속적으로 분류 : 자체적으로 자동적으로 배우고 지능적인 결정 수행&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;modularization : automatically learned from data (each classes)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;DNN consist&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;input layer + multiple hidden l + output layer&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;(CNN) Layers : FC Layer, Locally connected layer&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;corelation 구하는 작업 → 조합을 다음 layer로 전달한다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;FC : globally corelated - rsrc waste, too much calc., not enough data to train pm&lt;/li&gt;
      &lt;li&gt;LC : 일정 convolution내 node (different locations-convolutions with learned kernel)
        &lt;ul&gt;
          &lt;li&gt;convolution : 특정 Window size filter&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;(CNN) Conv. operations&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Conv A * B = B * A&lt;/li&gt;
      &lt;li&gt;cross-corelation : A . B ≠ B . A&lt;/li&gt;
      &lt;li&gt;auto-correlation : 자기 자신과 동일&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;(CNN) Pooling&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;filter responses at different location → robustnest to spatial location of filters&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;max, avg, l2 pooling&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;(CNN) size of feature map 계산&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;tasks&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Classification : exact class 분류&lt;/li&gt;
      &lt;li&gt;Localization : obj 주변에 box를 두고 정답과 적어도 50%이상 겹쳐야 함&lt;/li&gt;
      &lt;li&gt;Obj Detection : n개의 obj에 모두 boundary box 처리&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Alexnet&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;act. fn. : ReLU in Hidden layers → faster, expressive than sigmoid&lt;/li&gt;
      &lt;li&gt;ten different 224&lt;em&gt;224 patches from from 256&lt;/em&gt;256 img&lt;/li&gt;
      &lt;li&gt;dropout to reg. weight in FC layers&lt;/li&gt;
      &lt;li&gt;padding&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;FC Layer&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;has no constrains the input img size (상관 없음)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;DNN Evolution&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;NN - Perceptron - Backporpagatino ,RNN, RBM - CNN, MNIST, LSTM, BRNN - DBN - GAN - AlphaGo&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;data labeled&lt;/li&gt;
      &lt;li&gt;obj detection focused&lt;/li&gt;
      &lt;li&gt;GPU
        &lt;ul&gt;
          &lt;li&gt;good for mat*mat multiplies + high bandwidth&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;shallower&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Backgrounds&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;HW (GPU) + Data (Big data) + Alg (learning Alg)&lt;/li&gt;
      &lt;li&gt;limit : cannot do commonsense reasoning - 상식, 윤리의 Lack&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;10-dnn2&quot;&gt;10. DNN2&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/10-DNN-2-c5c97bb69d724e25bb655b70f34d2575&quot;&gt;10. DNN 2&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Data Processing&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;In practice, you may also see PCA and Whitening of the data&lt;/p&gt;

    &lt;p&gt;PCA : dimensionality reduction, clustering (unsupervised)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;decorrelated data
        &lt;ul&gt;
          &lt;li&gt;(data has diagonal covariance matrix)&lt;/li&gt;
          &lt;li&gt;axis방향으로 평행 : with x1 only (1dim)&lt;/li&gt;
          &lt;li&gt;from 2dim → 1dim compression (data info loss)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;whitened data
        &lt;ul&gt;
          &lt;li&gt;
            &lt;p&gt;(covariance matrix is the identity matrix)&lt;/p&gt;

            &lt;p&gt;$\Sigma =$&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;acc 변화했을 수도 있으므로 performance 체크&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Weight Init.&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;“Xavier initialization” [Glorot et al., 2010]&lt;/p&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fanin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fanout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fanin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;Reasonable initialization. (Mathematical derivation assumes linear activations) with tanh fn&lt;/li&gt;
      &lt;li&gt;현재 layer node의 sqrt로 init&lt;/li&gt;
      &lt;li&gt;but when using the ReLU nonlinearity it breaks. (0에 접근)&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;He et al., 2015 (note additional /2)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;error가 더 잘 감소됨을 확인할 수 있음&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fanin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fanout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fanin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Batch Normalization&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;To make each dimension unit gaussian, apply:
        &lt;ul&gt;
          &lt;li&gt;$\hat x^{(k)} = \frac{x^{(k)} - E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}$
            &lt;ul&gt;
              &lt;li&gt;this is a vanilla differentiable function…&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;dimension 단위 normalilze&lt;/li&gt;
    &lt;/ul&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;compute the empirical mean and variance independently for each dimension.&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;Final/10/Untitled.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Normalize&lt;/p&gt;
        &lt;ul&gt;
          &lt;li&gt;$\hat x^{(k)} = \frac{x^{(k)} - E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}$
        - Usually inserted after Fully Connected or Convolutional layers, and before &lt;strong&gt;nonlinearity.&lt;/strong&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;&lt;img src=&quot;Final/10/Untitled_1.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Normalize:
        &lt;ul&gt;
          &lt;li&gt;$\hat x^{(k)} = \frac{x^{(k)} - E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}$&lt;/li&gt;
          &lt;li&gt;$\hat x \sqrt{Var} + E[x] = X$&lt;/li&gt;
          &lt;li&gt;$\gamma = \sqrt{Var} , \beta = E[x]$&lt;/li&gt;
          &lt;li&gt;$\hat x$ : normalized data, X : original data&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;And then allow the network to squash the range if it wants to:
        &lt;ul&gt;
          &lt;li&gt;$\hat y^{(k)} = \gamma^{(k)} \hat x^{(k)}+\beta^{(k)}$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Note, the network can learn:to recover the identity mapping.
        &lt;ul&gt;
          &lt;li&gt;$\gamma^{(k)} = \sqrt{Var[x^{(k)}]}$ (stretch)&lt;/li&gt;
          &lt;li&gt;$\beta^{(k)} = E[x^{(k)}]$ (이동)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;$X \rightarrow \hat X$ : normalize : $\gamma, \beta$로 scaling된 y value&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Regularization&lt;/strong&gt;&lt;/p&gt;

\[L = \frac 1 N \Sigma_{i=1}^{N} \Sigma_{j\neq y_i}{\max(0, f(x_i);W)_j - f(x_i);W)_{y_i} +1} + \lambda R(W)\]

    &lt;ul&gt;
      &lt;li&gt;Loss Fn : $\frac 1 N \Sigma_{i=1}^{N} \Sigma_{j\neq y_i}{\max(0, f(x_i);W)&lt;em&gt;j - f(x_i);W)&lt;/em&gt;{y_i} +1}$&lt;/li&gt;
      &lt;li&gt;Lambda weight term $+ \lambda R(W)$&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;Final/10/Untitled_2.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;In common use:&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;Final/10/Untitled_3.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dropout&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;(배경) deep NN 일수록 특정 node가 학습 시 dropped case 발생&lt;/li&gt;
      &lt;li&gt;(train) assume dropout rate p → (test) no dropout&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;regularization common pattern&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Cross Entropy Loss : $-\Sigma y_i \lim P_i$
        &lt;ul&gt;
          &lt;li&gt;yi : the answer&lt;/li&gt;
          &lt;li&gt;Pi : prediction&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Training: Add some kind of randomness
        &lt;ul&gt;
          &lt;li&gt;randomness - regularize&lt;/li&gt;
          &lt;li&gt;$y = f_W (x,z)$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Testing: Average out randomness (sometimes approximate)
        &lt;ul&gt;
          &lt;li&gt;$y = f(x) = E_z[f(x,z)] = \int p(z)f(x,z)dz$&lt;/li&gt;
          &lt;li&gt;iteration별 여러 mu, sigma → average를 구하여 test시점에 적용한다&lt;/li&gt;
          &lt;li&gt;BN도 regularization작업&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Example:BatchNormalization
        &lt;ul&gt;
          &lt;li&gt;Training:Normalize using stats from random mini batches&lt;/li&gt;
          &lt;li&gt;Testing:Use fixed stats to normalize&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;11-ensemble-learning&quot;&gt;11. Ensemble learning&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/11-Ensemble-Learning-afd95182fd9c4803b961642026442403&quot;&gt;11. &lt;strong&gt;Ensemble Learning&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ensemble Learning
    &lt;ol&gt;
      &lt;li&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Generate Ensembles&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Data Manipulation&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Train set에 변화&lt;/li&gt;
        &lt;/ol&gt;

        &lt;p&gt;Supervised learning에서 train set에 대해 train 되어 얻어진 model&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;다른 train set을 사용하면 -&amp;gt; 다른 model : 분류 성능이 다름&lt;/li&gt;
          &lt;li&gt;it changes the training set in order to obtain different models&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Modeling process manipulation&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;algorihtm에 변화&lt;/li&gt;
        &lt;/ol&gt;

        &lt;ul&gt;
          &lt;li&gt;model process manipulation : algorithm의 변화&lt;/li&gt;
          &lt;li&gt;parameter만 변화하는 경우도 있고, classifier 자체를 변경할수도 있음, algorithm 자체를 변화시킬수도 있고&lt;/li&gt;
          &lt;li&gt;→ 다양한 model (f1 _ /// fk)&lt;/li&gt;
          &lt;li&gt;it changes the induction algorithm, the parameter set or the model in order to obtain different models&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ensemble learning via negative correlation learning:&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Generating sequentially new predictors &lt;strong&gt;negatively correlated&lt;/strong&gt; with the existing ones
        &lt;ul&gt;
          &lt;li&gt;현재 classifier하고 negative corelation갖는 classifier를 학습하여 융합한다&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bagging
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Averaging the prediction over a collection of predictors generated from &lt;strong&gt;bootstrap samples&lt;/strong&gt; (both classification and regression)&lt;/p&gt;

        &lt;p&gt;bootstrap sample :trian data있으면 subset sampling&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;
            &lt;p&gt;각각 sampling으로부터 classifier 학습&lt;/p&gt;

            &lt;p&gt;Random하게 sampling하며 다양한 model&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Training&lt;/p&gt;
        &lt;ul&gt;
          &lt;li&gt;Given a set D of d tuples, at each iteration i, a training set $D_i$ of $d$ tuples is sampled with replacement from D (i.e. bootstrap)
            &lt;ul&gt;
              &lt;li&gt;bootstrap 방법 : sampling with replacement - 전체 dataset으로부터 sampling하여 modeling하고 다시 복원&lt;/li&gt;
              &lt;li&gt;각각의 data subset에 대하여 model을 만듬&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;average, Sum 은 같은 방식 : sum에서 classifier number만큼 나눠주면 average value&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;bootstrapping = original data로부터 sampling&lt;/li&gt;
      &lt;li&gt;aggregating = 그것들로부터 각각의 classifier를 만들어 병합하는 방법&lt;/li&gt;
      &lt;li&gt;Classification: classify an unknown sample X
        &lt;ul&gt;
          &lt;li&gt;Each classifier $M_i$ returns its class prediction&lt;/li&gt;
          &lt;li&gt;The bagged classifier $M^*$ counts the votes and assigns the class with the most votes to X
            &lt;ul&gt;
              &lt;li&gt;각 classifier가 sample에 대한 class 예측값을 계산하고, 그리고 최종 판단은 voting / sum/ 등 여러 방법을 사용할 수 있다.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Prediction:
        &lt;ul&gt;
          &lt;li&gt;can be applied to the prediction of continuous values by taking the average value of each prediction for a given test tuple&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Accuracy
        &lt;ul&gt;
          &lt;li&gt;
            &lt;p&gt;Often significantly better than a single classifier derived from&lt;/p&gt;

            &lt;p&gt;significantly better : 5 ~ 10% 상승&lt;/p&gt;

            &lt;ul&gt;
              &lt;li&gt;물론 model을 여러번 쓰고 연산량은 그만큼 증가&lt;/li&gt;
              &lt;li&gt;test stage : Test sample에서는 model들 다 유지해서 그만큼 분류 작업 수행 후 융합&lt;/li&gt;
            &lt;/ul&gt;

            &lt;p&gt;Train + test stage 연산량 증가&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;For noisy data: not considerably worse, more robust
            &lt;ul&gt;
              &lt;li&gt;noisy data : robust하게 됨 (boost sampling : Noisy data가 빠진 형태로 학습)&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Proved improved accuracy in prediction&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Requirement: need unstable classifier types
        &lt;ul&gt;
          &lt;li&gt;Unstablemeansasmallchangetothetrainingdatamayleadtomajor decision changes&lt;/li&gt;
          &lt;li&gt;requirement : unstable classifier&lt;/li&gt;
        &lt;/ul&gt;

        &lt;p&gt;Unstable : train data를 조금 바꿀 경우 model decision이 크게 바뀌는 model을 의미함&lt;/p&gt;

        &lt;p&gt;(Remind) Model이 바뀐 train data에 대해서 diverse한 error = variance가 커야 한다.&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;bagging의 관점에서는 var 큰게 좋다 (일반적으로는 별로 안 좋다)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Stability in Training
        &lt;ul&gt;
          &lt;li&gt;Training: construct classifier from&lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Stability: small changes on results in small changes on&lt;/p&gt;

            &lt;p&gt;Training : f를 d로부터 형성&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;Decision trees are a typical unstable classifier&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Boosting
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Weighted vote with a collection of classifiers that were trained sequentially from training sets given priority to instances &lt;strong&gt;wrongly classified&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;Boosting : 여러 단계를 거쳐 classifier 학습&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;이전 단계의 classifier의 오답에 초점을 맞춘다.&lt;/li&gt;
        &lt;/ul&gt;

        &lt;p&gt;오류가 나오는 data들을 모아 다음 stage에서 초점을 맞추어 학습하여 융합한다&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;Incrementally create models selectively using training examples based on some distribution.
        &lt;ul&gt;
          &lt;li&gt;Incrementally하게 sample이 subset으로 selection된 확률값을 가지고 있음&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;How boosting works?
        &lt;ul&gt;
          &lt;li&gt;Weights are assigned to each training example&lt;/li&gt;
          &lt;li&gt;A series of k classifiers is iteratively learned&lt;/li&gt;
          &lt;li&gt;After a classifier $M_i$  is learned, the weights are updated to allow the subsequent classifier, $M_i +1$, to pay more attention to the training examples that were misclassified by&lt;/li&gt;
          &lt;li&gt;The final $M^*$ combines the votes of each individual classifier, where the weight of each classifier’s vote is a function of its accuracy 𝒊&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;각 sample들이 weight를 가지고 있음.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;그리고 우리는 k개의 classifier를 학습할 것&lt;/p&gt;

    &lt;p&gt;그런데 M_i가 학습 된 다음, classifier가 학습된 이후에는&lt;/p&gt;

    &lt;p&gt;weight을 update하는데 앞 단계에서 학습된 model들이 misclassified 에 더 주의를 기울인다 (weight를 올린다)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;blockquote&gt;
          &lt;p&gt;higher chance to be selected&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;즉 misclassified sample들이 점점 그 쪽으로 select되면서 hard sample들이 점점 추가되어 뒤쪽 classifier 학습&lt;/p&gt;

    &lt;p&gt;1~k개 classifier를 조합하여 m*&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;weighted combination : weight는 accuracy에 비례&lt;/li&gt;
      &lt;li&gt;boosting 기본 아이디어 : disagreement, hard sample&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Hard sample에 초점 맞추는 방법 : classifier 1번을 만들고 misclassified에 대해서 classifier 2번을 만들고 m1, m2가 다른 결정을 내리는 sample에 대해서 classifier 3번을 만들어 test sample이 들어오면 m1, m2를 돌려 최종 결과로 사용하고 두 분류기 결과가 다르면 m3를 활용하여 결과 도출&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Boosting - Adaboost&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Using Different Data Distribution
        &lt;ul&gt;
          &lt;li&gt;Start with uniform weighting&lt;/li&gt;
          &lt;li&gt;misclassified sample의 weight 증가&lt;/li&gt;
          &lt;li&gt;well classified sample에 대해서는 weight 감소&lt;/li&gt;
          &lt;li&gt;During each step of learning
            &lt;ul&gt;
              &lt;li&gt;Increase weights of the examples which are not correctly learned by the weak learner&lt;/li&gt;
              &lt;li&gt;Decrease weights of the examples which are correctly learned by the weak learner&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Idea
        &lt;ul&gt;
          &lt;li&gt;Focus on difficult examples which are not correctly classified in the previous steps&lt;/li&gt;
          &lt;li&gt;difficult example에 더 주의를 기울인 케이스&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Weighted Voting
        &lt;ul&gt;
          &lt;li&gt;Construct strong classifier by weighted voting of the weak classifiers&lt;/li&gt;
          &lt;li&gt;&lt;/li&gt;
          &lt;li&gt;strong classifier 만들 때 weak classifier 에 weight를 주고 weighted voting / weighted sum 등 일반적인 ensemble 방법 적용&lt;/li&gt;
          &lt;li&gt;weak classifier를 많이 첨가하여 combined classifier의 accuracy 증가 (strong classifier/learner)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Idea
        &lt;ul&gt;
          &lt;li&gt;Better weak classifier gets a larger weight&lt;/li&gt;
          &lt;li&gt;Iteratively add weak classifiers
            &lt;ul&gt;
              &lt;li&gt;Increase accuracy of the combined classifier through minimization of a cost function Ensemble Learning Adaboost Introduction to Machine Learning Page 17&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Adaboost vs Boosting&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Differences with Bagging:bagging과의 차이점
        &lt;ul&gt;
          &lt;li&gt;Models are built sequentially on modified versions of the data
            &lt;ul&gt;
              &lt;li&gt;random하게 sample된게 아니라 weight에 의해 sample된 data에 의해 학습&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;The predictions of the models are combined through a weighted sum/vote
            &lt;ul&gt;
              &lt;li&gt;점점 hard sample에 대해 학습되니 easy sample / hard sample의 classifier가 동일한 weight를 가질 수 없음 : bagging은 동일한 조건으로 randomly sampling (no weight)
                &lt;ul&gt;
                  &lt;li&gt;거의 동등한 조건이기 때문에 weight를 주지 않음&lt;/li&gt;
                  &lt;li&gt;boosting의 경우 misclassified에 대해 overfitting (hard sample이 증가하는 방향으로 weight update)-&amp;gt; ensemble하면 점점 hard sample 추가되며 overfitting 위험&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Random Forest&lt;/p&gt;

    &lt;p&gt;RandomForest:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Averaging the prediction over a collection of trees constructed using a &lt;strong&gt;randomly selected subset of features&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;tree를 randomly생성하여 randomly select해서 만든다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Random Forest: A variation of the bagging algorithm - bagging처럼 여러 개 ensemble&lt;/li&gt;
      &lt;li&gt;Created from individual decision trees
        &lt;ul&gt;
          &lt;li&gt;Diversity is guaranteed by selecting randomly at each split, a subset of the original features during the process of tree generation&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;tree 구조 : unstable 구조 → diversity가 guaranteed됨 automatically&lt;/strong&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;R.F 활용
        &lt;ul&gt;
          &lt;li&gt;During classification, each tree votes and the most popular class is returned
            &lt;ul&gt;
              &lt;li&gt;classification에서는 : vote를 가장 많이 받은 class가 최종 결과 decision&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;During regression, the result is the averaged prediction of all generated trees
            &lt;ul&gt;
              &lt;li&gt;regression에서는 :각 tree들이 result을 만드는데 이를 average 취하면 random forest result&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;random selection이 : feature selection / data sampling&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Heterogeneous ensembles:
    &lt;ul&gt;
      &lt;li&gt;Combining a set of &lt;strong&gt;heterogeneous predictors&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;NN + SVM + DT 등 융합&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Model Selection&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Golden rule: there is no algorithm that is the best one for all the problems
        &lt;ul&gt;
          &lt;li&gt;하나의 특정 알고리즘이 다른 모든 problem 모두를 해결하지는 않는다&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Typically, two approaches (or both) can be adopted:
        &lt;ul&gt;
          &lt;li&gt;To choose the algorithm more suitable for the given problem&lt;/li&gt;
          &lt;li&gt;To adapt the given data for the intended algorithm (using pre-processing, for instance)
            &lt;ul&gt;
              &lt;li&gt;주어진 data를 잘 tuning할 수 있도록 한다 for 사용하고자 하는 algorithm (preprocessing)&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The concept of “good algorithm” depends on the problem:
        &lt;ul&gt;
          &lt;li&gt;good algorithm : prob by prob&lt;/li&gt;
          &lt;li&gt;Explainability : model이 어떤 판단을 내린다면 판단의 정확도도 중요하나 그 결정의 이유도 중요함 : bayesian, decision tree는 쉽게 설명할 수 있는데 그 외에는 설명이 쉽지 않음&lt;/li&gt;
          &lt;li&gt;분류 관리 문제에 있어서는 이송 시간 예측 정확도가 가장 중요한 선택요인&lt;/li&gt;
          &lt;li&gt;For a doctor, the interpretation of the model can be a major criterion for the selection of the model (decision trees and Bayesian networks are very appreciated)&lt;/li&gt;
          &lt;li&gt;For logistics, the accuracy of travel time prediction is, typically, the most important selection criterion.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Statistical Validation&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;12-clustering&quot;&gt;12. Clustering&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/12-Clustering-68dc57c409b94b27afd366a66f7d672c&quot;&gt;12. Clustering&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;K-means clustering&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;An iterative clustering algorithm&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Initialize: Pick K random points as cluster centers&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;cluster의 개수 가정 : k개의 cluster = k개의 random point 초깃값 assume&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;Alternate:
        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;Assign data points to closest cluster center&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;k개의 pt에 대해서 각각의 data들을 가장 가까운 cluster center에 할당하고&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Change the cluster center to the average of its assigned points&lt;/p&gt;

            &lt;ol&gt;
              &lt;li&gt;Cluster center update : 각 iteration마다 update&lt;/li&gt;
            &lt;/ol&gt;

            &lt;ul&gt;
              &lt;li&gt;더 이상 update되지 않는 시점에서 cluster 중단&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Stop when no point assignments change&lt;/p&gt;

        &lt;p&gt;초깃값에 대해서 (initial center point) partition 나눔&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;그 data들의 center mean을 구해서 이로 center를 update함&lt;/li&gt;
          &lt;li&gt;이를 기반으로 update된 값들의 member들을 재할당&lt;/li&gt;
          &lt;li&gt;반복하다 보면 각각의 cluster의 center로 이동하게 됨&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;K-means clustering properties&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;## Properties of K-means algorithm (convergence)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Objective&lt;/p&gt;

        &lt;p&gt;모든 sample들에 대해서 center값을 계산 :sample들의 center 값으로부터의 거리 제곱의 합이
  k개의 cluster에 대해서 최소&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;cluster center에 잘 일치하게 되면, 해당 cluster에 속하는 sample들이 그 cluster center 와 이루는 거리의 합이 모든 cluster에 대해서 minimum이 됨&lt;/li&gt;
        &lt;/ul&gt;

\[\min_{\mu} \min_{c}  \Sigma_{i=1}^{k} {\Sigma_{x\in C_i}|x-\mu_i|^2}\]
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Fix $\mu$, optimize $C$&lt;/p&gt;

        &lt;p&gt;iteration작업- partition update&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;mu 고정, C optimize&lt;/li&gt;
          &lt;li&gt;center까지의 모든 sample들의 거리를 최소화하는 작업&lt;/li&gt;
        &lt;/ul&gt;

\[\min_{c}  \Sigma_{i=1}^{k} {\Sigma_{x\in C_i}|x-\mu_i|^2} = \min_{c}  \Sigma_{i=1}^{n} {|x_i-\mu_{xi}|^2}\]
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Fix $\mu$, optimize $\mu$&lt;/p&gt;

        &lt;p&gt;Partition update후 center값 update&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;각 cluster sample들에서 sample들로부터 center 거리를 최소화시킬 수 있도록 평균값 설정&lt;/li&gt;
          &lt;li&gt;mu에 대해서 미분하고ㅡ 이를 0으로 setting하면 평균값이라는 것은 각 cluster에 속한 sample들의 값의 합을 그 cluster에 속한 sample들의 값의 합을 그 cluster에 속한 sample들의 개수로 나눈 값이 그 center 값 : center mean&lt;/li&gt;
        &lt;/ul&gt;

\[\min_{\mu} \Sigma_{i=1}^{k} {\Sigma_{x\in C_i}|x-\mu_i|^2}\]

        &lt;ul&gt;
          &lt;li&gt;Take partial derivative with respect to $\mu_i$and sets to zero, we have $\mu_i = \frac 1 {C_i} \Sigma_{x\in C_i} x$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;K-means takes an alternating optimization, each step is guaranteed to decrease the objective – thus guaranteed to converge&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Agglomerative clustering&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Agglomerative clustering
        &lt;ul&gt;
          &lt;li&gt;First merge very similar instances
            &lt;ul&gt;
              &lt;li&gt;비슷한 data끼리 grouping : 처음에는 모든 data pt가 개별 cluster로 되고 점차 하나의 group이 될 때까지 group화&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Incrementally build larger clusters out of smaller clusters
            &lt;ul&gt;
              &lt;li&gt;가장 similarity가 큰 data끼리 group화함 :
                &lt;ul&gt;
                  &lt;li&gt;1,3을 하나의 group으로 묶고 2, 5 group으로 묶이게 되면 1st-2nd group간 거리는 가장 가까운 거리로 할 것인지 (1-2) 먼 거리로 할 것인지 (3-5) 평균으로 할 것인지에 따라, similarity 판단 기준에 따라 clustering이 다르게 됨&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Algorithm:
        &lt;ul&gt;
          &lt;li&gt;Maintain a set of clusters, Initially, each instance in its own cluster&lt;/li&gt;
          &lt;li&gt;Repeat:
            &lt;ul&gt;
              &lt;li&gt;Pick the two closest clusters&lt;/li&gt;
              &lt;li&gt;Merge them into a new cluster&lt;/li&gt;
              &lt;li&gt;Stop when there’s only one cluster left&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Produces not one cluster, but a family of clusters represented by a dendrogram&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;Final/12/Untitled.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;How should we define “close” for clusters with multiple elements?
        &lt;ul&gt;
          &lt;li&gt;similarity를 어떻게 판단할 것인가  =(distance를 어떻게 계산할 것인가)&lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;closest / Farthest / Average → cluster가 달라지게 됨&lt;/p&gt;

            &lt;p&gt;&lt;img src=&quot;Final/12/Untitled_1.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Many options:
        &lt;ul&gt;
          &lt;li&gt;Closest pair (single-link clustering)&lt;/li&gt;
          &lt;li&gt;Farthest pair (complete-link clustering)&lt;/li&gt;
          &lt;li&gt;Average of all pairs&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Different choices create different clustering behaviors&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Agglomerative clustering - hierarchical clustering : strength, complexity&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;## Strengths of Hierarchical Clustering&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;No assumptions on the number of clusters
        &lt;ul&gt;
          &lt;li&gt;cluster 개수 가정하고 수행하게 됨&lt;/li&gt;
          &lt;li&gt;단) cluster 개수 잘못 예측하면 algorithm 좋지 않은 결과를 낼 것&lt;/li&gt;
          &lt;li&gt;Any desired number of clusters can be obtained by ‘cutting’ the dendogram at the proper level&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Hierarchical clusterings may correspond to meaningful taxonomies
        &lt;ul&gt;
          &lt;li&gt;cluster 몇 개인지 모르는 상태에서 clustering&lt;/li&gt;
          &lt;li&gt;clustering : dendrogram 그려서 duration 긴 구간을 판단하여 cluster 개수 결정 / 적절한 상태에서 dendrogram cutting&lt;/li&gt;
          &lt;li&gt;대칭적 분류 : phylogeny. Catalog&lt;/li&gt;
          &lt;li&gt;Example in biological sciences (e.g., phylogeny reconstruction, etc), web (e.g., product catalogs), etc.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;## Complexity of hierarchical clustering&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Distance matrix is used for deciding which clusters to merge/split
        &lt;ul&gt;
          &lt;li&gt;distance &amp;lt;-&amp;gt; proximity&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;data point n개가 있다면, n by n개 distance를 모두 계산함 : n^2 연산
        &lt;ul&gt;
          &lt;li&gt;At least quadratic in the number of data points
            &lt;ul&gt;
              &lt;li&gt;Not usable for large datasets&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;group화가 진행되며 Matrix 크기가 점차 줄어들게 되어 최종적으로 하나의 block만 남게 됨&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Closest pair (single-link clustering)&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Each cluster is a set of points&lt;/li&gt;
      &lt;li&gt;How do we define distance between two sets of points&lt;/li&gt;
      &lt;li&gt;Lots of alternatives&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Not an easy task&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;Single-link distance between clusters Ci and Cj is the minimum distance between any object in Ci and any object in Cj
        &lt;ul&gt;
          &lt;li&gt;Single link : shortest distance&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;The distance is defined by the two most similar objects&lt;/p&gt;

\[D _{s l} ( C _i , C _j ) = \min _{x , y} (d ( x , y )| x \in C _i , y \in C _j )\]
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;# Single-link clustering: example&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Determined by one pair of points, i.e., by one link in the proximity graph&lt;/p&gt;

        &lt;p&gt;Diagonal value를 보고 판단할 수 있음&lt;/p&gt;

        &lt;p&gt;같은 요소에 대한 값이 1-&amp;gt; similarity&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;data 분포에 의하면 1,2,3,4,5 clustering&lt;/li&gt;
          &lt;li&gt;symmetric : 대각선 아래 부분은 크게 의미가 없음&lt;/li&gt;
          &lt;li&gt;값이 높은 순대로 먼저 cluster를 형성하게 됨&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Farthest pair (complete-link clustering)&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;## Distance between two clusters&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Complete-link distance between clusters Ci and Cj is the maximum distance between any object in Ci and any object in Cj&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;The distance is defined by the two most dissimilar objects&lt;/p&gt;

        &lt;p&gt;가장 먼 거리의 simple pair에 대해서 data를 clustering (Most dissimilar)&lt;/p&gt;

        &lt;p&gt;Most similar&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

\[D _{s l} ( C _i , C _j ) = \max _{x , y} (d ( x , y )| x \in C _i , y \in C _j )\]

    &lt;p&gt;## Complete-link clustering: example&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Distance between clusters is determined by the two most distant points in the different clusters&lt;/p&gt;

        &lt;p&gt;거리 판단한 이후(차이-dissimilar)
  cluster끼리 병합할 때는 가장 가까운 것 끼리 (동일)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Average of all pairs&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;# Distance between two clusters&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Group average distance between clusters Ci and Cj is the average distance between any object in Ci and any object in Cj
        &lt;ul&gt;
          &lt;li&gt;전체 data pair의 average 이용&lt;/li&gt;
          &lt;li&gt;I cluster , j cluster : 평균 distance 계산한 후 shortest path 결정&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

\[D_{avg} (C_i, C_j) = \frac 1 {|C_i| \times |C_j| } \Sigma_{x\in C_i, y \in C_j} d(x,y)\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;statistical validation&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;13-dimensionality-reduction&quot;&gt;13. Dimensionality Reduction&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/13-Dimensionality-Reduction-c21c309ea0724478ba6924d6ce913f81&quot;&gt;13. Dimensionality Reduction &lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Goal of Dimensionality Reduction&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Visualization 용이 : 3dim 이하로 Reduct → visualize easy&lt;/p&gt;

    &lt;p&gt;Performance 향상 : easy to handle data&lt;/p&gt;

    &lt;p&gt;Computation cost 감소&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Data Compression&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;(필요성) Too high dimension of detection windows : computationally intensive&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Cannot handle them : too high dimensionality → pixel diminish시켜 사용&lt;/li&gt;
      &lt;li&gt;Curse of dimensionality : 너무 Data dimension이 높아지면 accuracy가 떨어지는 현상
        &lt;ul&gt;
          &lt;li&gt;boolean이 아닌 Observed value (measured) : boolean이 아니라 acc 떨어질 수 있음&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Feature Extraction&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;(과정) very high-dim raw data → feature extraction dimension reduction → classifier&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;dimension reduction&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;axis에 projection한 형태로 reduct dimension&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;왜 좌표축을 rotate한 것이라고 표현하는가? (multivariate dataset into new config)&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;simplify data&lt;/li&gt;
      &lt;li&gt;easy to look at rel. between variable - patterns of units&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;PCA process&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;[goal] find k-dim projection  which preserves best variance&lt;/li&gt;
    &lt;/ul&gt;

    &lt;ol&gt;
      &lt;li&gt;compute mean vector $\mu$ and covariance matrix $\Sigma$ of original data
        &lt;ol&gt;
          &lt;li&gt;D-dim data로부터 Mean, Covariance 구함&lt;/li&gt;
          &lt;li&gt;$X = [X1, X2, … , Xn]$&lt;/li&gt;
          &lt;li&gt;(mean centered X) $X_{\mu_0} = X-\mu = [X1-\mu, X2-\mu, … , Xn-\mu]$&lt;/li&gt;
          &lt;li&gt;$\Sigma = X_{\mu_0} X_{\mu_0} ^T = \frac 1 n  \Sigma (X_i - \mu)(X_i - \mu)^T$&lt;/li&gt;
          &lt;li&gt;$S = \Sigma(X_i - \mu)(X_i - \mu)^T$&lt;/li&gt;
          &lt;li&gt;$\Sigma v = \lambda v$&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;Compute eigenvectors and eigenvalues of $\Sigma$&lt;/li&gt;
      &lt;li&gt;Select top k eigenvectors
        &lt;ol&gt;
          &lt;li&gt;Top k개 eigenvalue에 대응하눈 eigenvector 구함&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;Project points onto subspace spanned by them
        &lt;ol&gt;
          &lt;li&gt;$y = A(x-\mu)$&lt;/li&gt;
          &lt;li&gt;where y is the new data, x is the original data, and the rows of A are the eigenvectors&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;When we said the eigenvector as&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;&lt;img src=&quot;Final/13/Untitled.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;in the previous lecture, $A$ is $V^T$ (k vectors, $v_1$ … $v_k$)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;PCA  - Eigenvalue, vector의 의미?&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;eigenvector :PCA분석을 했을 때 data가 가장 크게 분산된 방향으로 표현하는 방향벡터이고 그 정도를 가리키는 것은 eigenvalue.&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;smaller eigenvalue 순 - eigenvector 정렬 → 크게 var되는 방향으로 정렬&lt;/li&gt;
      &lt;li&gt;가장 큰 eigenvector로 하여 좌표축을 변환해도 data들이 잘 표현이 됨
        &lt;ul&gt;
          &lt;li&gt;data를 Eigenvector에 Projection : 새로운 좌표값으로 나오게 됨&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Covariance matrix :
        &lt;ul&gt;
          &lt;li&gt;d dimension data로부터 d개의 eigenvector&lt;/li&gt;
          &lt;li&gt;2차원 data로부터 2개의 eigenvector, eigenvalue&lt;/li&gt;
          &lt;li&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;The eigenvectors of $\Sigma$ define a new coordinate system 
  (새로운 coordinate system으로 적용)&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;Eigenvector with largest eigenvalue captures the &lt;strong&gt;most variation&lt;/strong&gt; among data X
            &lt;ul&gt;
              &lt;li&gt;&lt;strong&gt;eigenvector :PCA분석을 했을 때 data가 가장 크게 분산된 방향으로 표현하는 방향벡터이고 그 정도를 가리키는 것은 eigenvalue.&lt;/strong&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Eigenvector with smallest eigenvalue has least variation
            &lt;ul&gt;
              &lt;li&gt;
                &lt;p&gt;&lt;strong&gt;가장 작은 eigenvalue에 대응되는 Eigenvector는 분산이 제일 작다.&lt;/strong&gt;
  &lt;img src=&quot;Final/13/Untitled_1.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
              &lt;/li&gt;
              &lt;li&gt;
                &lt;p&gt;v1이라는 axis로 투영한다면 Data가 가장 잘 분산되는 최적의 방향이다 → 최대 분산 방향으로 압축되면 제일 잘 분산되는 방향으로 data의 차원을 축소시키는 것이기에 원본 Data 정보 잘 반영&lt;/p&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Dimension reduction에 따른 원본 data의 information loss정도
            &lt;ul&gt;
              &lt;li&gt;1Dim 압축 : 가장 최소 eigenvector, 2Dim 압축 : 두 번째eigenvector&lt;/li&gt;
              &lt;li&gt;d dim에 대해서 D개를 모두 사용 → 어떠한 손실도 없이 원본 Data 수행 가능
                &lt;ol&gt;
                  &lt;li&gt;표현된 Data는 동일하지만 PCA 분석이 되어 있기에 Dimension을 줄이면 됨&lt;/li&gt;
                  &lt;li&gt;corelation이 감소된 형태로 좌표축 정립 : x1의 값이 변화할 때 x2의 값이 변화되는 정도&lt;/li&gt;
                &lt;/ol&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;LDA&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;LDA : labeled&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;PCA는 unsupervised learning에서 clustering, dimensionality reduction
        &lt;ul&gt;
          &lt;li&gt;Not for classification&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;LDA는 supervised learning, dimensionality reduction
        &lt;ul&gt;
          &lt;li&gt;Classification을 위해 쓸 수 있으나 label 사용해서 unsupervised라고 볼 수는 없음&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;LDA의 필요성&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;PCA maximizes the total scatter → PCA does not consider class information
        &lt;ul&gt;
          &lt;li&gt;PCA 분석 하면 data의 최대 분산 방향으로 eigenvector가 얻어지게 됨&lt;/li&gt;
          &lt;li&gt;최대 분산 방향으로 data 투영하게 되면 data label 구분이 없어짐 (섞임)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;PCA vs. LDA&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;PCA maximizes projected total scatter
  label이 없으니 전체 data에 대해서 covariance를 구함&lt;/p&gt;

\[\Sigma = \frac 1 N \Sigma_{i=1}^{N}{(x_i -\mu)(x_i -\mu)^T}\]

\[\Sigma v = \lambda v\]
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;LDA maximizes ratio of projected between-class to projected within-class scatter&lt;/p&gt;
        &lt;ul&gt;
          &lt;li&gt;LDA: 각 class별로 covariance matrix를 구함
            &lt;ul&gt;
              &lt;li&gt;within class scatter&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Eigen-decomposition: Sigma value가 최대화되는 방향 :
            &lt;ul&gt;
              &lt;li&gt;pca : covariance 최대화&lt;/li&gt;
              &lt;li&gt;lda : $\Sigma_b$ 최대화, $\Sigma_w$ 최소화&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;cluser의 분산이 각각 cluster 내부에서는 cov가 최소
  서로 다른 class 간에는 cov 최대의 방향&lt;/li&gt;
        &lt;/ul&gt;

\[\Sigma_w = \Sigma_{j=1}^{c}\frac 1 {N_c} \Sigma_{i=1}^{N_c}{(x_i -\mu_c)(x_i -\mu_c)^T}\]

\[\Sigma_c = \frac 1 {c} \Sigma_{i=1}^{c}{(\mu_c-\mu)(\mu_c-\mu)^T}\]

\[\frac{\Sigma_b}{\Sigma_w}v = \lambda v\]
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;## PCA vs. LDA (for reference)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;eigenvector PCA = var 최대 방향으로 vector를 구함
        &lt;ul&gt;
          &lt;li&gt;원래 vector를 transformation하여 var이 최대화되도록&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;$z = w^Tx$&lt;/li&gt;
      &lt;li&gt;
        &lt;table&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;Maximize $&lt;/td&gt;
              &lt;td&gt; &lt;/td&gt;
              &lt;td&gt;z&lt;/td&gt;
              &lt;td&gt; &lt;/td&gt;
              &lt;td&gt;= z^Tz$  , while $&lt;/td&gt;
              &lt;td&gt; &lt;/td&gt;
              &lt;td&gt;w&lt;/td&gt;
              &lt;td&gt; &lt;/td&gt;
              &lt;td&gt;= w^Tw = 1$&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
        &lt;ul&gt;
          &lt;li&gt;
            &lt;table&gt;
              &lt;tbody&gt;
                &lt;tr&gt;
                  &lt;td&gt;z를 maximize =&lt;/td&gt;
                  &lt;td&gt;z&lt;/td&gt;
                  &lt;td&gt;최대 = z^Tz 최대화&lt;/td&gt;
                &lt;/tr&gt;
              &lt;/tbody&gt;
            &lt;/table&gt;
          &lt;/li&gt;
          &lt;li&gt;앞에서 이 weight matrix는 norm =1이 되는 방향으료 표준화해놓고 z 최대화하는 방향으로 eigenvalue vector 구함 → $z^Tz$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;$z^Tz = w^Tx(w^Tx)^T = w^Tx x^Tw = w^T \Sigma w$&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$\max_w{(z^Tz - \lambda(w^T w-1))} = \max_w{(w^T \Sigma w - \lambda(w^Tw-1))}$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;Take derivative w.r.t. $w$&lt;/li&gt;
      &lt;li&gt;$2 \Sigma w - 2 \lambda w = 0$&lt;/li&gt;
      &lt;li&gt;$\Sigma w = \lambda w$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Eigenface&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;x new = sigma wi xi&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;data의 Weighted sum으로 나온다 : linear data&lt;/li&gt;
      &lt;li&gt;whoe data to DNN → 더 효과적이더라&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;14-rl&quot;&gt;14. RL&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/14-Reinforcement-Learning-0fffcc707ee9413a90b11ae19e6be037&quot;&gt;14. Reinforcement Learning&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Characteristics of Reinforcement Learning&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Feedback is delayed, not instantaneous&lt;/li&gt;
      &lt;li&gt;Time really matters (sequential, non i.i.d. data)
        &lt;ul&gt;
          &lt;li&gt;시간이 중요한 요소 중 하나&lt;/li&gt;
          &lt;li&gt;sequential : 전반의 선택이 후반의 선택에 영향
  iid = independent identically distributed - 상호 연관&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Agent’s actions affect the subsequent data it receives
        &lt;ul&gt;
          &lt;li&gt;agent action이 이후 data에 영향을 미친다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Goal: select actions to maximize total future reward&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;일련의 행동에 따른 reward가 최대가 되도록 학습한다&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Diff. with supervised, unsupervised learning&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;What makes reinforcement learning different from other machine learning paradigms?&lt;/li&gt;
      &lt;li&gt;supervised l. vs unsupervised l. vs. RL
        &lt;ul&gt;
          &lt;li&gt;supervised : label + data&lt;/li&gt;
          &lt;li&gt;Unsupervised : just use given data&lt;/li&gt;
          &lt;li&gt;RL : data + reward - Reward에 해당하는 추가적인 input이 존재함&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;→ There is no supervisor, only a reward signal&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rewards&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Indicate show well agent is doing at step t &amp;amp; The agent’s job is to maximize cumulative reward&lt;/li&gt;
      &lt;li&gt;각각의 시간에 얼마나 잘 행동 했는지 보고 reward 최대화되는 방향으로 행동하도록 학습&lt;/li&gt;
      &lt;li&gt;Reinforcementlearning is based on the reward hypothesis
        &lt;ul&gt;
          &lt;li&gt;reward = 사람이 만든 기준
  ex. Atari game : target 별 최대한의 점수를 학습할 수 있도록 학습이 되기도 함. 점수가 많은 쪽을 더 빨리 얻을 수 있도록 학습시키는 양상이 생길 수 있다,&lt;/li&gt;
          &lt;li&gt;Reward hypothesis: all goals can be described by the m&lt;strong&gt;aximization of expected cumulative reward&lt;/strong&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Reward may be delayed reward는 delay를 수반하여 주어질 수 있다&lt;/li&gt;
      &lt;li&gt;현재 action으로 인한 reward에 더 중점을 둘 것인지, 미래의 reward에 중점을 더 둘 것인지 : user setting할 수도 있고 학습 단계에서 어떻게 parameter를 설정했는지에 따라 / 학습이 잘 효과적으로 이루어질수 있는지를 고려하여 모수 조정
        &lt;ul&gt;
          &lt;li&gt;(greedy) 현재 reward에 초점을 맞추는 경우 - current reward&lt;/li&gt;
          &lt;li&gt;(optimal) 전체 reward에 초점을 맞추는 경우 - total reward
            &lt;ul&gt;
              &lt;li&gt;Itmay be better to sacrifice immediate reward to gain more long-term reward (greedy optimal)&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;구성 of RL&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;At each stept the agent: agent가 주변을 관찰하고, reward를 받아 action을 취함
        &lt;ul&gt;
          &lt;li&gt;Executes action At&lt;/li&gt;
          &lt;li&gt;Receives observation Ot&lt;/li&gt;
          &lt;li&gt;Receives scalar reward Rt&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;An RL agent may include one or more of these components:
        &lt;ul&gt;
          &lt;li&gt;Policy: agent’s behavior function 행동 정의&lt;/li&gt;
          &lt;li&gt;Value function: how good is each state and/or action 얼마나 좋은가&lt;/li&gt;
          &lt;li&gt;Model: agent’s representation of the environment  학습 모델&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&amp;lt;agent, environment의 상호작용&amp;gt;
  agent는 action을 취하고 state에 따라 Reward를 받게 됨
  env는 action을 받아들여서 agent에게 주고 변환된 statement를 agent에게 줌&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;t타임으로 이루어지는 요소들&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Bellman Eq&lt;/strong&gt;&lt;/p&gt;

\[V(s) = max_a(R(s,a) + \gamma V(s&apos;))\]

    &lt;ul&gt;
      &lt;li&gt;$R(s,a)$ : reward: state에서 취한 action에 따른 reward&lt;/li&gt;
      &lt;li&gt;$V(s)$ : is the value function - value function:전체 reward 를 어떻게 표현할 것인가&lt;/li&gt;
      &lt;li&gt;$\gamma$ : is the discounting factor
        &lt;ul&gt;
          &lt;li&gt;현재-미래 reward중 어느 것에 초점을 맞출 것인지 중요도 맞추는 상수&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;$s’$ : is the next state agent can go from
        &lt;ul&gt;
          &lt;li&gt;s : 현재 state, s’ : next state&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

\[V(s) = max_a(R(s,a) + \gamma V(s&apos;))\]

    &lt;ul&gt;
      &lt;li&gt;By calculating V(s) for all states
        &lt;ul&gt;
          &lt;li&gt;Agent can move to the state with larger state value&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;임의의 출발점에서 state function 커지는 쪽으로 action을 취하면 된다
  → equation을 이용해서 value funcition을 구한후 최적의 path를 구할 수 있다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sequential Decision Making&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;현재의 action이 다음 턴 action에 영향을 미치는데, 오랜 turn에 대해 영향을 끼칠수도 있음.&lt;/li&gt;
      &lt;li&gt;Actions may have long term consequences
        &lt;ul&gt;
          &lt;li&gt;state가 있고 action을 취해서 s1-(a1)-&amp;gt;s2-(a2)-&amp;gt;s3&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>KyuHwan Shim</name><email>skh7343@cnsh.hs.kr</email></author><category term="ml" /><category term="ML" /><category term="AI" /><category term="Lecture" /><summary type="html">ML repkg</summary></entry><entry xml:lang="en"><title type="html">Reinforcement Learning (Chapter 14)</title><link href="http://localhost:4000/blog/ML-14-RL/" rel="alternate" type="text/html" title="Reinforcement Learning (Chapter 14)" /><published>2022-06-14T12:26:09+09:00</published><updated>2022-06-14T12:26:09+09:00</updated><id>http://localhost:4000/blog/ML-14-RL</id><content type="html" xml:base="http://localhost:4000/blog/ML-14-RL/">&lt;h1 id=&quot;14-reinforcement-learning&quot;&gt;14. Reinforcement Learning&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Sutton RL&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;characteristics-of-reinforcement-learning&quot;&gt;Characteristics of Reinforcement Learning&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;14/Untitled.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What makes reinforcement learning different from other machine learning paradigms?
    &lt;ul&gt;
      &lt;li&gt;supervised l. vs unsupervised l. vs. RL
        &lt;ul&gt;
          &lt;li&gt;supervised : label + data&lt;/li&gt;
          &lt;li&gt;Unsupervised : just use given data&lt;/li&gt;
          &lt;li&gt;RL : data + reward - Reward에 해당하는 추가적인 input이 존재함&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;→ There is no supervisor, only a reward signal&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Feedback is delayed, not instantaneous&lt;/li&gt;
  &lt;li&gt;Time really matters (sequential, non i.i.d. data)
    &lt;ul&gt;
      &lt;li&gt;시간이 중요한 요소 중 하나&lt;/li&gt;
      &lt;li&gt;sequential : 전반의 선택이 후반의 선택에 영향
  iid = independent identically distributed - 상호 연관&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Agent’s actions affect the subsequent data it receives
    &lt;ul&gt;
      &lt;li&gt;agent action이 이후 data에 영향을 미친다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;examples-of-reinforcement-learning&quot;&gt;Examples of Reinforcement Learning&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Fly stunt manoeuvres in a helicopter
    &lt;ul&gt;
      &lt;li&gt;헬리콥터의 비행 모형&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Defeat the world champion at Backgammon
    &lt;ul&gt;
      &lt;li&gt;backgammon 게임에서의 응용&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Manageaninvestmentportfolio&lt;/li&gt;
  &lt;li&gt;Controlapowerstation&lt;/li&gt;
  &lt;li&gt;Makeahumanoidrobotwalk&lt;/li&gt;
  &lt;li&gt;Play many different Atari games better than humans
    &lt;ul&gt;
      &lt;li&gt;로봇, 투자 포트폴리오, 아타리 게임에서의 학습&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;14/Untitled_1.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;14/Untitled_2.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;rewards&quot;&gt;Rewards&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;A reward 𝒕 is a scalar feedback signal&lt;/li&gt;
  &lt;li&gt;Indicate show well agent is doing at step t &amp;amp; The agent’s job is to maximize cumulative reward&lt;/li&gt;
  &lt;li&gt;각각의 시간에 얼마나 잘 행동 했는지 보고 reward 최대화되는 방향으로 행동하도록 학습&lt;/li&gt;
  &lt;li&gt;Reinforcementlearning is based on the reward hypothesis
    &lt;ul&gt;
      &lt;li&gt;reward = 사람이 만든 기준
  ex. Atari game : target 별 최대한의 점수를 학습할 수 있도록 학습이 되기도 함. 점수가 많은 쪽을 더 빨리 얻을 수 있도록 학습시키는 양상이 생길 수 있다,&lt;/li&gt;
      &lt;li&gt;Reward hypothesis: all goals can be described by the m&lt;strong&gt;aximization of expected cumulative reward&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;examples-of-rewards&quot;&gt;Examples of Rewards&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Fly stunt manoeuvres in a helicopter&lt;/p&gt;

    &lt;p&gt;(+) : 원하는 궤적을 그리며 날아갈 때
  (-) : crashing 시 마이너스 ㅎ과&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;+ve reward for following desired trajectory&lt;/li&gt;
      &lt;li&gt;−ve reward for crashing&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Defeat the world champion at Backgammon
    &lt;ul&gt;
      &lt;li&gt;+/−ve reward for winning/losing a game&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Manage an investment portfolio&lt;/p&gt;

    &lt;p&gt;(+) : 원하는 이익
  (-) : 손실&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;+ve reward for each $ in bank&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Control a power station&lt;/p&gt;

    &lt;p&gt;(+) : 적절한 전력 공급
  (-) :&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;+ve reward for producing power&lt;/li&gt;
      &lt;li&gt;−ve reward for exceeding safety thresholds&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Make a humanoid robot walk&lt;/p&gt;

    &lt;p&gt;(+) : 주어진 환경에서 target 물질을 확보에서 mission 잘 수행
  (-) : 넘어짐&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;+ve reward for forward motion&lt;/li&gt;
      &lt;li&gt;−ve reward for falling over&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Play many different Atari games better than humans&lt;/p&gt;

    &lt;p&gt;(+) : 점수 얻거나
  (-) : 점수 잃거나
  -&amp;gt; 빠른 시간 안에 점수를 많이 얻는 방향으로&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;+/−ve reward for increasing/decreasing score&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;sequential-decision-making&quot;&gt;Sequential Decision Making&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;현재의 action이 다음 턴 action에 영향을 미치는데, 오랜 turn에 대해 영향을 끼칠수도 있음.&lt;/li&gt;
  &lt;li&gt;Goal: select actions to maximize total future reward
    &lt;ul&gt;
      &lt;li&gt;일련의 행동에 따른 reward가 최대가 되도록 학습한다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Actions may have long term consequences
    &lt;ul&gt;
      &lt;li&gt;state가 있고 action을 취해서 s1-(a1)-&amp;gt;s2-(a2)-&amp;gt;s3&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Reward may be delayed reward는 delay를 수반하여 주어질 수 있다&lt;/li&gt;
  &lt;li&gt;현재 action으로 인한 reward에 더 중점을 둘 것인지, 미래의 reward에 중점을 더 둘 것인지 : user setting할 수도 있고 학습 단계에서 어떻게 parameter를 설정했는지에 따라 / 학습이 잘 효과적으로 이루어질수 있는지를 고려하여 모수 조정
    &lt;ul&gt;
      &lt;li&gt;(greedy) 현재 reward에 초점을 맞추는 경우 - current reward&lt;/li&gt;
      &lt;li&gt;(optimal) 전체 reward에 초점을 맞추는 경우 - total reward
        &lt;ul&gt;
          &lt;li&gt;Itmay be better to sacrifice immediate reward to gain more long-term reward (greedy optimal)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Examples:&lt;/p&gt;

    &lt;p&gt;Ex.
  -투자 :당장은 손해가 나더라도 미래 시점에 수익
  -헬리콥터 주행 중 연료 주입 : crash하면 negative penalty하기에 현재로서는 reward 줄지만 optimal하게는 늘어나는 reward
  -체스에서 상대방 이동 : 본인 점수 취하는 것보다 상대방 방해가 전체적으로 더 이득일수도 있는 경우&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;A financial investment (may take months to be mature)&lt;/li&gt;
      &lt;li&gt;Refueling a helicopter (might prevent a crash in several hours)&lt;/li&gt;
      &lt;li&gt;Blocking opponent moves (might help winning chances many moves from now)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;agent-and-environment&quot;&gt;Agent and Environment&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;14/Untitled_3.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;At each stept the agent: agent가 주변을 관찰하고, reward를 받아 action을 취함
    &lt;ul&gt;
      &lt;li&gt;Executes action At&lt;/li&gt;
      &lt;li&gt;Receives observation Ot&lt;/li&gt;
      &lt;li&gt;Receives scalar reward Rt&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;14/Untitled_4.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The environment:
    &lt;ul&gt;
      &lt;li&gt;Receives action At&lt;/li&gt;
      &lt;li&gt;Emits observation Ot+1&lt;/li&gt;
      &lt;li&gt;Emits scalar reward Rt+1&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;t increments at env. step&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;lt;agent, environment의 상호작용&amp;gt;
agent는 action을 취하고 state에 따라 Reward를 받게 됨
env는 action을 받아들여서 agent에게 주고 변환된 statement를 agent에게 줌&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;t타임으로 이루어지는 요소들&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;action에 대해서 reward와 statement의 변화&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;14%20Reinforcement%20Learning%20e7de39297aeb4f5dab69c0ae48410224/IMG_0328.jpg&quot; alt=&quot;IMG_0328.jpg&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;major-components-of-an-rl-agent&quot;&gt;Major Components of an RL Agent&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;An RL agent may include one or more of these components:
    &lt;ul&gt;
      &lt;li&gt;Policy: agent’s behavior function 행동 정의&lt;/li&gt;
      &lt;li&gt;Value function: how good is each state and/or action 얼마나 좋은가&lt;/li&gt;
      &lt;li&gt;Model: agent’s representation of the environment  학습 모델&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;example---maze&quot;&gt;Example - Maze&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;14/Untitled_5.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Agent: explores environment and gets reward&lt;/li&gt;
  &lt;li&gt;Environment: agent 돌아다니는 환경 situation being explored by the agent&lt;/li&gt;
  &lt;li&gt;States: 위치 - positions/locations in the environment&lt;/li&gt;
  &lt;li&gt;Actions: 상하좌우 - allowed movements for the agent&lt;/li&gt;
  &lt;li&gt;Reward: what agent gets as it moves&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;14/Untitled_6.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;For example, bomb has reward -10, germ has reward 10, every other move has rewards -1&lt;/p&gt;

    &lt;p&gt;→ 불필요한 이동을 최소화시키기 위한 장치&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;s6 is blocked&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;14/Untitled_7.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;14/Untitled_8.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;bellman-equation&quot;&gt;Bellman equation&lt;/h1&gt;

\[V(s) = max_a(R(s,a) + \gamma V(s&apos;))\]

&lt;ul&gt;
  &lt;li&gt;$R(s,a)$ : reward: state에서 취한 action에 따른 reward&lt;/li&gt;
  &lt;li&gt;$V(s)$ : is the value function - value function:전체 reward 를 어떻게 표현할 것인가&lt;/li&gt;
  &lt;li&gt;$\gamma$ : is the discounting factor
    &lt;ul&gt;
      &lt;li&gt;현재-미래 reward중 어느 것에 초점을 맞출 것인지 중요도 맞추는 상수&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;$s’$ : is the next state agent can go from
    &lt;ul&gt;
      &lt;li&gt;s : 현재 state, s’ : next state&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bellman equation is used to calculate the value function 
→ 각 state에 대한 value function값으로 주어지게 됨 : 환경이 바뀌면 결과가 바뀌게 됨
R(s,a) : current reward
V(s’) : all futer reward&lt;/li&gt;
  &lt;li&gt;일반적인 규칙:폭탄,보석이 있고 env가 달려젔을 때 학습을 더 잘 할것인가-&amp;gt;bellman eq로 value fn으로 하는거는 환경 바뀌면 다시 적용해야 함&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;14/Untitled_9.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;T calculate V(1) ,consider a path s1- s2-s3-s7-s11-s12&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;s1에 대해 가장 큰 state function의 결과를 만드는 값을 취하도록 했다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;(assume $\gamma = 1$)
    &lt;ul&gt;
      &lt;li&gt;V(1) = R(s1, →) + V(2) = -1+V(2)&lt;/li&gt;
      &lt;li&gt;V(2) = R(s2, →) + V(3) = -1+V(3)&lt;/li&gt;
      &lt;li&gt;V(3) = R(s3, $\downarrow$) + V(7) = -1+V(7)&lt;/li&gt;
      &lt;li&gt;V(7) = R(s7, $\downarrow$) + V(11) = -1+V(11)&lt;/li&gt;
      &lt;li&gt;V(11) = R(s11, →) + V(12) = -1+V(12)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Since V(12) = 10
    &lt;ul&gt;
      &lt;li&gt;We can get V(11)=9, V(7)=8, V(3)=7, V(2) = 6, V(1) = 5&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;We can consider other path, s1-s2-s3-s4- s3-s7-s11-s12 to calculate V(1), in which case V(1) will be less than 5 14&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;14/Untitled_10.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

\[V(s) = max_a(R(s,a) + \gamma V(s&apos;))\]

&lt;ul&gt;
  &lt;li&gt;By calculating V(s) for all states
    &lt;ul&gt;
      &lt;li&gt;Agent can move to the state with larger state value&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;임의의 출발점에서 state function 커지는 쪽으로 action을 취하면 된다
→ equation을 이용해서 value funcition을 구한후 최적의 path를 구할 수 있다&lt;/li&gt;
&lt;/ul&gt;</content><author><name>KyuHwan Shim</name><email>skh7343@cnsh.hs.kr</email></author><category term="ml" /><category term="ML" /><category term="AI" /><category term="Lecture" /><summary type="html">Chap14.RL</summary></entry><entry xml:lang="en"><title type="html">Dimensionality Reduction (Chapter 13)</title><link href="http://localhost:4000/blog/ML-13-Dim/" rel="alternate" type="text/html" title="Dimensionality Reduction (Chapter 13)" /><published>2022-06-13T12:26:09+09:00</published><updated>2022-06-13T12:26:09+09:00</updated><id>http://localhost:4000/blog/ML-13-Dim</id><content type="html" xml:base="http://localhost:4000/blog/ML-13-Dim/">&lt;h1 id=&quot;13-dimensionality-reduction&quot;&gt;13. Dimensionality Reduction&lt;/h1&gt;

&lt;p&gt;Property 1: Goodfellow13, Bishop 12&lt;/p&gt;

&lt;h1 id=&quot;introduction-of-dimensionality-reduction&quot;&gt;Introduction of ‘Dimensionality Reduction’&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Unsupervised learning에서 중요한 dimensionality reduction
    &lt;ul&gt;
      &lt;li&gt;PCA, LDA 방식으로 수행 : eigen equation을 생성하여 covariance 생성
        &lt;ul&gt;
          &lt;li&gt;Covariance를 구하고 data var이 큰 방향으로 방향 vector를 구함 : eigenvector&lt;/li&gt;
          &lt;li&gt;분산 량 : eigenvalue&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;분산 큰 쪽으로 좌표축을 잡아 표현하는 방법 → dimension(data attribute) 줄이는 방법 (차원 축소)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;PCA Principal Component Analysis - label X
    &lt;ul&gt;
      &lt;li&gt;unsupervised learning&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;LDA Linear Discriminat Analysis - label O
    &lt;ul&gt;
      &lt;li&gt;supervised learning&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Semisupervised learning : unsupervised learning (부분적으로 Supervised)
    &lt;ul&gt;
      &lt;li&gt;물론 Clustering할 때도 일부 data에 label이 적용되어 알고 있을 수 있다 → label끼리 clustering할 때 정보를 활용하여 group화 할수 있음 (semi-supervised = unsupervised + supervised)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;dimensionality-reduction의-목적&quot;&gt;Dimensionality Reduction의 목적&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;1) Visualization 용이 : 3차원 이하로 Reduct하면 visualize 용이해짐&lt;/li&gt;
  &lt;li&gt;2) Performace 향상 : 데이터 다루기 쉬워져 performance (acc) 향상,&lt;/li&gt;
  &lt;li&gt;3) computation cost 감소 (time, computation 복잡도, memory)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PCA, LDA&lt;/p&gt;

&lt;h1 id=&quot;problems&quot;&gt;Problems&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Image에 있는 특정 Object검출 / 분류 / 영역 segmentation / caption / 임의의anomaly 검출 / Etc
    &lt;ul&gt;
      &lt;li&gt;image detection : window 를 지정하고 obj가 있는지 없는지 O,X로 검색&lt;/li&gt;
      &lt;li&gt;image scan하며 반복 : 전체 Image 크기의 일정 비율만큼 되는지까지 반복 - 1초에 10장 이상의 Image window, 얼굴 하나만 검출해도 각 window에 대해 계속 반복해야 하므로&lt;/li&gt;
      &lt;li&gt;computationally intensive → 연산량을 줄이기 위한 dimensionality reduction&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Object Detection: Many detection windows
    &lt;ul&gt;
      &lt;li&gt;Each window is very high dimensional data&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;→ computationally intensive (집약적)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;General framework&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;13/Untitled_1.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;고차원 Data&lt;/li&gt;
      &lt;li&gt;Feature extracted된 것은 일반적으로 reducted된 형태&lt;/li&gt;
      &lt;li&gt;Classifier / detection / segmentation&lt;/li&gt;
      &lt;li&gt;input data 가 image / signal/ video/ audio/ text이건 General 하게 사용가능&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;feature-extractiondimensionality-reduction-1&quot;&gt;Feature extraction/Dimensionality reduction 1&lt;/h1&gt;

&lt;h2 id=&quot;dimensionality-reduction의-목적-revisited&quot;&gt;Dimensionality Reduction의 목적 (Revisited)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;1) Visualization 용이 : 3차원 이하로 Reduct하면 visualize 용이해짐&lt;/li&gt;
  &lt;li&gt;2) Performace 향상 : 데이터 다루기 쉬워져 performance (acc) 향상,&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;3) computation cost 감소 (time, computation 복잡도, memory)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;It is impossible to process raw image data (pixels) directly
    &lt;ul&gt;
      &lt;li&gt;Too many of them (or data dimensionality too high)
        &lt;ul&gt;
          &lt;li&gt;data양이 너무 많음 : million cell을 넘어선 FHD, UHD 등 Resolution 이상 증가&lt;/li&gt;
          &lt;li&gt;e.g. 1M - 2M - 4M pixel 증가하기에 그대로 쓸 수는 없음 : 그대로 DNN에 넣어 처리하지는 않고 500*500 =250K정도로 줄여서 사용함&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Curse of dimensionality problem (차원의 저주)
        &lt;ul&gt;
          &lt;li&gt;Data dimension은 attribute로서 1d-2d-…-nd (data의 RGB, 길이, 크기 등) 많으면 많을수록 좋음 (더 많은 정보를 취합해서 처리할 수 있음)&lt;/li&gt;
          &lt;li&gt;그러나 너무 많아지면 오히려 accuracy가 떨어지게 되는 현상&lt;/li&gt;
          &lt;li&gt;RGB의 값과 무게 넓이를 측정하는데 Measured value 라는 것은 observed value로서 Boolean값이 아니기에 오차가 있을 수 있음.
            &lt;ul&gt;
              &lt;li&gt;(Boolean이 아닌, 오차가 포함된 observed value라면 값을 많이 추가하더라도 오히려 accuracy가 떨어지게 됨)&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Process the raw pixel to produce a smaller set of numbers which will capture most information contained in the original data – this is often called a feature vector
    &lt;ul&gt;
      &lt;li&gt;Raw data 원본 data를 처리하여 smaller set으로 만듬&lt;/li&gt;
      &lt;li&gt;d차원에서 임의로 10개 뽑아 정리하는게 아닌, 원본 data의 최대한 많은 정보를 뽑을 수 있도록 feature vector extract&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Given data points in d-dimensions
    &lt;ul&gt;
      &lt;li&gt;Convert them to data points in $k(&amp;lt;d)$ dimensions&lt;/li&gt;
      &lt;li&gt;k의 약 10% 정도로 d를 다룬다&lt;/li&gt;
      &lt;li&gt;With minimal loss of information&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;data-compression&quot;&gt;Data Compression&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_2.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;z_1 상에 proejction한 형태로 reduct dimensionailty&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reduce-data-from-3d-to-2d&quot;&gt;Reduce data from 3D to 2D&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;어떤 방향으로 Data를 투영하느냐에 따라 분포 모양이 달라짐&lt;/li&gt;
  &lt;li&gt;너무 뭉쳐서 투영되면 좋지 않은 reduction&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_3.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_4.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;feature-extractiondimensionality-reduction-2&quot;&gt;Feature extraction/Dimensionality reduction 2&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Suppose we have a population measured on p random variables x1, …, xd.
    &lt;ul&gt;
      &lt;li&gt;random variable&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Note that these random variables represent the d-axes of the Cartesian coordinate system in which the population resides. Our goal is to develop a new set of k axes (linear combinations of the original d axes) in the directions of greatest variability: X2
    &lt;ul&gt;
      &lt;li&gt;cartesian coordinate system : 새로운 axis를 찾아내서 더 잘 Represent하도록 표현&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_5.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;This is accomplished by rotating the axes 원래의 좌표축을 rotate하는 방법으로 진행
    &lt;ul&gt;
      &lt;li&gt;Rotates multivariate dataset into a new configuration which is easier to interpret&lt;/li&gt;
      &lt;li&gt;Purpose
        &lt;ul&gt;
          &lt;li&gt;simplify data (잘 압축하여 간소화)&lt;/li&gt;
          &lt;li&gt;look at relationships between variables , patterns of units (Data 간 관계, 패턴 분석 가능)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;basic-principle&quot;&gt;Basic Principle&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;From a raw data (vector) X of d-dimension to a new vector Y of k-dimensional (k &amp;lt; &amp;lt; d) via a transformation matrix A such that Y will capture most information in X&lt;/li&gt;
&lt;/ul&gt;

\[Y = AX\]

&lt;p&gt;&lt;img src=&quot;13/Untitled_6.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;원래 데이터 X에 변환 Matrix A를 곱하여 Y라는 변환된 matrix&lt;/li&gt;
  &lt;li&gt;변환된 matrix : 회전된 좌표축에서의 data
    &lt;ul&gt;
      &lt;li&gt;→ X matrix를 raw matrix로 간주하고 d dimension to k dimension matrix&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;principal-component-analysis-pca&quot;&gt;Principal Component Analysis (PCA)&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Goal: find k-dim projection that best preserves variance&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;calculation&quot;&gt;Calculation&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;compute mean vector $\mu$ and covariance matrix $\Sigma$ of original data
    &lt;ol&gt;
      &lt;li&gt;D-dim data로부터 Mean, Covariance 구함&lt;/li&gt;
      &lt;li&gt;$X = [X1, X2, … , Xn]$&lt;/li&gt;
      &lt;li&gt;(mean centered X) $X_{\mu_0} = X-\mu = [X1-\mu, X2-\mu, … , Xn-\mu]$&lt;/li&gt;
      &lt;li&gt;$\Sigma = X_{\mu_0} X_{\mu_0} ^T = \frac 1 n  \Sigma (X_i - \mu)(X_i - \mu)^T$&lt;/li&gt;
      &lt;li&gt;$S = \Sigma(X_i - \mu)(X_i - \mu)^T$&lt;/li&gt;
      &lt;li&gt;$\Sigma v = \lambda v$&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Compute eigenvectors and eigenvalues of $\Sigma$&lt;/li&gt;
  &lt;li&gt;Select top k eigenvectors
    &lt;ol&gt;
      &lt;li&gt;Top k개 eigenvalue에 대응하눈 eigenvector 구함&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Project points onto subspace spanned by them
    &lt;ol&gt;
      &lt;li&gt;$y = A(x-\mu)$&lt;/li&gt;
      &lt;li&gt;where y is the new data, x is the original data, and the rows of A are the eigenvectors&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;When we said the eigenvector as&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_7.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;in the previous lecture, $A$ is $V^T$ (k vectors, $v_1$ … $v_k$)&lt;/p&gt;

&lt;h2 id=&quot;feature-extractiondimensionality-reduction-3&quot;&gt;Feature extraction/Dimensionality reduction 3&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Covariance matrix :
    &lt;ul&gt;
      &lt;li&gt;d dimension data로부터 d개의 eigenvector&lt;/li&gt;
      &lt;li&gt;2차원 data로부터 2개의 eigenvector, eigenvalue&lt;/li&gt;
      &lt;li&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The eigenvectors of $\Sigma$ define a new coordinate system 
(새로운 coordinate system으로 적용)&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Eigenvector with largest eigenvalue captures the &lt;strong&gt;most variation&lt;/strong&gt; among data X
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;eigenvector :PCA분석을 했을 때 data가 가장 크게 분산된 방향으로 표현하는 방향벡터이고 그 정도를 가리키는 것은 eigenvalue.&lt;/strong&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Eigenvector with smallest eigenvalue has least variation
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;가장 작은 eigenvalue에 대응되는 Eigenvector는 분산이 제일 작다.&lt;/strong&gt;&lt;/li&gt;
        &lt;/ul&gt;

        &lt;p&gt;&lt;img src=&quot;13/Untitled_8.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;v1이라는 axis로 투영한다면 Data가 가장 잘 분산되는 최적의 방향이다 → 최대 분산 방향으로 압축되면 제일 잘 분산되는 방향으로 data의 차원을 축소시키는 것이기에 원본 Data 정보 잘 반영&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Dimension reduction에 따른 원본 data의 information loss정도
        &lt;ul&gt;
          &lt;li&gt;1Dim 압축 : 가장 최소 eigenvector, 2Dim 압축 : 두 번째eigenvector&lt;/li&gt;
          &lt;li&gt;d dim에 대해서 D개를 모두 사용 → 어떠한 손실도 없이 원본 Data 수행 가능
            &lt;ol&gt;
              &lt;li&gt;표현된 Data는 동일하지만 PCA 분석이 되어 있기에 Dimension을 줄이면 됨&lt;/li&gt;
              &lt;li&gt;corelation이 감소된 형태로 좌표축 정립 : x1의 값이 변화할 때 x2의 값이 변화되는 정도&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;We can compress the data by only using the top few eigenvectors
    &lt;ul&gt;
      &lt;li&gt;Corresponds to choosing a “linear subspace”
        &lt;ul&gt;
          &lt;li&gt;일정 constant를 곱한 형태이므로 linear&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;These eigenvectors are known as the principal components&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;covariance&quot;&gt;Covariance&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;각 차원 별 Relation (corelation)&lt;/li&gt;
  &lt;li&gt;Variance and Covariance:
    &lt;ul&gt;
      &lt;li&gt;Measure of the “spread” of a set of points around their center of mass (mean)&lt;/li&gt;
      &lt;li&gt;각 차원에서의 data가 얼마나 많이 분산되어 있느냐에 대한 정보 제공&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Variance
    &lt;ul&gt;
      &lt;li&gt;Measure of the deviation from the mean for points in one dimension&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Covariance&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;13/Untitled_9.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Measure of how much each of the dimensions vary from the mean with respect to each other&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;여러 차원에 걸쳐 분산을 계산하면 -&amp;gt; covariance정보 얻을 수 있음&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;Covariance is measured between two dimensions&lt;/li&gt;
      &lt;li&gt;Covariance sees if there is a relation between two dimensions&lt;/li&gt;
      &lt;li&gt;Covariance in one dimension is the variance&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Positive: Both dimensions increase or decrease together
    &lt;ul&gt;
      &lt;li&gt;한 차원의 값이 증가하면 다른 차원의 값도 증가&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_10.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Negative: While one increase the other decrease
    &lt;ul&gt;
      &lt;li&gt;한 차원의 값이 증가하면 다른 차원의 값은 반대로 감소&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_11.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;식&quot;&gt;식&lt;/h2&gt;

\[\Sigma = \frac 1 N \Sigma_{i=1}^{N}{(x_i -\mu)(x_i -\mu)^T}\]

&lt;ul&gt;
  &lt;li&gt;$\Sigma v = \lambda v$
    &lt;ul&gt;
      &lt;li&gt;$\Sigma$  : Square Matrix&lt;/li&gt;
      &lt;li&gt;$v$  : Eigenvector or characteristic vector (d)&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$\lambda$ : Eigenvector or characteristic value (d*d)&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;13/Untitled_12.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;$\Sigma v = \lambda v$&lt;/li&gt;
  &lt;li&gt;$(\Sigma -\lambda I) v=0$&lt;/li&gt;
  &lt;li&gt;$\Sigma -\lambda I=0 \iff M = 0$&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$&lt;/td&gt;
          &lt;td&gt;\Sigma -\lambda I&lt;/td&gt;
          &lt;td&gt;=0 \iff&lt;/td&gt;
          &lt;td&gt;M&lt;/td&gt;
          &lt;td&gt;= 0$ // Characteristic Equation&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;The zero vector cannot be an eigenvector&lt;/li&gt;
  &lt;li&gt;The value zero can be an eigenvalue
    &lt;ul&gt;
      &lt;li&gt;Eigen solver - library 별로 Serving algorithm이 다름&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;다른 좌표계의 값으로 해석
    &lt;ul&gt;
      &lt;li&gt;차원 축소로 인한 info loss를 최소화시킴&lt;/li&gt;
      &lt;li&gt;원래 좌표계에서 차원 축소하면 info loss가 너무 크기 때문에 변환하여&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;From d original variables: $x_1, x_2, …, x_d$&lt;/p&gt;

    &lt;p&gt;x 라는 좌표축을 y 좌표축으로 변환 (y-axis: uncorrelated)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Produce k new variables: $y_1, y_2, …, y_k$ - Eigenvector의 개수를 k«d개로 표현할 수 있음.&lt;/li&gt;
      &lt;li&gt;y좌표계에는 data diension간 correlation이 최소화&lt;/li&gt;
      &lt;li&gt;다른 좌표축으로 새롭게 변환하며 dimension reduction
        &lt;ul&gt;
          &lt;li&gt;표현 방법은 다르지만 data 자체는 동일하게 d variables : y1~ y1d&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;13/Untitled_13.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;13/Untitled_14.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;such that:
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;$y_k$’s are uncorrelated (orthogonal)&lt;/p&gt;

        &lt;p&gt;새로운 좌표축 yk는 서로 수직인 관계 (uncorrelated, orthogonal)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;$y_1$ explains as much as possible of original variance in data set
        &lt;ul&gt;
          &lt;li&gt;data의 가장 큰 Variance 방향으로&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;$y_2$ explains as much as possible of remaining variance&lt;/li&gt;
      &lt;li&gt;etc.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;eigenvector / eigenvalue 대응 → characteristic equation으로 solve 가능
    &lt;ul&gt;
      &lt;li&gt;solver에 따라 solution이 다르게 나타나는데 eigenvector value가 잘 적합하게 구해졌는지 확인 (unstable하게 구해졌을 수가 있으므로)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;$v_1 = \left[ \begin{matrix}v_{11} &amp;amp; v_{12} &amp;amp; …&amp;amp; v_{1d} \end{matrix} \right]^T$ is the 1st Eigenvector of covariance matrix, and coefficients of $y_1$ ( $v_1$ is the first principal component)&lt;/li&gt;
  &lt;li&gt;$v_2 = \left[ \begin{matrix}v_{21} &amp;amp; v_{22} &amp;amp; …&amp;amp; v_{2d} \end{matrix} \right]^T$is the 2nd Eigenvector of covariance matrix, and coefficients of $y_2$ ( $v_2$ is the 2nd principal component)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$v_k = \left[ \begin{matrix}v_{k1} &amp;amp; v_{k2} &amp;amp; …&amp;amp; v_{kd} \end{matrix} \right]^T$is the kth Eigenvector of covariance matrix, and coefficients of $y_k$ ( $v_k$ is the kth principal component)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_15.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;eigenvector, eigenvalue가 나오게 되고 
2개의 eigenvalue의 크기 순서대로 eigenvector을 내림차순으로 정렬
    &lt;ul&gt;
      &lt;li&gt;→ 가장 크게 var이 되는 방향으로 정렬하게 됨&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;새로운 좌표계를 보면 제일 큰 분산 방향으로 분산을 표현해 낸 좌표축 v1, v2
    &lt;ul&gt;
      &lt;li&gt;첫 번째 eigenvalue에 해당하는 좌표축을 써서 data 표현해면 → info loss 최소화&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;더 분별력 잇는 방향으로 표현되나 data 자체는 동일하다.&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;13/Untitled_16.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;더 분별력 잇는 방향으로 표현되나 data 자체는 동일 (x1, x2) → (y1, y2)
    &lt;ul&gt;
      &lt;li&gt;그 변환 관계는 x좌표와 y좌표의 연관&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;d차원을 k차원으로 줄어들게 됨 : 가장 큰 eigenvector로 해서 좌표축을 변환해도 잘 date들이 표현이 됨을 확인할 수 있다. (최대 분산 방향이므로)&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;13/Untitled_17.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;pca-example&quot;&gt;PCA Example&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_18.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_19.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Calculate the covariance matrix
    &lt;ul&gt;
      &lt;li&gt;$cov = \left[ \begin{matrix}.616555556 &amp;amp; .615444444 \ .615444444 &amp;amp;.716555556\end{matrix} \right]$
        &lt;ul&gt;
          &lt;li&gt;covariance : $\sigma _{12} = \sigma _{21}$이 같은 값을 가지는 symmetric - &amp;gt; correlation이 positive :&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;since the non-diagonal elements in this covariance matrix are positive, we should expect that both the x and y variable increase together.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;ol&gt;
      &lt;li&gt;Zero mean data를 이용해 $XX^T$&lt;/li&gt;
      &lt;li&gt;각각의 data에서 mu를 빼 주어 n으로 나누자:  $\frac 1 n (x-\mu)(x-\mu)^T$
        &lt;ul&gt;
          &lt;li&gt;$\frac 1 n$으로 나누어주면 covariance&lt;/li&gt;
          &lt;li&gt;안 나누어주면 scatter matrix
            &lt;ul&gt;
              &lt;li&gt;: 나누어주냐 나누어주지 않느냐는 상수를 곱해주는 것이기 때문에 cov로 하던 scatter로 하던 방향과 크기를 이야기하는 것이기에 같게 나옴.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Calculate the eigenvectors and eigenvalues of the covariance matrix&lt;/p&gt;

    &lt;p&gt;characteristic equation을 구해 lambda를 구해 eigenvalue, vector&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;eigenvalues$= \left[ \begin{matrix}.0490833989 \ 1.28402771  \end{matrix} \right]$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;eigenvectors$= \left[ \begin{matrix}-.735178656 &amp;amp;-.677873399 \ .677873399 &amp;amp;-.735178656 \end{matrix} \right]$
    &lt;ul&gt;
      &lt;li&gt;크기 순서대로 정렬하게 되면 v2 / v1&lt;/li&gt;
      &lt;li&gt;(-) (-) 북동/남서방향 : 서로 수직인 관계로 얻어짐&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_20.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;eigenvectors are plotted as diagonal dotted lines on the plot.&lt;/li&gt;
  &lt;li&gt;Note they are perpendicular to each other.&lt;/li&gt;
  &lt;li&gt;Note one of the eigenvectors goes through the middle of the points, like drawing a line of best fit.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The second eigenvector gives us the other, less important, pattern in the data, that all the points follow the main line, but are off to the side of the main line by some amount.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reduce dimensionality and form feature vector&lt;/p&gt;

    &lt;p&gt;차원 축소된 data : feature&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;the eigenvector with the highest eigenvalue is the principle component of the data set.
        &lt;ul&gt;
          &lt;li&gt;원래 data dimension을 drop한 형태가 아닌 원래 거를 잘 조합해서 만든 feature vector&lt;/li&gt;
          &lt;li&gt;eigenvalue를 크기 순대로 대응하여 첫 번째 component로 간주한다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;In our example, the eigenvector with the largest eigenvalue was the one that goes through the middle of the data.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Once eigenvectors are found from the covariance matrix, the next step is to order them by eigenvalue, highest to lowest. This gives you the components in order of significance.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Eigen Feature Vector
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Feature Vector = (eig1 eig2 eig3 … eign)&lt;/p&gt;

        &lt;p&gt;모든 eigenvector를 사용하면 원래 data 사용&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;dim reduction은 없으나 correlation 최소되도록 좌표값 생성&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;We can either form a feature vector with both of the eigenvectors:
    &lt;ul&gt;
      &lt;li&gt;eigenvectors$= \left[ \begin{matrix}-.677873399 &amp;amp; -.735178656 \ -.735178656 &amp;amp;.677873399  \end{matrix} \right]$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;or, we can choose to leave out the smaller, less significant component and only have a single column:
    &lt;ul&gt;
      &lt;li&gt;less significant 한 eigenvector순으로 drop시키면 차원의 수 = data info loss 최소화 하는 방향으로 drop&lt;/li&gt;
      &lt;li&gt;eigenvalues$= \left[ \begin{matrix}.677873399 \ - .735178656 \end{matrix} \right]$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Back to our example: Transform data to eigen-space $(x’, y’)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_21.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_22.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;좌표축의 반시계방향 회전 (data의 시계방향 회전) 이라고도 볼 수 있음&lt;/li&gt;
  &lt;li&gt;data를 eigenvector에 투영한다는 것은 :
    &lt;ul&gt;
      &lt;li&gt;Eigenvector를 원래 data point에 곱하는 것은
  새로운 좌표값에서의 값이 나오게 됨.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;eigenface&quot;&gt;Eigenface&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_23.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;data 분석할 때 : 특히 video 처리할 때 image 100*100만 되도 dimension 10000
    &lt;ul&gt;
      &lt;li&gt;→ 처리:&lt;/li&gt;
      &lt;li&gt;image column방향으로 이어붙여서 column vector륾 만들어 처리했는데 너무 dim이 컸음
  PCA를 통해 dimension reduction을 하려고 했음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;When viewed as vectors of pixel values, face images are extremely high-dimensional
    &lt;ul&gt;
      &lt;li&gt;d = 100´100 image → 10,000 dimensions&lt;/li&gt;
      &lt;li&gt;Slow and lots of storage&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;However, very few of 10,000 dimensional vectors are valid face images&lt;/li&gt;
  &lt;li&gt;We want to effectively model the subspace of face images&lt;/li&gt;
  &lt;li&gt;$X_{new} = \Sigma_i w_i x_i$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_24.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Eigenspace 얼굴 이미지를 모아서 평균 face - PCA할 때 mean을 빼 주어 평균 얼굴을 빼 주어 수행&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;10000차원 data를 이용해 covariance mat를 구하고 이로부터 eigenvector/value를 구할 수 있음
    &lt;ul&gt;
      &lt;li&gt;그 eigenvector는 10000차원임 (d = 10000) / data 개수 n = 100
        &lt;ul&gt;
          &lt;li&gt;
            &lt;blockquote&gt;
              &lt;p&gt;covariance matrix의 차원은 : 10000 * 10000&lt;/p&gt;
            &lt;/blockquote&gt;
          &lt;/li&gt;
          &lt;li&gt;d*d로 pca하면 eigenvector d개 → 10000개 나오게 됨&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;eigenvector : 10,000차원의 column vector를 100*100 이미지로 만들게 되면 eigenvalue모양이 얼굴 모양을 나타내게 됨.&lt;/li&gt;
  &lt;li&gt;eigenvalue와 data를 곱하게 되면 이를 feature vector로 다섯 개로 줄어듦&lt;/li&gt;
  &lt;li&gt;이런 식으로 feature vector로 나오게 된 것을 DT, bayesian에 넣는 것보다도 data 전체를 다 넣어서 NN에 넣는게 더 효율적이더라 :더 좋은 feature를 뽑아 classification도 잘 해줌&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_25.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$X_{\mu} = VY$&lt;/li&gt;
  &lt;li&gt;$X = \mu + VY$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_26.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_27.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;(1) 원래 data를 이용하는 것 vs (2) eigenvector를 이용하는 것 중 어느 것이 더 효율적일까? (효과적일까)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;→ eigenvector가 더 효율적이다.&lt;/p&gt;

&lt;p&gt;이유)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;original data X에는 많은 duplicate를 포함되어 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그러나&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Eigenvector에는 그 duplicate가 제거된 correlation이 배제됨&lt;/li&gt;
  &lt;li&gt;심지어 원래는 i 100개를 다 써야 하는데 eigenvector를 쓰면 10000 iteration까지도 갈 수 있음/ data correlation 제거했기 때문에 고유성을 가진 vector들은 적은 data를 사용해도 전체 데이터를 표현할 수 있다&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;→ original data 100개 돌려서 쓰는 것보다 10개 해서 쓰는게 더 효과적인 결과가 나올 수 있다&lt;/p&gt;

&lt;h1 id=&quot;sift-feature-visualization&quot;&gt;SIFT feature visualization&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_28.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The top three principal components of SIFT descriptors from a set of images are computed&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;data image pixel을 조합하여 image표현하는 방법&lt;/li&gt;
  &lt;li&gt;등장 배경
    &lt;ul&gt;
      &lt;li&gt;고차원 data feature pixel(4k 해상도 등)을 개별적으로 처리하기에는 어려움이 큼&lt;/li&gt;
      &lt;li&gt;→ data를 10*10으로 쪼개서 unit pattern의 조합 block으로 SIFT Descriptor를 뽑아 PCA를 수행시킴 → correlation이 배제된 상위 몇 개의 eigenvector 구해짐&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;상위 n개의 eigenvector를 가지고 원본 image로 mapping하기 위한 alpha값을 구할 수 있을 것.
    &lt;ul&gt;
      &lt;li&gt;Map these principal components to the RGB space
        &lt;ul&gt;
          &lt;li&gt;$\Sigma_i \alpha_i v_i$&lt;/li&gt;
          &lt;li&gt;alpha value는 3개로 나타남 : 어떤 image의 patch이건 RGB&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;blockquote&gt;
          &lt;p&gt;image에 비슷한 경향을 나타나면 비스무리한 색으로 나타나게 된다.&lt;/p&gt;
        &lt;/blockquote&gt;
        &lt;ul&gt;
          &lt;li&gt;pixels with similar colors share similar structures 32&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;→ data에 어떤 내용이 포함 되어 있을지에 대한 연구를 수행할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_29.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;임의의 차원의 data block을 원하는 차원으로 줄임
    &lt;ul&gt;
      &lt;li&gt;임의의 block에 PCA 분석을 수행시키고 eigenvector에 원하는 개수 만큼 수행하면 그 alpha값을 활용하여 dim reduction : unit patch에 대한 pca 분석&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Divide the original 372x492 image into patches:&lt;/li&gt;
  &lt;li&gt;Each patch is an instance that contains 12x12 pixels on a grid&lt;/li&gt;
  &lt;li&gt;View each as a 144-D vector 33&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;PCA compression: 144-D → 60 D&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;13/Untitled_30.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;144개 eigenvector 모두 : 원본 image와 동일한 quality
  60개 eigenvector : data 해상도가 떨어지지만 dim은 절반 정도로 줄어듬&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;16 most important eigenvectors&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;13/Untitled_31.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;6 most important eigenvectors&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;13/Untitled_32.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;PCA compression: 144-D → 3-D&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;13/Untitled_33.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;60 most important eigenvectors&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;13/Untitled_34.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;block의 대소에 따른 compression 정도의 차 :
    &lt;ul&gt;
      &lt;li&gt;compression 정도 - image quality 사이의 tradeoff 존재&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;일정 크기의 patch에 대해 pca를 보고 상위 n개의 eigenvector&lt;/p&gt;

    &lt;p&gt;→ 어떤 image건 12*12 pixel은 60개의 숫자로 표현되는 60dim&lt;/p&gt;

    &lt;p&gt;Compression 많이 되면 잘 분간할 수 없을 정도가 될 수 있으므로 적절한 선에서 (1/10) 마무리하면 괜찮음&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;pca-vs-lda&quot;&gt;PCA vs. LDA&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;PCA maximizes the total scatter → PCA does not consider class information
    &lt;ul&gt;
      &lt;li&gt;PCA 분석 하면 data의 최대 분산 방향으로 eigenvector가 얻어지게 됨&lt;/li&gt;
      &lt;li&gt;최대 분산 방향으로 data 투영하게 되면 data label 구분이 없어짐 (섞임)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Linear Discriminant Analysis(LDA) considers class information&lt;/p&gt;

    &lt;p&gt;LDA&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;data label 이용:&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_35.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_36.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;PCA maximizes projected total scatter
label이 없으니 전체 data에 대해서 covariance를 구함&lt;/p&gt;

\[\Sigma = \frac 1 N \Sigma_{i=1}^{N}{(x_i -\mu)(x_i -\mu)^T}\]

\[\Sigma v = \lambda v\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;LDA maximizes ratio of projected between-class to projected within-class scatter&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;LDA: 각 class별로 covariance matrix를 구함
        &lt;ul&gt;
          &lt;li&gt;within class scatter&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Eigen-decomposition: Sigma value가 최대화되는 방향 :
        &lt;ul&gt;
          &lt;li&gt;pca : covariance 최대화&lt;/li&gt;
          &lt;li&gt;lda : $\Sigma_b$ 최대화, $\Sigma_w$ 최소화&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;cluser의 분산이 각각 cluster 내부에서는 cov가 최소
  서로 다른 class 간에는 cov 최대의 방향&lt;/li&gt;
    &lt;/ul&gt;

\[\Sigma_w = \Sigma_{j=1}^{c}\frac 1 {N_c} \Sigma_{i=1}^{N_c}{(x_i -\mu_c)(x_i -\mu_c)^T}\]

\[\Sigma_c = \frac 1 {c} \Sigma_{i=1}^{c}{(\mu_c-\mu)(\mu_c-\mu)^T}\]

\[\frac{\Sigma_b}{\Sigma_w}v = \lambda v\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;pca-vs-lda-for-reference&quot;&gt;PCA vs. LDA (for reference)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;eigenvector PCA = var 최대 방향으로 vector를 구함
    &lt;ul&gt;
      &lt;li&gt;원래 vector를 transformation하여 var이 최대화되도록&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;$z = w^Tx$&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Maximize $&lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;z&lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;= z^Tz$  , while $&lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;w&lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;= w^Tw = 1$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;table&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;z를 maximize =&lt;/td&gt;
              &lt;td&gt;z&lt;/td&gt;
              &lt;td&gt;최대 = z^Tz 최대화&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
      &lt;/li&gt;
      &lt;li&gt;앞에서 이 weight matrix는 norm =1이 되는 방향으료 표준화해놓고 z 최대화하는 방향으로 eigenvalue vector 구함 → $z^Tz$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;$z^Tz = w^Tx(w^Tx)^T = w^Tx x^Tw = w^T \Sigma w$&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$\max_w{(z^Tz - \lambda(w^T w-1))} = \max_w{(w^T \Sigma w - \lambda(w^Tw-1))}$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Take derivative w.r.t. $w$&lt;/li&gt;
  &lt;li&gt;$2 \Sigma w - 2 \lambda w = 0$&lt;/li&gt;
  &lt;li&gt;$\Sigma w = \lambda w$&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;pca-vs-lda-face-recognition-accuracy&quot;&gt;PCA vs. LDA Face recognition accuracy&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Database 상 Face 중에서 어느 것과 가장 같은지 비교&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;13/Untitled_37.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;eigenvector 너무 적게하면 정보 손실된 것이니까 잘 비교 안됨&lt;/li&gt;
      &lt;li&gt;eigenvector(feature) 늘여보면 성능 올라감 / 떨어짐&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;PCA (eigenfaces): 80.0%&lt;/li&gt;
  &lt;li&gt;LDA (fisherfaces): 93.2%&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;13/Untitled_38.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;FERET database&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;PCA : dim reduction
    &lt;ul&gt;
      &lt;li&gt;얼굴 data 이용하여 : row 방향이 아닌 column vector 모양&lt;/li&gt;
      &lt;li&gt;data에 대한 pca 분석 수행하면 eigenvector가 나오는데&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;y = V^T X로 y가 나옴
    &lt;ul&gt;
      &lt;li&gt;V eigenvector 10000개 중 k=100~200로 쓰면 100~200 dim의 data로 수행&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;PCA는 unsupervised learning에서 clustering, dimensionality reduction
    &lt;ul&gt;
      &lt;li&gt;Not for classification&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;LDA는 supervised learning, dimensionality reduction
    &lt;ul&gt;
      &lt;li&gt;Classification을 위해 쓸 수 있으나 label 사용해서 unsupervised라고 볼 수는 없음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;사람의 수 = class 개수 → 수천만 개가 되면 class별 학습이 어려움
    &lt;ul&gt;
      &lt;li&gt;보통 얼굴인식할 때는 사람 수가 되게 많다 (수십 ~ 수백이나 폰에는 보통 한 명)&lt;/li&gt;
      &lt;li&gt;출입 시스템에 등록된 사람 : 수십~수백&lt;/li&gt;
      &lt;li&gt;CCTV block system : 수십 명&lt;/li&gt;
      &lt;li&gt;운전면허, 주민등록 얼굴 : 수천만 명&lt;/li&gt;
      &lt;li&gt;얼굴 인식할 때 등록되는 사람들 중 얼굴&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;identification&quot;&gt;Identification&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;one-to-n matching&lt;/li&gt;
  &lt;li&gt;k nearest neighbor를 사용하여 l2 distance가 가장 가까운 것을 새로운 얼굴에 대응되는 id라고 간주함&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;verification&quot;&gt;Verification&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;one-to-one matching&lt;/li&gt;
  &lt;li&gt;사용자가 id를 이야기하고 맞는지 판단하는 경우-해당 id가 맞느냐 틀리느냐&lt;/li&gt;
  &lt;li&gt;Attribute가 많아지는데 성능 떨어지면 curse of dimensionality / overfitting&lt;/li&gt;
&lt;/ul&gt;</content><author><name>KyuHwan Shim</name><email>skh7343@cnsh.hs.kr</email></author><category term="ml" /><category term="ML" /><category term="AI" /><category term="Lecture" /><summary type="html">Chap13.Dim</summary></entry><entry xml:lang="en"><title type="html">Clustering (Chapter 12)</title><link href="http://localhost:4000/blog/ML-12-Clustering/" rel="alternate" type="text/html" title="Clustering (Chapter 12)" /><published>2022-06-12T12:26:09+09:00</published><updated>2022-06-12T12:26:09+09:00</updated><id>http://localhost:4000/blog/ML-12-Clustering</id><content type="html" xml:base="http://localhost:4000/blog/ML-12-Clustering/">&lt;h1 id=&quot;12-clustering&quot;&gt;12. Clustering&lt;/h1&gt;

&lt;h1 id=&quot;clustering&quot;&gt;Clustering&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Unsupervised learning&lt;/li&gt;
  &lt;li&gt;Requires data, but no labels
    &lt;ul&gt;
      &lt;li&gt;label이 없다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Detect patterns e.g. in
    &lt;ul&gt;
      &lt;li&gt;data pattern을 인식하려고 한다 : email / 검색 결과 / 쇼핑 패턴 / 이미지 리전으로부터&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Useful when don’t know what you’re looking for Clustering
    &lt;ul&gt;
      &lt;li&gt;일단 clustering 수행하고 나면 해당 data가 어떻게 이루어지는지는 알 수 있다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Basic idea: group together similar instances&lt;/li&gt;
  &lt;li&gt;Example: 2D point patterns Clustering&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_1.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_2.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What could “similar” mean?
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;One option: small Euclidean distance&lt;/p&gt;

        &lt;p&gt;‘ similarity’를 어떻게 판단할 수 있는가&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;2 dim 공간 상 거리 -&amp;gt; Euclidean distance
  Similarity 는 distance에 반비례&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Clustering results are crucially dependent on the measure of similarity (or distance) between “points” to be clustered&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_3.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Partition algorithms
    &lt;ul&gt;
      &lt;li&gt;K-means&lt;/li&gt;
      &lt;li&gt;Mixture of Gaussian&lt;/li&gt;
      &lt;li&gt;Spectral clustering&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Hierarchical algorithms
    &lt;ul&gt;
      &lt;li&gt;Bottom up : agglomerative&lt;/li&gt;
      &lt;li&gt;Top down : divisive&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;clustering-examples&quot;&gt;Clustering Examples&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Image segmentation
    &lt;ul&gt;
      &lt;li&gt;Image segmentation : 인접한 유사한 feature를 가진 pixel 끼리 group으로 분할&lt;/li&gt;
      &lt;li&gt;Goal: Break up the image into meaningful or perceptually similar regions&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;12/Untitled_4.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Clustering gene data&lt;/p&gt;

    &lt;p&gt;Hierarchical clustering : gene group에 큰 두 개의 gruop이 있음을 판단할 수 있다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;나중에 들어오는 data에 대해서도 두 가지 class 대상으로 labeling할 수도 있고 두 가지 label로 supervised learning도 가능&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;12/Untitled_5.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cluster news articles&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;12/Untitled_6.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cluster people by space and time&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;12/Untitled_7.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cluster languages&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;12/Untitled_8.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;12/Untitled_9.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cluster species (phylogeny)&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;12/Untitled_10.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cluster search queries&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;12/Untitled_11.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;k-means-clustering&quot;&gt;K-Means Clustering&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_12.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;An iterative clustering algorithm&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Initialize: Pick K random points as cluster centers&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;cluster의 개수 가정 : k개의 cluster = k개의 random point 초깃값 assume&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Alternate:
    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Assign data points to closest cluster center&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;k개의 pt에 대해서 각각의 data들을 가장 가까운 cluster center에 할당하고&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Change the cluster center to the average of its assigned points&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Cluster center update : 각 iteration마다 update&lt;/li&gt;
        &lt;/ol&gt;

        &lt;ul&gt;
          &lt;li&gt;더 이상 update되지 않는 시점에서 cluster 중단&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Stop when no point assignments change&lt;/p&gt;

    &lt;p&gt;초깃값에 대해서 (initial center point) partition 나눔&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;그 data들의 center mean을 구해서 이로 center를 update함&lt;/li&gt;
      &lt;li&gt;이를 기반으로 update된 값들의 member들을 재할당&lt;/li&gt;
      &lt;li&gt;반복하다 보면 각각의 cluster의 center로 이동하게 됨&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_13.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;k-means-clustering-example&quot;&gt;K-Means Clustering: Example&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_14.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Pick K random points as cluster centers (means)&lt;/li&gt;
  &lt;li&gt;Shown here for K=2&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;iterative-step-1&quot;&gt;Iterative Step 1&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Assign data points to closest cluster center
    &lt;ul&gt;
      &lt;li&gt;mean값에 대해서 다시 partition./ center값 할당하며 반복하게 되면
  K means clustering 작업에 의한 clustering 결과를 얻게 됨.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_15.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;iterative-step-2&quot;&gt;Iterative Step 2&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Change the cluster center to the average of the assigned points&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_16.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;properties-of-k-means-algorithm&quot;&gt;Properties of K-means algorithm&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Guaranteed to converge in a finite number of iterations&lt;/p&gt;

    &lt;p&gt;k값이 대략적인 cluster개수와 일치해야지, 그렇지 않으면 만족하지 못할 결과가 나올 수도 있음&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Running time per iteration:&lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Assign data points to closest cluster center : O(KN)&lt;/p&gt;

        &lt;p&gt;k개의 point, n samples -&amp;gt; kn&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Change the cluster center to the average of its assigned points : O(N)&lt;/p&gt;

        &lt;p&gt;Cluster center average -&amp;gt; n&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;properties-of-k-means-algorithm-convergence&quot;&gt;Properties of K-means algorithm (convergence)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Objective&lt;/p&gt;

    &lt;p&gt;모든 sample들에 대해서 center값을 계산 :sample들의 center 값으로부터의 거리 제곱의 합이
  k개의 cluster에 대해서 최소&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;cluster center에 잘 일치하게 되면, 해당 cluster에 속하는 sample들이 그 cluster center 와 이루는 거리의 합이 모든 cluster에 대해서 minimum이 됨&lt;/li&gt;
    &lt;/ul&gt;

\[\min_{\mu} \min_{c}  \Sigma_{i=1}^{k} {\Sigma_{x\in C_i}|x-\mu_i|^2}\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Fix $\mu$, optimize $C$&lt;/p&gt;

    &lt;p&gt;iteration작업- partition update&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;mu 고정, C optimize&lt;/li&gt;
      &lt;li&gt;center까지의 모든 sample들의 거리를 최소화하는 작업&lt;/li&gt;
    &lt;/ul&gt;

\[\min_{c}  \Sigma_{i=1}^{k} {\Sigma_{x\in C_i}|x-\mu_i|^2} = \min_{c}  \Sigma_{i=1}^{n} {|x_i-\mu_{xi}|^2}\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Fix $\mu$, optimize $\mu$&lt;/p&gt;

    &lt;p&gt;Partition update후 center값 update&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;각 cluster sample들에서 sample들로부터 center 거리를 최소화시킬 수 있도록 평균값 설정&lt;/li&gt;
      &lt;li&gt;mu에 대해서 미분하고ㅡ 이를 0으로 setting하면 평균값이라는 것은 각 cluster에 속한 sample들의 값의 합을 그 cluster에 속한 sample들의 값의 합을 그 cluster에 속한 sample들의 개수로 나눈 값이 그 center 값 : center mean&lt;/li&gt;
    &lt;/ul&gt;

\[\min_{\mu} \Sigma_{i=1}^{k} {\Sigma_{x\in C_i}|x-\mu_i|^2}\]

    &lt;ul&gt;
      &lt;li&gt;Take partial derivative with respect to $\mu_i$and sets to zero, we have $\mu_i = \frac 1 {C_i} \Sigma_{x\in C_i} x$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;K-means takes an alternating optimization, each step is guaranteed to decrease the objective – thus guaranteed to converge&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;example-k-means-for-image-segmentation&quot;&gt;Example: K-Means for Image Segmentation&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_17.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Goal of image segmentation is to partition an image into regions each of which has reasonably homogenous visual appearance.&lt;/p&gt;

    &lt;p&gt;K means clustering segmentation&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;clustering : space상에서 한 게 아니고 color값들이 r,g,b의 값을 갖는데 256^3 의 dimension 3 histogram&lt;/li&gt;
      &lt;li&gt;k개의 color로 clustering&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;k-means-algorithm---initialization&quot;&gt;K-means algorithm - initialization&lt;/h1&gt;

&lt;p&gt;K-means algorithm is a heuristic&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;converging하기도 하고 완전 heuristic하지는 않고 완전 이상한 initial value로 하면 아예 못 구하기도 함&lt;/li&gt;
  &lt;li&gt;Requires initial means
    &lt;ul&gt;
      &lt;li&gt;초기 center값에 따라 최종 결과가 잘못될수도 있음&lt;/li&gt;
      &lt;li&gt;It does matter what you pick!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What can go wrong?&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Various schemes for preventing this kind of thing: variance-based split / merge, initialization heuristics&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A local optimum&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;12/Untitled_18.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Would be better to have one cluster here&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;12/Untitled_19.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;k-means-algorithm&quot;&gt;K-means algorithm&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Not able to cluster properly&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_20.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_21.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Changing the features (distance function) can help&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;clustering-hierarchical-clustering&quot;&gt;Clustering Hierarchical Clustering&lt;/h1&gt;

&lt;p&gt;Two main types of hierarchical clustering&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Agglomerative: 각각의 개별 sample로 시작해서 cluster로 간주하여 각각을 merge하여 최종적으로 1~k개의 cluster가 되기까지 merge
    &lt;ul&gt;
      &lt;li&gt;Start with the points as individual clusters&lt;/li&gt;
      &lt;li&gt;At each step, merge the closest pair of clusters until only one cluster (or k clusters) left&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Divisive:하나에서 개별 cluster로 divide
    &lt;ul&gt;
      &lt;li&gt;Start with one, all-inclusive cluster&lt;/li&gt;
      &lt;li&gt;At each step, split a cluster until each cluster contains a point (or there are k clusters)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Traditional hierarchical algorithms use a similarity or distance matrix&lt;/p&gt;

    &lt;p&gt;similarity와 distance는 서로 역수 관계&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Merge or split one cluster at a time&lt;/p&gt;

        &lt;p&gt;Merge/split하는 방식을 hierarchical clustering이라고 함&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;agglomerative-clustering&quot;&gt;Agglomerative clustering&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;supervised : data label 제공 / unsupervised : data label 미제공
    &lt;ul&gt;
      &lt;li&gt;→ labeling해서 classification, regression 수행&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;clustering : hierarchical process로 data 분석하기도 하고&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이상 전기 신호를 어떻게 구분할 것인가 (classification) 해야 하는데 이에 대한 label이 없음&lt;/p&gt;

&lt;p&gt;몇 년치 data를 labeling하기도, 분석도 바로 못 들어감.&lt;/p&gt;

&lt;p&gt;→ 평균치보다 크거나 작은 값을 군집화하여 이상신호를 보고 판단하고 labeling 수작업&lt;/p&gt;

&lt;p&gt;정상과 비정상의 label에 대하여 이후 들어오는 data들에 대하여 수작업 (supervised)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Agglomerative clustering
    &lt;ul&gt;
      &lt;li&gt;First merge very similar instances
        &lt;ul&gt;
          &lt;li&gt;비슷한 data끼리 grouping : 처음에는 모든 data pt가 개별 cluster로 되고 점차 하나의 group이 될 때까지 group화&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Incrementally build larger clusters out of smaller clusters
        &lt;ul&gt;
          &lt;li&gt;가장 similarity가 큰 data끼리 group화함 :
            &lt;ul&gt;
              &lt;li&gt;1,3을 하나의 group으로 묶고 2, 5 group으로 묶이게 되면 1st-2nd group간 거리는 가장 가까운 거리로 할 것인지 (1-2) 먼 거리로 할 것인지 (3-5) 평균으로 할 것인지에 따라, similarity 판단 기준에 따라 clustering이 다르게 됨&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Algorithm:
    &lt;ul&gt;
      &lt;li&gt;Maintain a set of clusters, Initially, each instance in its own cluster&lt;/li&gt;
      &lt;li&gt;Repeat:
        &lt;ul&gt;
          &lt;li&gt;Pick the two closest clusters&lt;/li&gt;
          &lt;li&gt;Merge them into a new cluster&lt;/li&gt;
          &lt;li&gt;Stop when there’s only one cluster left&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Produces not one cluster, but a family of clusters represented by a dendrogram&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_22.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;How should we define “close” for clusters with multiple elements?
    &lt;ul&gt;
      &lt;li&gt;similarity를 어떻게 판단할 것인가  =(distance를 어떻게 계산할 것인가)&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;closest / Farthest / Average → cluster가 달라지게 됨&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;12/Untitled_23.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Many options:
    &lt;ul&gt;
      &lt;li&gt;Closest pair (single-link clustering)&lt;/li&gt;
      &lt;li&gt;Farthest pair (complete-link clustering)&lt;/li&gt;
      &lt;li&gt;Average of all pairs&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Different choices create different clustering behaviors&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;strengths-of-hierarchical-clustering&quot;&gt;Strengths of Hierarchical Clustering&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;No assumptions on the number of clusters
    &lt;ul&gt;
      &lt;li&gt;cluster 개수 가정하고 수행하게 됨&lt;/li&gt;
      &lt;li&gt;단) cluster 개수 잘못 예측하면 algorithm 좋지 않은 결과를 낼 것&lt;/li&gt;
      &lt;li&gt;Any desired number of clusters can be obtained by ‘cutting’ the dendogram at the proper level&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Hierarchical clusterings may correspond to meaningful taxonomies
    &lt;ul&gt;
      &lt;li&gt;cluster 몇 개인지 모르는 상태에서 clustering&lt;/li&gt;
      &lt;li&gt;clustering : dendrogram 그려서 duration 긴 구간을 판단하여 cluster 개수 결정 / 적절한 상태에서 dendrogram cutting&lt;/li&gt;
      &lt;li&gt;대칭적 분류 : phylogeny. Catalog&lt;/li&gt;
      &lt;li&gt;Example in biological sciences (e.g., phylogeny reconstruction, etc), web (e.g., product catalogs), etc.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;complexity-of-hierarchical-clustering&quot;&gt;Complexity of hierarchical clustering&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Distance matrix is used for deciding which clusters to merge/split
    &lt;ul&gt;
      &lt;li&gt;distance &amp;lt;-&amp;gt; proximity&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;data point n개가 있다면, n by n개 distance를 모두 계산함 : n^2 연산
    &lt;ul&gt;
      &lt;li&gt;At least quadratic in the number of data points
        &lt;ul&gt;
          &lt;li&gt;Not usable for large datasets&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;group화가 진행되며 Matrix 크기가 점차 줄어들게 되어 최종적으로 하나의 block만 남게 됨&lt;/p&gt;

&lt;h1 id=&quot;agglomerative-clustering-algorithm&quot;&gt;Agglomerative clustering algorithm&lt;/h1&gt;

&lt;p&gt;Data point distance metric계산하고 각각의 data point가 개별 cluster로 여겨지고 Closest cluster끼리 merge되고 (방법에는 최단/최대/평균)&lt;/p&gt;

&lt;p&gt;Compute the distance matrix between the input data points Let each data point be a cluster Repeat Merge the two closest clusters Update the distance matrix Until only a single cluster remains&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Key operation is the computation of the distance between two clusters&lt;/li&gt;
  &lt;li&gt;Different definitions of the distance between clusters lead to different algorithms Clustering&lt;/li&gt;
  &lt;li&gt;Most popular hierarchical clustering technique&lt;/li&gt;
  &lt;li&gt;Basic algorithm&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;input-initial-setting&quot;&gt;Input/ Initial setting&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_24.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;n Start with clusters of individual points and a distance/proximity matrix&lt;/p&gt;

&lt;h2 id=&quot;intermediate-state&quot;&gt;Intermediate State&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;After some merging steps, we have some clusters
    &lt;ul&gt;
      &lt;li&gt;&lt;/li&gt;
      &lt;li&gt;clustering이 진행되면 group화 진행&lt;/li&gt;
      &lt;li&gt;처음에 data point 12개여서 12&lt;em&gt;12
  -&amp;gt; clustering되어 5&lt;/em&gt;5&lt;/li&gt;
      &lt;li&gt;data dimension이 커지면 거리 계산에 어려움&lt;/li&gt;
      &lt;li&gt;dimension별 scaling : K nearest neighbor에서 고려해야 함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_25.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Merge the two closest clusters (C2 and C5) and update the distance matrix&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;12/Untitled_26.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;How do we update the distance matrix?&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;12/Untitled_27.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;distance-between-two-clusters&quot;&gt;Distance between two clusters&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Each cluster is a set of points&lt;/li&gt;
  &lt;li&gt;How do we define distance between two sets of points&lt;/li&gt;
  &lt;li&gt;Lots of alternatives&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Not an easy task&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Single-link distance between clusters Ci and Cj is the minimum distance between any object in Ci and any object in Cj
    &lt;ul&gt;
      &lt;li&gt;Single link : shortest distance&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The distance is defined by the two most similar objects&lt;/p&gt;

\[D _{s l} ( C _i , C _j ) = \min _{x , y} (d ( x , y )| x \in C _i , y \in C _j )\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;single-link-clustering-example&quot;&gt;Single-link clustering: example&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Determined by one pair of points, i.e., by one link in the proximity graph&lt;/p&gt;

    &lt;p&gt;Diagonal value를 보고 판단할 수 있음&lt;/p&gt;

    &lt;p&gt;같은 요소에 대한 값이 1-&amp;gt; similarity&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;data 분포에 의하면 1,2,3,4,5 clustering&lt;/li&gt;
      &lt;li&gt;symmetric : 대각선 아래 부분은 크게 의미가 없음&lt;/li&gt;
      &lt;li&gt;값이 높은 순대로 먼저 cluster를 형성하게 됨&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_28.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_29.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Can handle non-elliptical shapes&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;12/Untitled_30.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Sensitive to noise and outliers&lt;/li&gt;
  &lt;li&gt;It produces long, elongated clusters&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_31.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;distance-between-two-clusters-1&quot;&gt;Distance between two clusters&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Complete-link distance between clusters Ci and Cj is the maximum distance between any object in Ci and any object in Cj&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The distance is defined by the two most dissimilar objects&lt;/p&gt;

    &lt;p&gt;가장 먼 거리의 simple pair에 대해서 data를 clustering (Most dissimilar)&lt;/p&gt;

    &lt;p&gt;Most similar&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[D _{s l} ( C _i , C _j ) = \max _{x , y} (d ( x , y )| x \in C _i , y \in C _j )\]

&lt;h2 id=&quot;complete-link-clustering-example&quot;&gt;Complete-link clustering: example&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Distance between clusters is determined by the two most distant points in the different clusters&lt;/p&gt;

    &lt;p&gt;거리 판단한 이후(차이-dissimilar)
  cluster끼리 병합할 때는 가장 가까운 것 끼리 (동일)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_32.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_33.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;More balanced clusters (with equal diameter)&lt;/p&gt;

    &lt;p&gt;Balance : separation이 조금 더 명확해졌고 cluster의 크기가 비슷하게 분류됐고, noise에 대해서 약간 덜 예민해짐&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Less susceptible to noise&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_34.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tends to break large clusters&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;All clusters tend to have the same diameter – small clusters are merged with larger ones&lt;/p&gt;

    &lt;p&gt;큰 cluster를 작게 쪼개려고 하는 성질&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;cluster크기가 커지면 다른 sample들과 계산하건 거리가 크게 나옴 : 큰 덩어리가 분할되는 결과를 가져옴&lt;/li&gt;
      &lt;li&gt;전체 cluster들이 비슷한 결과&lt;/li&gt;
      &lt;li&gt;작은 cluster들이 큰 것을 흡수&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_35.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;distance-between-two-clusters-2&quot;&gt;Distance between two clusters&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Group average distance between clusters Ci and Cj is the average distance between any object in Ci and any object in Cj
    &lt;ul&gt;
      &lt;li&gt;전체 data pair의 average 이용&lt;/li&gt;
      &lt;li&gt;I cluster , j cluster : 평균 distance 계산한 후 shortest path 결정&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[D_{avg} (C_i, C_j) = \frac 1 {|C_i| \times |C_j| } \Sigma_{x\in C_i, y \in C_j} d(x,y)\]

&lt;h1 id=&quot;average-link-clustering-example&quot;&gt;Average-link clustering: example&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Proximity of two clusters is the average of pairwise proximity between points in the two clusters.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_36.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Average distance의 길이가 짧을수록 stable cluster&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_37.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;average-link-clustering-discussion&quot;&gt;Average-link clustering: discussion&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Compromise between Single and Complete Link&lt;/li&gt;
  &lt;li&gt;Strengths
    &lt;ul&gt;
      &lt;li&gt;Less susceptible to noise and outliers&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Limitations
    &lt;ul&gt;
      &lt;li&gt;Biased towards globular clusters 각각의 cluster를 구 형태로 만드려는 특성&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;hierarchical-clustering-comparison&quot;&gt;Hierarchical Clustering: Comparison&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;최종 cluster는 동일&lt;/li&gt;
  &lt;li&gt;중간 cluster에서는 계산 방식이 다르기 때문에 다른 형태&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_38.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;divisive-hierarchical-clustering&quot;&gt;Divisive hierarchical clustering&lt;/h1&gt;

&lt;p&gt;Top-down : global (optimal)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;한 번에 하나의 cluster를 split : which to divide&lt;/li&gt;
  &lt;li&gt;calculation 많아짐&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Bottom-up : local (heuristic, greedy)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;개별 data를 각각의 cluster -&amp;gt; 점차 Merge하며 하나의cluster&lt;/li&gt;
  &lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Divisive top down&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;detailed cluster로 split recursively&lt;/li&gt;
  &lt;li&gt;사용할 dimension, variable의 개수 정도&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;monotheistic : 한 번에 한 개&lt;/p&gt;

&lt;p&gt;polytheistic : 여러 dim/var을 한 번에&lt;/p&gt;

&lt;p&gt;(Univariate / multivariate)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;distance measure metric : 수치 등의 기준&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;1 : n-1 (n)/ 2: n-2 (nC2)/ … 경우의 수를 따져볼 수 있고 최종적으로 하나의 Cluster&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;가장 적합한 split을 선택&lt;/li&gt;
  &lt;li&gt;모든 경우의수 따져보면 bottom up보다 더 많이 연산을 요구할 것인지는 차이가 있을 수 있음&lt;/li&gt;
  &lt;li&gt;일반적으로 agglomerative bottom-up방식 사용 : dendrogram방식으로 다양한 단계에서의 Clustering을 수행하며 정보를 얻고 취합하여 최종 Cluster 결과 선정 가능&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;현재 상태의 cluster에서 가장 가짜운 Cluster과 Merge : optimal보다는 heuristic, Greedy (전체 objective를 최적화하는 global의 개념은 아님-너무 연산 많아짐)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Start with a single cluster composed of all data points&lt;/li&gt;
  &lt;li&gt;Split this into components&lt;/li&gt;
  &lt;li&gt;Continue recursively&lt;/li&gt;
  &lt;li&gt;Monothetic divisive methods split clusters using one variable/dimension at a time&lt;/li&gt;
  &lt;li&gt;Polythetic divisive methods make splits on the basis of all variables together&lt;/li&gt;
  &lt;li&gt;Any intercluster distance measure can be used&lt;/li&gt;
  &lt;li&gt;Computationally intensive, less widely used than agglomerative methods&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_39.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Initially, all points in the dataset belong to one single cluster&lt;/li&gt;
  &lt;li&gt;Partition the cluster into two least similar cluster&lt;/li&gt;
  &lt;li&gt;Proceed recursively to form new clusters until the desired number of clusters is obtained Clustering Divisive hierarchical 53&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;12/Untitled_40.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Check the sum of squared errors of each cluster and choose the one with the largest value.&lt;/li&gt;
  &lt;li&gt;In the dataset below, the data points are separated into 2 clusters&lt;/li&gt;
  &lt;li&gt;For further separating it to form the 3rd cluster, find the sum of squared errors (SSE) for each cluster&lt;/li&gt;
  &lt;li&gt;The cluster with the largest SSE value is separated into 2 clusters&lt;/li&gt;
&lt;/ul&gt;</content><author><name>KyuHwan Shim</name><email>skh7343@cnsh.hs.kr</email></author><category term="ml" /><category term="ML" /><category term="AI" /><category term="Lecture" /><summary type="html">Chap12.Clustering</summary></entry><entry xml:lang="en"><title type="html">[SP] 12. Linking</title><link href="http://localhost:4000/blog/12-sp-linking/" rel="alternate" type="text/html" title="[SP] 12. Linking" /><published>2022-06-11T12:26:09+09:00</published><updated>2022-06-11T12:26:09+09:00</updated><id>http://localhost:4000/blog/12-sp-linking</id><content type="html" xml:base="http://localhost:4000/blog/12-sp-linking/">&lt;h1 id=&quot;12-linking&quot;&gt;12. Linking&lt;/h1&gt;

&lt;h1 id=&quot;linking&quot;&gt;Linking&lt;/h1&gt;

&lt;h2 id=&quot;whats-linking&quot;&gt;What’s linking?&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;A process of collecting and combining various pieces of code and data into a single file that can be loaded (copied) into memory and executed
여러 코드와 데이터를 모아 memory에 load될 수 있고 executable file 하나로 만드는 작업
    &lt;ul&gt;
      &lt;li&gt;큰 규모의 프로그램을 한 개의 소스 파일로 구성하는 대신&lt;/li&gt;
      &lt;li&gt;별도로 editable, compilable smaller module로 나눌 수 있음&lt;/li&gt;
      &lt;li&gt;edit할 때 단순히 해당 파일을 recompile하고 다른 file을 recompile할 필요 없이 link함.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;작은 프로그램을 만든다고 하면 linking이 필요 없지만 큰 프로그램을 만들면 잘게 잘게 기능을 나누어 쪼갤 필요가 있다.&lt;/li&gt;
  &lt;li&gt;Linking can be performed at compile time, load time, and run time
    &lt;ul&gt;
      &lt;li&gt;compile time 시 수행 - src code는 기계어로 translate됨&lt;/li&gt;
      &lt;li&gt;load time - application program에 의해 수행&lt;/li&gt;
      &lt;li&gt;run time&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Linking is performed automatically by programs called linkers on modern systems
    &lt;ul&gt;
      &lt;li&gt;초기에는 수동으로 수행된 linking → 현재는 linker가 대신 수행해줌&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;why-bother-learning-about-linking&quot;&gt;Why bother learning about linking?&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Understanding linkers will help you&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;build-large-programs-큰-프로그램-작성에-도움&quot;&gt;build large programs 큰 프로그램 작성에 도움&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Unless you understand how a linker resolve references, what a library is, and how a linker uses a library to resolve references, these kinds of errors will be baffling and frustrating.&lt;/li&gt;
  &lt;li&gt;발생되는 linker error들에 대한 식견&lt;/li&gt;
  &lt;li&gt;작은 프로그램 compile하고 linking하는 과정
    &lt;ul&gt;
      &lt;li&gt;local + external defined symbol들을 어떻게 reference할 수 있느냐.&lt;/li&gt;
      &lt;li&gt;Malloc / printf reference : 어떻게 library를 활용하여 reference하느냐&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;linux에서 직접 link해보면 link error가 많이 뜨는데 이해하기 쉬워질 것&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;avoid-dangerous-programming-errors-위험한-에러를-피할-수-있음&quot;&gt;avoid dangerous programming errors 위험한 에러를 피할 수 있음&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Programs that incorrectly define multiple global variables can pass through the linker without any warnings in the default case. The resulting programs can exhibit baffling run-time behavior and are extremely difficult to debug.&lt;/li&gt;
  &lt;li&gt;global var을 여러 분야에서 잘못 선언 : run-time시에 여러 문제가 생길 수 있음&lt;/li&gt;
  &lt;li&gt;linker에서 잡아주지 못하는 / linker의 기능과 방식 을 잘 이해하지 못한 상태에서 runtime 때 찾기는 어렵다
    &lt;ul&gt;
      &lt;li&gt;debug하기도 어려운 상황에서→ 어떻게 권장하는지를 보고 어떻게 발생하고 회피하는지 알 수 있음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;understand-how-language-scoping-rules-are-implemented&quot;&gt;understand how language scoping rules are implemented&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;What’s the difference between global and local variables? (전역 vs 지역)&lt;/li&gt;
  &lt;li&gt;What does it really mean when you define a variable or function with the &lt;strong&gt;static&lt;/strong&gt; attribute?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;understand-other-important-systems-concepts&quot;&gt;understand other important systems concepts&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;The executable object files produced by linkers play key roles in important systems functions such as loading and running programs, virtual memory, paging, and memory mapping&lt;/li&gt;
  &lt;li&gt;system의 중요한 여러 개념들을 이해하는 데 도움&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;enable-you-to-exploit-shared-libraries&quot;&gt;enable you to exploit shared libraries&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;With the increased importance of shared libraries and dynamic linking in modern operating systems, linking is a sophisticated process that provides the knowledgeable programmer with significant power.
현대 사회에서 중요해진 shared library, dynamic linking의 중요성 → 주요 능력을 제공하는 process
    &lt;ul&gt;
      &lt;li&gt;쉬우면서도 간과하는 부분이 많은 linking&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;For example, many software products use shared libraries to upgrade shrink-wrapped binaries at run time.
    &lt;ul&gt;
      &lt;li&gt;shared library : dynamic linking 다양하게 쓰임&lt;/li&gt;
      &lt;li&gt;smaller하게 된 binary를 runtime때 upgrade&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Many Web servers rely on dynamic linking of shared libraries to serve dynamic content.5
    &lt;ul&gt;
      &lt;li&gt;많은 sw들은 runtime 시에 linking많이 씀 : service할 때 동적으로 mapping&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;example-c-program&quot;&gt;Example C Program&lt;/h2&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;각각에 대해서 linking을 수행하여 하나의 executable file&lt;/li&gt;
  &lt;li&gt;sum이라는 procedure는 sum.c로부터 reference하여 구동시켜 Main 함수에서 integer array&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;static-linking&quot;&gt;Static Linking&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Programs are translated and linked using a compiler driver:&lt;/p&gt;

    &lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gcc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Og&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prog&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prog&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;compiler-driver&quot;&gt;Compiler driver&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Preprocessor, compiler, assembler, linker를 필요에 따라 user 대신하여 호출&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/underthelights/underthelights.github.io/main/_posts/SP/12/Untitled.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;C preprocessor (cpp) : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;main.c&lt;/code&gt; → &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;main.i&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;translates the C source file main.c into an ASCII intermediate file main.i&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;C Compiler (cc1) : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;main.i&lt;/code&gt; → &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;main.s&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;translates main.i into an ASCII assembly-language file main.s&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Assembler (as)&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;main.s&lt;/code&gt; → &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;main.o&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;translates main.s into a binary relocatable object file main.o&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Linker (ld)
    &lt;ul&gt;
      &lt;li&gt;combine main.o and sum.o along with the necessary object files,to create the binary executable object file&lt;/li&gt;
      &lt;li&gt;ld 실행 : prog을 생성하기 위해 main.o / sum.o 연결&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;→ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;./prog&lt;/code&gt; : prog 실행&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Shell은 loader라는 OS Function을 호출하여, 실행 파일 prog의 code, data를 memory로 복사하고 control을 program 시작 부분으로 전환한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Source File
    &lt;ul&gt;
      &lt;li&gt;각 symbol들의 주소, access하는 주소
  memory할 때 어디에 올라가는지
  VM에서 어디 부분에 올라가는지 등은 잘 정해져 있지 않기 때문에 relocate필요&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Separately compiled relocatable obj files
    &lt;ul&gt;
      &lt;li&gt;linking해야지 virtual memory 상 어디에 올라가는지 상대적인 offset 부분을 나중에 알 수 있기 때문에, 나중에 relocate되는 obj file이라고 부른다.
  그러고 나서 나중에 linking되게 되면 실행 file 생성&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Fully linked&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;why-linkers&quot;&gt;Why Linkers?&lt;/h2&gt;

&lt;h3 id=&quot;reason-1-modularity&quot;&gt;Reason 1: Modularity&lt;/h3&gt;

&lt;p&gt;Program can be written as a collection of smaller source files, rather than one monolithic mass.
구조적으로 쪼개서 작은 source file로 만든다 → 내가 필요한 부분들만 쓸 수 있게 하는데 도움이 된다&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Can build libraries of common functions (more on this later)
    &lt;ul&gt;
      &lt;li&gt;Standard c library, math library : 다른 application에서도 사용 가능&lt;/li&gt;
      &lt;li&gt;e.g., Math library, standard C library&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reason-2-efficiency&quot;&gt;Reason 2: Efficiency&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Time: Separate compilation
    &lt;ul&gt;
      &lt;li&gt;sum.c code만 수정하고 sum.c만 recompile&lt;/li&gt;
      &lt;li&gt;monolithic한 프로그램이 아니라면 코드 전체를 모두 compile하는 것보다 더 빨라짐&lt;/li&gt;
      &lt;li&gt;Change one source file, compile, and then relink.&lt;/li&gt;
      &lt;li&gt;No need to recompile other source files.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Space: Libraries
    &lt;ul&gt;
      &lt;li&gt;Common functions can be aggregated into a single file…
        &lt;ul&gt;
          &lt;li&gt;하나의 compile로 만들어질 수 있음&lt;/li&gt;
          &lt;li&gt;모두다 사용하는게 아니고, 특정한 부분만 사용할 수 있기 때문에 필요한 특정한 부분만 사용하는거기 때문에 필요에 따라 linker를 돌아 사용하는게 효과적&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Yet executable files and running memory images contain only code for the functions they actually use.
        &lt;ul&gt;
          &lt;li&gt;memory에 다 올라갈 필요가 없음 → powerful software programming&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;what-do-linkers-do&quot;&gt;What Do Linkers Do?&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;to make executable file → linker는 두 가지 step task를 수행해야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-1-symbol-resolution&quot;&gt;Step 1: Symbol resolution&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Programs define and reference symbols (global variables and functions):
    &lt;ul&gt;
      &lt;li&gt;program 내부에서 여러 symbol을 가져다가 reference&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;swap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{...}&lt;/span&gt; &lt;span class=&quot;cm&quot;&gt;/* define symbol swap */&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;swap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;cm&quot;&gt;/* reference symbol swap */&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;cm&quot;&gt;/* define symbol xp, reference x */&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;Swap function definition - reference&lt;/li&gt;
      &lt;li&gt;xp라는 symbol : x라는 variable의 address value&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Symbol definitions are stored in object file (by assembler) in symbol table.
    &lt;ul&gt;
      &lt;li&gt;Symbol table is an array of structs → Executable file 생성 이전 object file : section에 symbol table이 들어감.
        &lt;ul&gt;
          &lt;li&gt;Each entry includes name, size, and location of symbol.&lt;/li&gt;
          &lt;li&gt;compile시 preprocess다음 c compile하여 obj 파일 만들어질 때 elf라는 file format에서 symbol table 안에 저장되는데 각 symbol마다 크기, 이름, 위치 생성 정보를 가진 table&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;During symbol resolution step, the linker associates each symbol reference with exactly one symbol definition.&lt;/strong&gt; symbol이 있으면 각각의 reference가 정확히 하나의 symbol definition과 대응되어야 한다.
    &lt;ul&gt;
      &lt;li&gt;cnt가 두 번 initialized -&amp;gt; linker error&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(){&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;…&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    
  &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; 
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Fun&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(){&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;…&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-2-relocation&quot;&gt;Step 2: Relocation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Merges separate code and data sections into single sections
    &lt;ul&gt;
      &lt;li&gt;두개의 다른 object file (code/data)를 모아 하나의 section으로 만emsek.&lt;/li&gt;
      &lt;li&gt;0번지에서 시작하는 code, data section&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Executable file로 linux가 만들게 되는데 memory location에 올라가는 절대 주소로 변환 : 실제 가상메모리 주소는 어떻게 할 것이냐
    &lt;ul&gt;
      &lt;li&gt;Relocates symbols from their relative locations in the .o files to their final absolute memory locations in the executable.&lt;/li&gt;
      &lt;li&gt;linker : code/data section을 symbol def과 연결 → relocate하며 모든 reference를 모두 수정하여 절대주소를 가리키도록 함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;relocation entry : symbol에 대한 모든 reference 가 새로운 위치를 가리킬 수 있게 해 줌
    &lt;ul&gt;
      &lt;li&gt;Updates all references to these symbols to reflect their new positions.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let’s look at these two steps in more detail….&lt;/p&gt;

&lt;h1 id=&quot;three-kinds-of-object-files-modules&quot;&gt;Three Kinds of Object Files (Modules)&lt;/h1&gt;

&lt;h3 id=&quot;relocatable-object-file-o-file&quot;&gt;Relocatable object file (.o file)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Contains code and data in a form that can be combined with other relocatable object files to form executable object file.&lt;/li&gt;
  &lt;li&gt;Each .o file is produced from exactly one source (.c) file&lt;/li&gt;
  &lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Main.o, .o&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;code, data를 가지고 있는데 다른 relocatable file과 같이 compile되어 실행 file을 만들기 위한 code, data를 가진 object file&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;executable-object-file-aout-file&quot;&gt;Executable object file (a.out file)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Contains code and data in a form that can be copied directly into memory and then executed.&lt;/li&gt;
  &lt;li&gt;명명 of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a.out&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;BELL Lab에서 compile하고 executable file 이름을 지정하지 않을 때 a.out으로 명명&lt;/li&gt;
      &lt;li&gt;특정한 의미는 없음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;shared-object-file-so-file&quot;&gt;Shared object file (.so file)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Special type of relocatable object file that can be loaded intomemory and linked dynamically, at either load time or run-time.&lt;/li&gt;
  &lt;li&gt;Called Dynamic Link Libraries (DLLs) by Windows13&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;executable-and-linkable-format-elf&quot;&gt;Executable and Linkable Format (ELF)&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Standard binary format for object files&lt;/li&gt;
  &lt;li&gt;One unified format for
    &lt;ul&gt;
      &lt;li&gt;Relocatable object files (.o),&lt;/li&gt;
      &lt;li&gt;Executable object files (a.out)&lt;/li&gt;
      &lt;li&gt;Shared object files (.so)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Generic name: ELF binaries&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/183250682-b6613650-3d77-4763-bff1-40350dc3536a.png&quot; alt=&quot;Untitled 1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;elf-header-16-b&quot;&gt;Elf header (16 B)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Describes word size, byte ordering, file type (.o, exec, .so), machine type, file offset of section header table, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-header-table&quot;&gt;Section header table&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Offsets and sizes of each section&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/183250683-f504e0b1-4b05-4b72-9ae9-05fca5097165.png&quot; alt=&quot;Untitled 2&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;text-section&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.text&lt;/code&gt; section&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Code (the machine code of the compiledprogram)&lt;/li&gt;
  &lt;li&gt;compile된 program의 기계어 code가 들어가 있음&lt;/li&gt;
  &lt;li&gt;c compile후 assembly에 의해 기계어 코드 (add, multiply, load, store에 대한 assembly에 대한 기계어 코드가 들어가 있음)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;rodata-section&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.rodata&lt;/code&gt; section&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Read only data: jump tables for switch&lt;/li&gt;
  &lt;li&gt;Read only data section : read only data, jump table, format string 가지고 있음&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;data-section&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.data&lt;/code&gt; section&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Initialized global variables
    &lt;ul&gt;
      &lt;li&gt;Initialized global var : int count = 6;&lt;/li&gt;
      &lt;li&gt;Local variable static : static int a =3;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;bss-section&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.bss&lt;/code&gt; section&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Uninitialized global variables&lt;/p&gt;

    &lt;p&gt;아직은 yet initialized : 위치만을 가지고 잇음 (공간 할당 x)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;이름 : “Block Started by Symbol”, “Better Save Space”&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;initialize된 global var을 구분함으로서 공간을 할당하지만 .bss는 공간을 할당하지 않아 공간 효용성을 구분할 수 있음 →Has section header but occupies no space&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;나중에 memory에 load될 때는 0으로 초기화 : 그 때의 메모리 공간 생성&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/183250686-1347cb96-2326-42d5-96f4-dd7f5eaf6f40.png&quot; alt=&quot;Untitled 3&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;symtab-section&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.symtab&lt;/code&gt; section&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Symbol table with info. about functions and global variables (procedures and static variable names) that are defined and referenced in the program-&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reltextsection&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.rel.text&lt;/code&gt;section&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Relocation info for .text section&lt;/li&gt;
  &lt;li&gt;Addresses of instructions that will need to be modified in the executable
    &lt;ul&gt;
      &lt;li&gt;Instructions for modifying.-&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reldatasection&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.rel.data&lt;/code&gt;section&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Relocation info for .data section&lt;/li&gt;
  &lt;li&gt;Addresses of pointer data that will need to be modified in the merged executable-&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;debug-section&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.debug&lt;/code&gt; section&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Info for symbolic debugging (gcc -g)ELF header.text section.rodata section.data section.bss section.symtab section.rel.txt section.rel.data section.debug sectionSection header table18&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;symbols-and-symbol-tables&quot;&gt;Symbols and Symbol Tables&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Each relocatable object module, m, has a symbol table
    &lt;ul&gt;
      &lt;li&gt;각각의 relocatable object (module) : 어떠한 module에 의해 reference / define되어 있는 symbol에 대한 정보를 가진 symbol table이 가진 정보&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The symbol table contains information about the symbols that are defined and referenced by m&lt;/li&gt;
  &lt;li&gt;In the context of a linker, there are three different kinds of symbols:
    &lt;ul&gt;
      &lt;li&gt;Global symbols&lt;/li&gt;
      &lt;li&gt;External symbols&lt;/li&gt;
      &lt;li&gt;Local symbols&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;linker-symbols&quot;&gt;Linker Symbols&lt;/h2&gt;

&lt;h3 id=&quot;global-symbols&quot;&gt;Global symbols&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Symbols defined by module m that can be referenced by other modules.&lt;/li&gt;
  &lt;li&gt;E.g.: non-static C functions and non-static global variables.
    &lt;ul&gt;
      &lt;li&gt;다른 module에 의해 reference될 수 있는 global variable
  a.c/Int count = 5
  b.c/Int count;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;external-symbols&quot;&gt;External symbols&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Global symbols that are referenced by module m but defined by some other module.&lt;/li&gt;
  &lt;li&gt;module에 의해서 reference되는 symbol이지만 다른 module에 의해서 defined되어 있는 것
    &lt;ul&gt;
      &lt;li&gt;a.c입장에서 b.c.의 count symbol&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;local-symbols&quot;&gt;Local symbols&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Symbols that are defined and referenced exclusively by module m.&lt;/li&gt;
  &lt;li&gt;E.g.: C functions and global variables defined with the static attribute.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Local linker symbols are not local program variables 20&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;local-linker-symbols-vs-local-program-variables&quot;&gt;Local linker symbols vs. Local program variables&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.symtab&lt;/code&gt; does not contain any symbols that correspond to local non-static program variables
    &lt;ul&gt;
      &lt;li&gt;var 중 non static variable들은 Symbol table에 들어가지 않음 / linker에 연관 x&lt;/li&gt;
      &lt;li&gt;Local var : stack / Local symbol : symbol table에 들어감&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Local non-static program variables are managed at run time on the stack and are not of interest to the linker&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;See more details in next slides…&lt;/p&gt;

&lt;h1 id=&quot;step-1-symbol-resolution-1&quot;&gt;Step 1: Symbol Resolution&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/183250687-d356bbb5-0a06-441e-a715-37156b66c00a.png&quot; alt=&quot;Untitled 4&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;local-symbols-1&quot;&gt;Local Symbols&lt;/h2&gt;

&lt;p&gt;Local static var : global variable -&amp;gt; .data&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;단 local var이기 때문에 함수를 다시 호출하게 되면 재접속 가능
Local nonstatic var : static x, 일반 local var -&amp;gt; @stack&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;f, g에서 같은 variable x를 쓰지만 다른 symbol
X.1, x.2 이런식으로 compiler가 놓고 compiler가 unique한 이름을 가지도록 함.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Local non-static C variables vs. local static C variables
    &lt;ul&gt;
      &lt;li&gt;local non-static C variables: stored on the stack&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;local static C variables: stored in either .bss, or .data&lt;/p&gt;

        &lt;p&gt;Local static var : global variable -&amp;gt; .data&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;단 local var이기 때문에 함수를 다시 호출하게 되면 재접속 가능
  Local nonstatic var : static x, 일반 local var -&amp;gt; @stack&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/183250689-46a8e3d6-738c-4157-ba55-5e037051ed86.png&quot; alt=&quot;Untitled 5&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Compiler allocates space in .data for each definition of x&lt;/li&gt;
  &lt;li&gt;Creates local symbols in the symbol table with unique names,
    &lt;ul&gt;
      &lt;li&gt;f, g에서 같은 variable x를 쓰지만 다른 symbol
  → x.1, x.2 이런식으로 compiler가 놓고 compiler가 unique한 이름을 가지도록 함.&lt;/li&gt;
      &lt;li&gt;e.g., x.1 and x.2&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-linker-resolves-duplicate-symbol-definitions&quot;&gt;How Linker Resolves Duplicate Symbol Definitions&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Program symbols are either strong or weak&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Strong:&lt;/strong&gt; procedures and initialized globals
    &lt;ul&gt;
      &lt;li&gt;initialize되어 있는 variable&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Weak:&lt;/strong&gt; uninitialized globals
    &lt;ul&gt;
      &lt;li&gt;uninitialize되어 있는 variable&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/183250690-9fb87e46-e2a7-45d4-93e5-48b1c7529ec5.png&quot; alt=&quot;Untitled 6&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;linkers-symbol-rules&quot;&gt;Linker’s Symbol Rules&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Rule 1: Multiple strong symbols are not allowed&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Each item can be defined only once&lt;/li&gt;
      &lt;li&gt;Otherwise: Linker error&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;만일 symbol이 strong하다 - 단 한번만 선언 가능&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;compiler가 보고 나서 foo=5(p1.c) / foo=10(p2.c) -&amp;gt; link error&lt;/li&gt;
      &lt;li&gt;같은 게 strong이면 안됨&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rule 2: Given a strong symbol and multiple weak symbols, choose the strong symbol&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;References to the weak symbol resolve to the strong symbol&lt;/li&gt;
      &lt;li&gt;Weak가 strong을 쫓아간다.&lt;/li&gt;
      &lt;li&gt;P2의 foo : weak-&amp;gt; p1의 foo : strong을 쫓아감
  p2에서 foo 접근 = p1에서의 foo 접근&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rule 3: If there are multiple weak symbols, pick anarbitrary one&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;둘다 weak면 compiler가 임의로 설정&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;rule 1.&lt;/p&gt;

&lt;p&gt;만일 symbol이 strong하다 - 단 한번만 선언 가능&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;compiler가 보고 나서 foo=5(p1.c) / foo=10(p2.c) -&amp;gt; link error&lt;/li&gt;
  &lt;li&gt;같은 게 strong이면 안됨&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Rule 2.&lt;/p&gt;

&lt;p&gt;Weak가 strong을 쫓아간다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;P2의 foo : weak-&amp;gt; p1의 foo : strong을 쫓아감&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;p2에서 foo 접근 = p1에서의 foo 접근&lt;/p&gt;

&lt;p&gt;rule3&lt;/p&gt;

&lt;p&gt;둘다 weak면 compiler가 임의로 설정&lt;/p&gt;

&lt;h2 id=&quot;linker-puzzle&quot;&gt;Linker Puzzle&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/183250691-5ff73093-2555-41c8-9cb5-a04bb1b0dd40.png&quot; alt=&quot;Untitled 7&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;link error - 모종의 이유로 version이 달라 뜨는 error&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/183250693-0ef021f3-20c7-49f5-a820-86e79d39a50e.png&quot; alt=&quot;Untitled 8&quot; /&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/183250696-17586618-91c2-4d30-87d3-5ff032e2fd88.png&quot; alt=&quot;Untitled 9&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;둘 중에 무엇을 선택할 지 모름 (weak)
    &lt;ul&gt;
      &lt;li&gt;1-&amp;gt;2, : y를 overwrite하지 않음 / 2-&amp;gt;1 : overwrite&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;→ ‘might’라는 용어 사용 : 해당 xy가 다른 strong symbol reference할 수 있기 때문이다&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/183250699-1b391410-d480-43ce-99fb-b302d0a32313.png&quot; alt=&quot;Untitled 10&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;double로 선언한 x (8byte) - integer 로 원래 선언된 형태 → y에게도 악영향&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/183250700-f113d77b-3d63-4337-802c-f3294e818c29.png&quot; alt=&quot;Untitled 11&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Nightmare scenario : 2 identical weak structs, compiled by different compilers with different alignment rules (compiler dependent)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;link error&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모종의 이유로 version이 달라 뜨는 error&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;two-weak-definitions-of-x-rule-3&quot;&gt;Two weak definitions of x (rule 3)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Run-time bugs
    &lt;ul&gt;
      &lt;li&gt;Can cause some insidious run-time bugs that are incomprehensible to the unwary programmer&lt;/li&gt;
      &lt;li&gt;compiler error가 발생하지는 않는데&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;둘 다 uninitialized된 형태, f 수행 후 15212로 변화&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/183250702-1ced2849-efda-4cf4-853c-8b035f128403.png&quot; alt=&quot;Untitled 12&quot; /&gt;&lt;/p&gt;
        &lt;h2 id=&quot;another-example-rule-2&quot;&gt;Another example (rule 2)&lt;/h2&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Subtle and nasty run-time bugs!
    &lt;ul&gt;
      &lt;li&gt;On an x86-64/Linux machine, doubles are 8 bytes and ints are 4 bytes&lt;/li&gt;
      &lt;li&gt;Suppose the address of x is 0x601020 and the address of y is 0x601024&lt;/li&gt;
      &lt;li&gt;The assignment x = 0.0 in lin6 6 will overwrite the memory locations for x and y with the double-precision floating-point representation of negative zero!&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/183250703-d65958c6-18e5-4b99-af5b-0c7f1d16461b.png&quot; alt=&quot;Untitled 13&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Compile error 전혀 안 뜸&lt;/li&gt;
      &lt;li&gt;나도 모르게 y값이 바뀜, 그러나 link error를 runtime때 찾기에는 너무 어렵다
        &lt;ul&gt;
          &lt;li&gt;→ 주의깊게 익혀야 한다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;library에서 우연치 않게 같은 symbol을 써서 이상하게 돌아가는 경우도 발생가능&lt;/p&gt;

    &lt;p&gt;Compile error 전혀 안 뜸&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;나도 모르게 y값이 바뀜&lt;/li&gt;
      &lt;li&gt;link error를 runtime때 찾기에는 너무 어렵다&lt;/li&gt;
      &lt;li&gt;
        &lt;blockquote&gt;
          &lt;p&gt;주의깊게 익혀야 한다.&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;library에서 우연치 않게 같은 symbol을 써서 이상하게 돌아가는 경우도 발생가능&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;global-variables&quot;&gt;Global Variables&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Avoid if you can&lt;/li&gt;
  &lt;li&gt;Otherwise
    &lt;ul&gt;
      &lt;li&gt;Use static if you can
        &lt;ul&gt;
          &lt;li&gt;data 에서 선언되지만 해당 함수 내에서만 접근 가능&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Initialize if you define a global variable : initialize해서 가급적 문제가 발생하지 않도록 함.&lt;/li&gt;
      &lt;li&gt;Use extern if you reference an external global variable
        &lt;ul&gt;
          &lt;li&gt;Initialize된 형태로 써라 (쓰지 않을 수 있다면 쓰지 마라)&lt;/li&gt;
          &lt;li&gt;→ 예기치 않은 runtime bug에 빠지지 않도록 해라.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;static 선언&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;data 에서 선언되지만 해당 함수 내에서만 접근 가능&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;initialize해서 가급적 문제가 발생하지 않도록 함.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;extern&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;Initialize된 형태로 써라 (쓰지 않을 수 있다면 쓰지 마라)&lt;/li&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;예기치 않은 runtime bug에 빠지지 않도록 해라.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;step-2-relocation-1&quot;&gt;Step 2: Relocation&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;relocation
    &lt;ul&gt;
      &lt;li&gt;내가 penn university에서 졸업하고 job을 구하면 relocate : relocate negotiation (주소 바뀌는 것에 대한 signing bonus 등)&lt;/li&gt;
      &lt;li&gt;내가 penn university에 있다가 다른 회사 사무소 주소로 바귐&lt;/li&gt;
      &lt;li&gt;이처럼, 내가 현재 접근하는 변수의 주소를 모르기 때문에 relocate하는 과정 : 주소 찾아서 assign해주는 작업&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step1: Symbol resolution&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Once the linker has completed the symbol resolution step, it has associated each symbol reference in the code with exactly one symbol definition
    &lt;ul&gt;
      &lt;li&gt;linker가 symbol resolution step에 따라 resolve하게 되면 모든 symbol reference는 오직 한개의 symbol definition에 associate된다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;At this point, the linker knows the exact sizes of the code and data sections in its input object modules.
    &lt;ul&gt;
      &lt;li&gt;obj file 생성하게 되면 code, data에 대한 정확한 정보를 알게 됨&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;만일 그렇지 않다면 link error&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Now, next step is the relocation step (Step 2)&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Merges the input modules and assigns run-time addresses to eachsymbol&lt;/p&gt;

    &lt;p&gt;두 개의 object module을 병합하여 실제 각각의 symbol에 run time address를 부여해주는 작업&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Moe details will come in the next slides…&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;relocation&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;내가 penn university에서 졸업하고 job을 구하면 relocate : relocate negotiation (주소 바뀌는 것에 대한 signing bonus 등) - 내가 penn university에 있다가 다른 회사 사무소 주소로 바귐&lt;/li&gt;
      &lt;li&gt;내가 현재 접근하는 변수의 주소를 모르기 때문에 relocate하는 과정 : 주소 찾아서 assign해줌&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Symbol resolution 복습&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;linker가 symbol resolution step에 따라 resolve하게 되면 모든 symbol reference는 오직 한개의 symbol definition에 associate된다
    &lt;ul&gt;
      &lt;li&gt;만일 그렇지 않다면 link error&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;obj file 생성하게 되면 code, data에 대한 정확한 정보를 알게 됨&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;relocation step&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;main.c , .c : 두 개의 object module을 병합하여 실제 각각의 symbol에 run time address를 부여해주는 작업&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/183250704-b6b65e72-d191-470e-b186-2c84210bf0ca.png&quot; alt=&quot;Untitled 14&quot; /&gt;&lt;/p&gt;

&lt;p&gt;relocation : 이 세 가지를 하나로 병합하는 과정&lt;/p&gt;

&lt;p&gt;ELF File Format&lt;/p&gt;

&lt;p&gt;.Text / .Data&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;각 symbol에다 address assign하는 것에 대해 알아보자&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;relocation : 이 세 가지를 하나로 병합하는 과정&lt;/li&gt;
  &lt;li&gt;ELF File Format&lt;/li&gt;
  &lt;li&gt;.Text / .Data : 각 symbol에다 address assign하는 것에 대해 알아보자&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;relocation-entries&quot;&gt;Relocation Entries&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;object module : Compiler 내 assembler가 기계어 code를 만들어 내는데 이를 obj module&lt;/li&gt;
  &lt;li&gt;When an assembler generates an object module, it does not know where the code and data will ultimately be stored in memory.: 이를 생성해 낼 때, 1. code, data가 나중에 executible file 생성하는 시점에서 memory 어디에 적재될지 모름&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Nor does it know the location of any externally defined functions of global variables that are referenced by the module.&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;main.c에서 sum이라는 함수는 외부에서 externally defined : sum이라는 함수를 호출할 때 그 위치가 어디인지 모른다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;So, whenever the assembler encounters a reference to an object whose ultimate location is unknown, it generates a relocation entry that tells the linker how to modify the reference when it merges the object file into an executable.&lt;/p&gt;

    &lt;p&gt;→ 결국에는 location 어디인지 모르는 (global var, external function)은 알려져 있지 않기 때문에 relocation entry라고 해서 하나씩 만든다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;ELF file format의 .rel.text / .rel.data에 들어간다&lt;/li&gt;
      &lt;li&gt;Linker에게 ‘이 주소를 잘 모르니까 나중에 다른 obj와 merge되어 executable file만들 때 이 reference를 수정해야 한다’고 알려줌
        &lt;ul&gt;
          &lt;li&gt;.rel을 보고 symbol들이 address가 확인되지 않음을 보고 linking 과정에서 병합하며 그 address를 채워준다&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c0000000000000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;484&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;be9&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bfe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;e813&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;48&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c383ec08&lt;/span&gt; &lt;span class=&quot;mo&quot;&gt;020000&lt;/span&gt; &lt;span class=&quot;mo&quot;&gt;00000000&lt;/span&gt; &lt;span class=&quot;mo&quot;&gt;00&lt;/span&gt; &lt;span class=&quot;mo&quot;&gt;00&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;83&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c40800&lt;/span&gt; &lt;span class=&quot;mo&quot;&gt;0000&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rspmov&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;esimov&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edi&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arraya&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_X86_64_32&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;array&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Relocation&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entrycallq&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;0x13&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_X86_64_PC32&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;0x4&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Relocation&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entryadd&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rspretqmain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;oRelocation&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EntriesSource&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;objdump&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;–&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;–&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o33&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Relocation entries for code are placed in .rel.text.&lt;/li&gt;
  &lt;li&gt;Relocation entries for data are placed in .rel.data. 32&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;relocated-text-section&quot;&gt;Relocated .text section&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/183250705-f1e4b6eb-2f1f-459e-9c3d-5ef33dc938bc.png&quot; alt=&quot;Untitled 15&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Relocation: 앞의 obj module들을 병합한 다음에 각 symbol에 대해 runtime address
    &lt;ul&gt;
      &lt;li&gt;(Vm address O, not physical) E8 05 00 00 00&lt;/li&gt;
      &lt;li&gt;instruction 수행할 때 relative&lt;/li&gt;
      &lt;li&gt;현재 주소 :  PC는 항상 다음 주소 (명령어 fetch하는 그 순간에) PC가 가리키는 주소에 5 더하면 &lt;sum&gt;의 주소가 나온다 :&lt;/sum&gt;&lt;/li&gt;
      &lt;li&gt;상대적인 주소 : detail은 assembler, linking / 2 path scanning을 하기 때문에&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;loading-executable-object-files&quot;&gt;Loading Executable Object Files&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/183250706-9c12a80d-f4e7-40f3-87d2-2ab267602bb3.png&quot; alt=&quot;Untitled 16&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ELF 보면 되고 process address space : 0x400000~2^48 -1 (process)&lt;/li&gt;
  &lt;li&gt;kernel&lt;/li&gt;
  &lt;li&gt;shaerd library : 동적으로 linking 만들어지는 library, API memory map을 위함&lt;/li&gt;
  &lt;li&gt;Heap : break point만큼 heap의 크기&lt;/li&gt;
  &lt;li&gt;segment : r/w data&lt;/li&gt;
  &lt;li&gt;Shared memory 하나 올라오고 Application a, b 뜰 때 필요에 따라 reference함 
(그냥 copy하는게 아님) - c가 shared library라고 할 때 ptr로 그냥 갈 수 있기 때문에 c는 하나만 있으면 되어 duplicate하지 않아도 됨&lt;/li&gt;
  &lt;li&gt;memory mapped region에 대한 ptr가 들어가있는 것.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;packaging-commonly-used-functions&quot;&gt;Packaging Commonly Used Functions&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;How to package functions commonly used by programmers?&lt;/p&gt;

    &lt;p&gt;자주 쓰는 함수 모아둠  - library 형태로 모아 둠&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Math, I/O, memory management, string manipulation, etc.- Awkward, given the linker framework so far:
    &lt;ul&gt;
      &lt;li&gt;memory management : malloc, calloc 등 모아서 자주 쓰니까 어떻게 하나의 패키지로 쓰는가&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Option 1: Put all functions into a single source file
    &lt;ol&gt;
      &lt;li&gt;모든 함수들을 코드들에 집어넣음&lt;/li&gt;
    &lt;/ol&gt;
    &lt;ul&gt;
      &lt;li&gt;Programmers link big object file into their programs&lt;/li&gt;
      &lt;li&gt;Space and time inefficient
        &lt;ul&gt;
          &lt;li&gt;생성되는 executable code 자체가 많이 커짐 → 시간, 공간 많이 차지함&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Option 2: Put each function in a separate source file
    &lt;ol&gt;
      &lt;li&gt;modular 접근 방법처럼 기능 별로 file들을 쪼갠다&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;각 file들에는 특정 기능 수행하는 fn들을 따로 따로 만들어 줌&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;필요한 것만 링킹 - 모든 소스 파일을 다 집어넣을 필요 없음&lt;/li&gt;
      &lt;li&gt;Programmers explicitly link appropriate binaries into their programs&lt;/li&gt;
      &lt;li&gt;More efficient, but burdensome on the programmer36
        &lt;ul&gt;
          &lt;li&gt;효율적이지만 프로그래머가 이해해주어야 함&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;old-fashioned-solution-static-libraries&quot;&gt;Old-fashioned Solution: Static Libraries&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Static libraries (.a archive files)&lt;/li&gt;
  &lt;li&gt;Concatenate related relocatable object files into a single file with an index (called an archive).&lt;/li&gt;
  &lt;li&gt;Enhance linker so that it tries to resolve unresolved external references by looking for the symbols in one or more archives.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If an archive member file resolves reference, link it into the executable.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;static linking - static library&lt;/li&gt;
  &lt;li&gt;archive file&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Object files 들을 concatenate해서 하나의 file로 만듬&lt;/p&gt;

&lt;p&gt;index를 통해 archive 안에 sum, average 등의 함수를 찾아서 참조할 수 있도록 함&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;archive 안에서 symbol 찾아보고 나서 실행 file linking&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;creating-static-libraries&quot;&gt;Creating Static Libraries&lt;/h2&gt;

&lt;p&gt;함수별로 모듈만들어 하나의 archive로 만들어 static link 만들 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/183250707-98680edd-9ce0-44ae-872c-85d0fdfb3030.png&quot; alt=&quot;Untitled 17&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Archiver allows incremental updates-&lt;/li&gt;
  &lt;li&gt;Recompile function that changes and replace .o file in archive.38&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;commonly-used-libraries&quot;&gt;Commonly Used Libraries&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;libc.a (the C standard library)
    &lt;ul&gt;
      &lt;li&gt;4.6 MB archive of 1496 object files.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;I/O, memory allocation, signal handling, string handling, data and time, random numbers, integer mathlibm.a (the C math library)
    &lt;ul&gt;
      &lt;li&gt;2 MB archive of 444 object files.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://o.remove.bg/downloads/13330d44-9549-410f-80b6-80a64b79942b/Untitled_18-removebg-preview.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;linking-with-static-libraries&quot;&gt;Linking with Static Libraries&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;libvector.a&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &quot;vector.h&quot;
&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;addvec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;z = [%d %d]&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;”,z[0], z[1]);&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;    return 0;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;main2.c40&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;void addvec(int *x, int *y, int *z, int n)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;    int i;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;    for (i = 0; i &amp;lt; n; i++)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;z[i] = x[i] + y[i];&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;addvec.c&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;void multvec(int *x, int *y, int *z, int n)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;    int i;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;    for (i = 0; i &amp;lt; n; i++)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;        z[i] = x[i] * y[i];&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;41page - addvec.o는 무엇을 의미하는가:
    &lt;ul&gt;
      &lt;li&gt;Main 함수에서 사용하는 addvec&lt;/li&gt;
      &lt;li&gt;다 올리는 게 아니라 archive라는 utility를 통해서 object concatenate하는 건데 addvec만 사용하기에 이거만 빼서 link한다는 의미이다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;static link : 사용되는 object file 100개를 모아두고 archive처럼 code generation할 때 다 모아서 symbol reolution하고 link하는 것임.
    &lt;ul&gt;
      &lt;li&gt;static linking에서 duplication생기는 이유&lt;/li&gt;
      &lt;li&gt;똑같이 main함수 생성해서 addvec(x,y,z, 3)을 선언해서 넣었다고 하자.
  이 코드들이 생성될 때 addvec.o가 proc2에 포함되어 있다.
  나중에 또 proc3을 생성할 때에도 addvec.o가 들어가 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;using-static-libraries&quot;&gt;Using Static Libraries&lt;/h2&gt;

&lt;h3 id=&quot;linkers-algorithm-for-resolving-external-references&quot;&gt;Linker’s algorithm for resolving external references:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;symbol resolving algorithm : linker가 사용하는 algorithm&lt;/li&gt;
  &lt;li&gt;Scan .o files and .a files in the command line order.&lt;/li&gt;
  &lt;li&gt;During the scan, keep a list of the current unresolved references.&lt;/li&gt;
  &lt;li&gt;As each new .o or .a file, obj, is encountered, try to resolve each unresolved reference in the list against the symbols defined in obj.&lt;/li&gt;
  &lt;li&gt;If any entries in the unresolved list at end of scan, then error.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;problem&quot;&gt;Problem:&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://o.remove.bg/downloads/911ad385-1de8-47ff-9f47-9f0636a7d930/Untitled_19-removebg-preview.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Command line order matters!&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Moral: put libraries at the end of the command line.unix&amp;gt; gcc -L. libtest.o -lmineunix&amp;gt; gcc -L. -lmine libtest.olibtest.o: In function main’: libtest.o(.text+0x4): undefined reference to libfun’42&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Compiler를 통해 example - Gcc -L : object file에서 library에 있는 file을 찾는 것
    &lt;ol&gt;
      &lt;li&gt;Test file + library : test file 안에 선언되어 있는 걸 external reference해서 없으면 library를 ㅁ찾아본다&lt;/li&gt;
    &lt;/ol&gt;
    &lt;ul&gt;
      &lt;li&gt;Test라는 file obj module안에서 없으면 library안에 있으면 해결되기 때문에
        &lt;ol&gt;
          &lt;li&gt;library + test file 넣으면 error가 뜨게 됨. (reference 안되어 있음)&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;-lmine에는 있지만 libtest.o에는 없어서 그 다음으로 넘어가야 하는데 그 다음 file이 존재하지 않으므로 error 발생&lt;/li&gt;
      &lt;li&gt;command line 순서대로 수행 * order가 되게 중요 → library는 맨 뒤&lt;/li&gt;
      &lt;li&gt;scanning하면서 현재 resolve 안된 reference 기록
  그리고 각각에 대해 unresolved reference를 뒤에서 찾아본다 : 있으면 resolve, 없으면 error&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;modern-solution-shared-libraries&quot;&gt;Modern Solution: Shared Libraries&lt;/h1&gt;

&lt;h3 id=&quot;static-libraries-have-the-following-disadvantages&quot;&gt;Static libraries have the following disadvantages:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;dynamic library = shared library&lt;/li&gt;
  &lt;li&gt;Compile time때 static linking을 통한 linking
    &lt;ul&gt;
      &lt;li&gt;지금 돌아가는 executable file이라든지 둘 다 library를 가져다 사용하게 되면 static하게 linking했기 때문에 static이던 running중이던 동일한 file을 본인의 executable에 포함 → 중복된 contents&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Duplication in the stored executables (every function needs libc)
    &lt;ul&gt;
      &lt;li&gt;Duplication in the running executables&lt;/li&gt;
      &lt;li&gt;Minor bug fixes of system libraries require each application to explicitly relink
        &lt;ul&gt;
          &lt;li&gt;bug 수정 :application 수정하고 linking 다시 해야 함&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;modern-solution-shared-libraries-1&quot;&gt;Modern solution: Shared Libraries&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Object files that contain code and data that are loaded and linked
해당 library 부분만 수정해서 되는게 아니라 application을 relink시켜 또 다시 link해야 함&lt;/li&gt;
  &lt;li&gt;into an application dynamically, at either load-time or run-time
    &lt;ul&gt;
      &lt;li&gt;load time, runtime에 동적으로 shared library가 linking됨&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Also called: dynamic link libraries, DLLs, .so files43&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;dynamic library = shared library
    &lt;ul&gt;
      &lt;li&gt;Compile time때 static linking을 통한 linking&lt;/li&gt;
      &lt;li&gt;지금 돌아가는 executable file이라든지 둘 다 library를 가져다 사용하게 되면 static하게 linking했기 때문에 static이던 running중이던 동일한 file을 본인의 executable에 포함 → 중복된 contents&lt;/li&gt;
      &lt;li&gt;bug 수정 :application 수정하고 linking 다시 해야 함&lt;/li&gt;
      &lt;li&gt;해당 library 부분만 수정해서 되는게 아니라 application을 relink시켜 또 다시 link해야 함&lt;/li&gt;
      &lt;li&gt;shared: load time, runtime에 동적으로 shared library가 linking됨&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Library를 여러개 dynamically 사용할 수 있어서 shared&lt;/p&gt;

&lt;p&gt;Loading time, rumtime이 될 수 있음&lt;/p&gt;

&lt;h3 id=&quot;dynamic-linking-can-occur-when-executable-is-first-loaded-and-run-load-time-linking&quot;&gt;Dynamic linking can occur when executable is first loaded and run (load-time linking).&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Common case for Linux, handled automatically by the dynamic linker (&lt;a href=&quot;http://ld-linux.so/&quot;&gt;ld-linux.so&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Standard C library (&lt;a href=&quot;http://libc.so/&quot;&gt;libc.so&lt;/a&gt;) usually dynamically linked.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dynamic-linking-can-also-occur-after-program-has-begun-run-time-linking&quot;&gt;Dynamic linking can also occur after program has begun (run-time linking).&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;In Linux, this is done by calls to the dlopen() interface.&lt;/li&gt;
  &lt;li&gt;Distributing software.&lt;/li&gt;
  &lt;li&gt;High-performance web servers. Runtime library interpositioning.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;shared-library-routines-can-be-shared-by-multiple-processes&quot;&gt;Shared library routines can be shared by multiple processes.&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;More on this when we learn about virtual memory 44&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;dynamic-linking-at-load-time&quot;&gt;Dynamic Linking at Load-time&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://o.remove.bg/downloads/b80de3c1-2553-4188-b5cc-3cb9f16f1c66/Untitled_20-removebg-preview.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;static link : addvec, multvec library 모두 main2.o에 concatenate했어야 했음&lt;/li&gt;
  &lt;li&gt;dynamic link : 사용되는 function 중 main2가 reference하겠다는 note정도만 partly 저장&lt;/li&gt;
  &lt;li&gt;그리고 나서 실제 program 실행할 때 library 해당하는 external reference 되어 있는 name들을 resolve하면서 나중에 loading할 때 dynamic linker에 의해 memory에 올라갈 때 비로소 shared library가 이어짐.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(둘 다 memory에 load되어 있을 때)&lt;/p&gt;

&lt;h2 id=&quot;dynamic-linking-at-run-time&quot;&gt;Dynamic Linking at Run-time&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;dlopen을 사용해서 shaerd library 선언하고 dlsym을 통해 addvec을 pointer로 넘거받음
    &lt;ul&gt;
      &lt;li&gt;그리고 그 함수를 가지고 원래 있는 함수처럼 사용&lt;/li&gt;
      &lt;li&gt;code 실행할 때 linking하겠다 : runtime&lt;/li&gt;
      &lt;li&gt;필요에 따라 memory에 그 때 그때 옮긴다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;dlfcn.h&amp;gt;
&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;handle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;addvec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;cm&quot;&gt;/* Dynamically load the shared library that contains addvec() */&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;handle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dlopen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;./libvector.so&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RTLD_LAZY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;handle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fprintf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stderr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;%s&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dlerror&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;cm&quot;&gt;/* Get a pointer to the addvec() function we just loaded */&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;addvec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dlsym&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;handle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;addvec&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dlerror&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fprintf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stderr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;%s&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;cm&quot;&gt;/* Now we can call addvec() just like any other function */&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;addvec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;z = [%d %d]&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt;
    &lt;span class=&quot;cm&quot;&gt;/* Unload the shared library */&lt;/span&gt; 
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dlclose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;handle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fprintf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stderr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;%s&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dlerror&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;linking-summary&quot;&gt;Linking Summary&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Linking is a technique that allows programs to be constructed from multiple object files.-
    &lt;ul&gt;
      &lt;li&gt;여러 개의 object로 하나의 file을 만들 때 사용됨&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Linking can happen at different times in a program’s lifetime:
언제 하느냐에 따라 /방법에 따라 여러 많은 error들을 확인하여 resolve할 수 있음
    &lt;ul&gt;
      &lt;li&gt;실제 memory 사용량, 실행 시간 등의 장단점을 구분할 수 있음&lt;/li&gt;
      &lt;li&gt;Compile time (when a program is compiled)&lt;/li&gt;
      &lt;li&gt;Load time (when a program is loaded into memory)&lt;/li&gt;
      &lt;li&gt;Run time (while a program is executing)-&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Understanding linking can help you avoid nasty errors and make you a better programmer.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;7-13-case-study-library-interpositioning&quot;&gt;7. 13. Case study: Library interpositioning&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Library interpositioning : powerful linking technique that allows programmers to intercept calls to arbitrary functions&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Interpositioning can occur at:&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Compile time: When the source code is compiled&lt;/li&gt;
      &lt;li&gt;Link time: When the relocatable object files are statically linked to form an executable object file&lt;/li&gt;
      &lt;li&gt;Load/run time: When an executable object file is loaded into memory, dynamically linked, and then executed.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;some-interpositioning-applications&quot;&gt;&lt;strong&gt;Some Interpositioning Applications&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Security
    &lt;ul&gt;
      &lt;li&gt;Confinement (sandboxing)&lt;/li&gt;
      &lt;li&gt;Behind the scenes encryption&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Debugging
    &lt;ul&gt;
      &lt;li&gt;In 2014, two Facebook engineers debugged a treacherous 1-year old bug in their iPhone app using interpositioning&lt;/li&gt;
      &lt;li&gt;Code in the SPDY networking stack was writing to the wrong location&lt;/li&gt;
      &lt;li&gt;Solved by intercepting calls to Posix write functions (write, writev, pwrite)&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Source:  Facebook engineering blog post at https://code.facebook.com/posts/313033472212144/debugging-file-corruption-on-ios/&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Monitoring and Profiling
    &lt;ul&gt;
      &lt;li&gt;Count number of calls to functions&lt;/li&gt;
      &lt;li&gt;Characterize call sites and arguments to functions&lt;/li&gt;
      &lt;li&gt;Malloc tracing
        &lt;ul&gt;
          &lt;li&gt;Detecting memory leaks&lt;/li&gt;
          &lt;li&gt;Generating address traces52&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Developer가 기존의 function들을 본인의 function으로 intercept하여 실행하고 다시 돌아올 수 있도록 하는 기법&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Compile time : src code compile 될 때 interpositioning. Malloc함수 자체를 내가 짠 코드로 interpositioning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Link time : executable file 만들 때&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Load, run time : obj file이 load될 때 동적 link&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;example-program&quot;&gt;Example program&lt;/h2&gt;

&lt;p&gt;32byte 할당하여 tracking&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;compile time에 mymalloc, myfree로 대치&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;지금 배우고 있는 interposition technique&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;compile, link, loadtime 때 할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;malloc.h&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;malloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;free&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Goal: trace the addresses and sizes of the allocated and freed blocks, without breaking the program, and without modifying the source code.&lt;/li&gt;
  &lt;li&gt;Three solutions: interpose on the lib malloc and free functions at compile time, link time, and load/run time.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;compile-time-interpositioning&quot;&gt;Compile-time Interpositioning&lt;/h1&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#ifdef COMPILETIME
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;malloc.h&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;cm&quot;&gt;/* malloc wrapper function */&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mymalloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;malloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;malloc(%d)=%p&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* free wrapper function */&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;myfree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;free&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;free(%p)&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#endif 
#define malloc(size) mymalloc(size)
#define free(ptr) myfree(ptr)
&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mymalloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;myfree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intc&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gcc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wall&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DCOMPILETIME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mymalloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gcc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wall&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;I&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intc&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mymalloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runc&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intc&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;malloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x1edc010&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;free&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x1edc010&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;mymalloc code&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;C library에서 제공해 주는 malloc을 사용한 후 그 다음에 무엇을 할 것이냐 : 기존 c library에서 제공하는 malloc을 사용하는 게 아니라 내가 작성한 mymalloc, myfree로 replace (@compile time) -&amp;gt; 즉, 현재 mymalloc은 기존의 malloc의 wrapper함수처럼 쓰여지는데 앞에 있던 코드에서 malloc을 compile time때 mymalloc/myfree으로 대치되어 실행하도록 할 수 있다.&lt;/li&gt;
  &lt;li&gt;mymalloc/myfree trace하기 위해서 printf code&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;기존에는 malloc에다 ptr을 가져다가 안에서 mymalloc으로 대치함으로써 실제 malloc을 내부적으로 call하지만 tracing위한 printf 삽입하여 - 어떤 block이 alloc/free되었는지 확인&lt;/p&gt;

&lt;p&gt;preprocessing&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;compilie할 때 내부의 malloc이 mymalloc / free가 myfree로 바뀌어 구동되게 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(linux print 결과)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;int.c, mymalloc.c 같이 compile&lt;/li&gt;
  &lt;li&gt;원래는 아무것도 print하지 않는데 mymalloc, myfree를 통해서 원하는 정보를 tracing할 수 있게 됨. -&amp;gt; 이 주소에다가 우리가 allocate했음을 알고 vm주소를 deallocate했음을 확인할 수 있음&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;link-time-interpositioning&quot;&gt;Link-time Interpositioning&lt;/h1&gt;

&lt;p&gt;linktime 때 하는 경우 → object를 만들고 Wl option을 주고 —wrap, malloc/free&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#ifdef LINKTIME
#include &amp;lt;stdio.h&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__real_malloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__real_free&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* malloc wrapper function */&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__wrap_malloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__real_malloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;cm&quot;&gt;/* Call libc malloc */&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;malloc(%d) = %p&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* free wrapper function */&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__wrap_free&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;__real_free&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;cm&quot;&gt;/* Call libc free */&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;free(%p)&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#endif
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intl&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gcc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wall&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DLINKTIME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mymalloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gcc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wall&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gcc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wall&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;malloc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;free&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intl&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mymalloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runl&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intl&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;malloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;0x1aa0010&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;free&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x1aa0010&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-Wl&lt;/code&gt; flag passes argument to linker, replacing each comma with a space.&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;-wl flag 자체가 argument를 linker에게 넘겨주어 각각의 comma로 되어 있는 것을 space로 바꾸어 대치하라는 command&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--wrap_malloc&lt;/code&gt; arg instructs linker to resolve references in a special way:&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;나중에 —wrap,malloc/free를 gcc compiler에게 넘겨줌으로서 linker에 이야기 : reference되어 있는데 Linker에게 gcc compilier가 이런 식으로 resolve하라고 만든다.
        &lt;ul&gt;
          &lt;li&gt;malloc → &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;wrap malloc&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Real malloc&lt;/code&gt; → malloc&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Refs to malloc should be resolved as __wrap_malloc&lt;/li&gt;
      &lt;li&gt;Refs to   __real_malloc should be resolved as malloc&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;→ link time에 그 값을 가져다 reserve한 다음 원하는 대로 interposition&lt;/p&gt;

&lt;h1 id=&quot;loadrun-time-interpositioning&quot;&gt;&lt;strong&gt;Load/Run-time Interpositioning&lt;/strong&gt;&lt;/h1&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#ifdef RUNTIME
#define _GNU_SOURCE
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;dlfcn.h&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;cm&quot;&gt;/* malloc wrapper function */&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;malloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mallocp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;mallocp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dlsym&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RTLD_NEXT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;malloc&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;cm&quot;&gt;/* Get addr of libc malloc */&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dlerror&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stderr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mallocp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;cm&quot;&gt;/* Call libc malloc */&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;malloc(%d) = %p&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;cm&quot;&gt;/* free wrapper function */&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;free&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;freep&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dlsym&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RTLD_NEXT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;free&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;cm&quot;&gt;/* Get address of libc free */&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dlerror&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stderr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;freep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;cm&quot;&gt;/* Call libc free */&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;free(%p)&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#endif
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&amp;lt;Load/runtime interpositioning&amp;gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;dlsym : Library malloc의 address를 받아오기 위함&lt;/li&gt;
  &lt;li&gt;mallocp(size) : malloc이라는 wrapper 함수와 free라는 wrapper 함수가 있는데 나중에 동적으로 malloc이라는 wrapper함수에서 동적으로 malloc이 호출되는 그 순간에 malloc의 ptr address를 return하고 이를 가지고 print하게 하는 방법&lt;/li&gt;
  &lt;li&gt;동적으로 interpositioning을 malloc./ free
    &lt;ul&gt;
      &lt;li&gt;동일하게 free함수 호출했을 때 address를 받아오고 free를 한다음 printf를 통해 ptr값에 해당하는 heap에 있는 address 공간을 free&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LD_PRELOAD&lt;/code&gt; environment variable tells the dynamic linker to resolve unresolved refs (e.g., to malloc) by looking in mymalloc.so first.
    &lt;ul&gt;
      &lt;li&gt;‘LD Preload 환경 변수’를 통해 내가 찾고자 하는 함수를 code 안에서 찾을 수 있음.&lt;/li&gt;
      &lt;li&gt;순차적으로 찾고 동적으로 실행되는 그 때, 앞에 print하고자 하는 value들과 size를 print하고 free하며 끝남&lt;/li&gt;
      &lt;li&gt;환경 변수가 dynamic link에게 mymalloc.so file (shared library)를 찾아보고 malloc으로 대체할 수 있도록 하는 역할을 수행함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intr&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gcc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wall&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DRUNTIME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shared&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fpic&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mymalloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;so&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mymalloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ldl&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gcc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wall&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intr&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runr&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LD_PRELOAD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;./mymalloc.so&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;malloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;0xe60010&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;free&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0xe60010&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;interpositioning-recap&quot;&gt;&lt;strong&gt;Interpositioning Recap&lt;/strong&gt;&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Compile Time&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;compile time : macro 확장처럼 mymalloc&lt;/li&gt;
      &lt;li&gt;Apparent calls to malloc/free get macro-expanded into calls to mymalloc/myfree&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Link Time&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;link time : linker에게 trick을 불러 이름 resolution을 바꾸어 준다&lt;/li&gt;
      &lt;li&gt;Use linker trick to have special name resolutions&lt;/li&gt;
      &lt;li&gt;malloc → &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__wrap_malloc&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__real_malloc&lt;/code&gt; → malloc&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Load/Run Time&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;load/run time : dynamic linking을 통해서 실제 malloc, free를 다른 이름으로 load할 때 대치하게 함으로서 원하는 interpositioning을 수행할 수 있음&lt;/li&gt;
      &lt;li&gt;Implement custom version of malloc/free that use dynamic linking to load library malloc/free under different names&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;→ 세 가지 방법 중 load/runtime, compile time때 많이 수행. 물론 compile의 경우 preprocess 단계에서 내 것으로 가로채기 할 수 있으나 다 같이 compile해야 하는 문제점&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;load/runtime의 경우에는 이에 반해 따로 compile할 필요 없고, so file을 찾도록 하여 내가 작성한 함수로 interpositioning 기술을 적용할 수 있다&lt;/li&gt;
&lt;/ul&gt;</content><author><name>KyuHwan Shim</name><email>skh7343@cnsh.hs.kr</email></author><category term="system-programming" /><category term="CS" /><category term="os" /><category term="system-programming" /><summary type="html">Chap 12.</summary></entry><entry xml:lang="en"><title type="html">Ensemble Learning (Chapter 11)</title><link href="http://localhost:4000/blog/ML-11-Ensemble/" rel="alternate" type="text/html" title="Ensemble Learning (Chapter 11)" /><published>2022-06-10T12:26:09+09:00</published><updated>2022-06-10T12:26:09+09:00</updated><id>http://localhost:4000/blog/ML-11-Ensemble</id><content type="html" xml:base="http://localhost:4000/blog/ML-11-Ensemble/">&lt;h1 id=&quot;11-ensemble-learning&quot;&gt;11. Ensemble Learning&lt;/h1&gt;

&lt;p&gt;Property 1: Bishop 14&lt;/p&gt;

&lt;h1 id=&quot;ensemble-learning&quot;&gt;Ensemble Learning&lt;/h1&gt;

&lt;p&gt;지금까지 배운 여러개의 classifier 각각 : parameter 변화하여 여러가지 model&lt;/p&gt;

&lt;p&gt;한 가지 model보다는 여러 model을 활용하여 prediction&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;model 여러개를 써서 여러개의 model을 조합하여 최종 model을 결정&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ensemble learning is a process that uses a set of models, each of them obtained by applying a learning process to a given problem. This set of models (ensemble) is integrated in some way to obtain the final prediction&lt;/li&gt;
  &lt;li&gt;Aggregation of multiple learned models with the goal of improving accuracy
    &lt;ul&gt;
      &lt;li&gt;목표 : 정확도 높이기 / classification, regression acc, clustering acc에서 좋은 성능 얻기&lt;/li&gt;
      &lt;li&gt;Intuition: simulate what we do when we combine an expert panel in a human decision-making process
        &lt;ul&gt;
          &lt;li&gt;사람들이 결정 내릴 때도 한 두명 생각보다는 전문 집단 panel에 의해서 결정 내리면 좀 더 합리적이고 좀 더 좋은 결정을 내릴거라 생각하는 것처럼 결정&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;types-of-ensembles&quot;&gt;Types of ensembles&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;fusion
    &lt;ul&gt;
      &lt;li&gt;다른 version의 dataset, algorithm을 갖고 종합해 최종 판단&lt;/li&gt;
      &lt;li&gt;두 개의 용어는 바슷한 개념으로 사용되고도 있고 엄밀하게 분류하기 애매함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ensemble
    &lt;ul&gt;
      &lt;li&gt;randomness : 한 쪽은 NN, SVM &amp;lt;- 2 model, no randomness&lt;/li&gt;
      &lt;li&gt;NN 사용 시 w randomly init : w 초기값이 다른 model을 여러 가지 만들면 randomness로 model 만든 ensemble&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;→ randomness 추가된 부분 : ensemble / Randomness excluded : Fusion (섞어서 사용하기도 함)&lt;/p&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;Ensemble methods are used for:
    &lt;ul&gt;
      &lt;li&gt;Classification
        &lt;ul&gt;
          &lt;li&gt;각 model들이 분류 결과를 만들어나면 이를 조합하여 최종 (average)&lt;/li&gt;
          &lt;li&gt;classification alg 바꾸기 or dataset 변화를 주어 다른 모델 만들 수 있음&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Regression&lt;/li&gt;
      &lt;li&gt;Clustering (also known as consensus clustering)
        &lt;ul&gt;
          &lt;li&gt;clustering : 여러 version의 clustering에서 average를 취하여 어떻게 avg할 것인가가 차이
            &lt;ul&gt;
              &lt;li&gt;group의 category로 분류 : label이 학습할 때 주어진게 아님
  → 1번 그룹 안 어떤 sample들이 동일한 그룹 안에 있다는 게 의미&lt;/li&gt;
              &lt;li&gt;1번, 2번 group은 다른 group임이 의미
  -&amp;gt; clustering의 결과가 나타날 때 어떻게 합칠 것인가&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Ensembles can also be classifed as :
    &lt;ul&gt;
      &lt;li&gt;Homogeneous: It uses only one induction algorithm
        &lt;ul&gt;
          &lt;li&gt;동일한 분류 algorithm의 경우에도 (induction algorithm = classifier)
            &lt;ul&gt;
              &lt;li&gt;Bayesian classifier에서도 pdf로 gaussian 사용 -&amp;gt; classifier의 구조를 바꾸면 다른 구조의 algorithm&lt;/li&gt;
              &lt;li&gt;아예 다르게 바꾸게 되면 perceptron / svm/ decision tree 등 DNN/ CNN 자체도 구조는 차이가 있음&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Heterogeneous: It uses different induction algorithms
        &lt;ul&gt;
          &lt;li&gt;algorithm의 구조에 차이가 있으면 heterogeneous&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;some-comments&quot;&gt;Some Comments&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Combining models adds complexity&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;It is, in general, more difficult to characterize and explain predictions&lt;/p&gt;

        &lt;p&gt;Model의 개수가 늘어나니까 전체 complexity 증가 → 설명하기도 어려워지고, 어떤 결과값이 나올지, 그 결과값 설명하기도 어려워짐&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;The accuracy may increase&lt;/p&gt;

        &lt;p&gt;하지만 정확도는 일반적으로 향상됨&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Violation of Ockham’s Razor: &lt;strong&gt;“Simplicity leads to better accuracy”&lt;/strong&gt;&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;simple decision boundary가 일반적으로 좋은 성능을 보인다&lt;/li&gt;
      &lt;li&gt;Identifying the best model requires identifying the proper “model complexity”
        &lt;ul&gt;
          &lt;li&gt;좋은 성능을 내는 model을 찾으려면 complexity를 고민해야 하는데&lt;/li&gt;
          &lt;li&gt;occam에 거스르긴 하지만, 여러 model 사용하게 되면 개별 model은 복잡하지만 종합한 model은 smooth한 모양일수도 있음&lt;/li&gt;
        &lt;/ul&gt;

        &lt;p&gt;→ simple하게 만드는 과정이라 볼 수 있고, occam’s razor에 적합&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;simple boundary = simple alg이라고 생각했는데, complexity를 올림으로 db가 simple해질수도 있다!&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Decision boundary may become simpler, eventually. E&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-ensemble-learning-process&quot;&gt;The Ensemble Learning Process&lt;/h2&gt;

&lt;p&gt;data가 주어지면 그에 대해 함수들을 생성 - 각각이 분류 함수들 k개의 model 생성→ pruning&lt;/p&gt;

&lt;p&gt;→ 최종 함수 fk 도출&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;11/Untitled.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;methods-to-generate-ensembles&quot;&gt;Methods to Generate Ensembles&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Data Manipulation&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Train set에 변화&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;Supervised learning에서 train set에 대해 train 되어 얻어진 model&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;다른 train set을 사용하면 -&amp;gt; 다른 model : 분류 성능이 다름&lt;/li&gt;
      &lt;li&gt;it changes the training set in order to obtain different models&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Modeling process manipulation&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;algorihtm에 변화&lt;/li&gt;
    &lt;/ol&gt;

    &lt;ul&gt;
      &lt;li&gt;model process manipulation : algorithm의 변화&lt;/li&gt;
      &lt;li&gt;parameter만 변화하는 경우도 있고, classifier 자체를 변경할수도 있음, algorithm 자체를 변화시킬수도 있고&lt;/li&gt;
      &lt;li&gt;→ 다양한 model (f1 _ /// fk)&lt;/li&gt;
      &lt;li&gt;it changes the induction algorithm, the parameter set or the model in order to obtain different models&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;11/Untitled_1.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;data-manipulation&quot;&gt;Data manipulation&lt;/h2&gt;

&lt;p&gt;Data, algorithm에 대한 구분&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;data : data의 src로부터 subset 추출&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Data src / sensor (visible, thermal, near infrared)&lt;/p&gt;

&lt;p&gt;빛의 파장이 가시광선, 적외선 등에 따라 영상이 다양히 나타나는데 개별적인 src로 판단할 수 있고 이를 조합하는 것 또한 ensemble이라 볼 수 있다&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;그런 식의 ensemble을 Fusion이라고 볼 수도 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Manipulating the input features&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;11/Untitled_2.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;movie data features : rating, actor, genre
  -&amp;gt; 흥행할것인지, 수익이 어느정도일 것인지, 그룹의 사람들이 좋아할지&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;세 feature를 다르게 조합하여 각각의 경우가 모두 다른 classifier model&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sub-sampling from the training set&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;11/Untitled_3.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;data의 분할 : subset들 조합하여 최종 결과&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;modeling-process-manipulation&quot;&gt;Modeling process manipulation&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Manipulating the parameter sets
    &lt;ul&gt;
      &lt;li&gt;hyperparameter : network layer, 초기값을 어떻게 설정할지,
  node 개수, activation fn은 어떻게 설정할지&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;11/Untitled_4.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Manipulating the induction algorithm&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;11/Untitled_5.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-to-combine-models&quot;&gt;How to Combine Models&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Algebraic methods : Score를 어떻게 처리할 것인가
    &lt;ul&gt;
      &lt;li&gt;Average&lt;/li&gt;
      &lt;li&gt;Weighted average&lt;/li&gt;
      &lt;li&gt;Sum&lt;/li&gt;
      &lt;li&gt;Weighted sum&lt;/li&gt;
      &lt;li&gt;Product&lt;/li&gt;
      &lt;li&gt;Maximum&lt;/li&gt;
      &lt;li&gt;Minimum&lt;/li&gt;
      &lt;li&gt;Median&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Voting methods
    &lt;ul&gt;
      &lt;li&gt;Majority voting&lt;/li&gt;
      &lt;li&gt;Weighted majority voting&lt;/li&gt;
      &lt;li&gt;Borda count&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;11/Untitled_6.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;11/Untitled_7.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;characteristics-of-the-base-models&quot;&gt;Characteristics of the Base Models&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;The Base classifiers should be as accurate as possible and having diverse errors, while each classifier provides some positive evidences
    &lt;ul&gt;
      &lt;li&gt;diverse한 error가 나타나야 함. (Alg1, alg2 … 결과가 diverse)&lt;/li&gt;
      &lt;li&gt;어느 정도의 정확도를 가지면서 정답의 다양성을 가져야 classify의 의미가 있다&lt;/li&gt;
      &lt;li&gt;여러 version의 classifier를 ensemble하여 좋은 classifier&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The average error of the base learners should be as small as possible&lt;/li&gt;
  &lt;li&gt;The variance (of the predicted values) of the base learners should be as small as possible
    &lt;ul&gt;
      &lt;li&gt;Variance : when alg1 is trained&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Random한 initial value에 의하여 train 여러번하는데&lt;/p&gt;

    &lt;p&gt;Variance 정확도가 많이 변화한다면 좋은 classifier가 아닐 것&lt;/p&gt;

    &lt;p&gt;diversity&lt;/p&gt;

    &lt;p&gt;Stability : 한 알고리즘을 볼 때 다양하지 않은 결과&lt;/p&gt;

    &lt;p&gt;bias : ansewr과의 차이&lt;/p&gt;

    &lt;p&gt;Variance : 얼마나 정답이 다양하겠는가&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;11/Untitled_8.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;popular-ensemble-methods&quot;&gt;Popular Ensemble Methods&lt;/h2&gt;

&lt;p&gt;Bagging:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Averaging the prediction over a collection of predictors generated from &lt;strong&gt;bootstrap samples&lt;/strong&gt; (both classification and regression)&lt;/p&gt;

    &lt;p&gt;bootstrap sample :trian data있으면 subset sampling&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;각각 sampling으로부터 classifier 학습&lt;/p&gt;

        &lt;p&gt;Random하게 sampling하며 다양한 model&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Boosting:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Weighted vote with a collection of classifiers that were trained sequentially from training sets given priority to instances &lt;strong&gt;wrongly classified&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Boosting : 여러 단계를 거쳐 classifier 학습&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;이전 단계의 classifier의 오답에 초점을 맞춘다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;오류가 나오는 data들을 모아 다음 stage에서 초점을 맞추어 학습하여 융합한다&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;RandomForest:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Averaging the prediction over a collection of trees constructed using a &lt;strong&gt;randomly selected subset of features&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;tree를 randomly생성하여 randomly select해서 만든다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ensemble learning via negative correlation learning:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Generating sequentially new predictors &lt;strong&gt;negatively correlated&lt;/strong&gt; with the existing ones
    &lt;ul&gt;
      &lt;li&gt;현재 classifier하고 negative corelation갖는 classifier를 학습하여 융합한다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Heterogeneousensembles:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Combining a set of &lt;strong&gt;heterogeneous predictors&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;NN + SVM + DT 등 융합&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;bagging-bootstrap-aggregating&quot;&gt;Bagging: Bootstrap AGGregatING&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;11/Untitled_9.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Analogy: Diagnosis based on multiple doctors’ majority vote&lt;/p&gt;

    &lt;p&gt;여러 명의 의사들의 진단 결과를 융합하는 방법&lt;/p&gt;

    &lt;p&gt;Ex. Max score, average score 등&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;여러 model을 만들기 위해서 bootstrap sampling&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Training&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Given a set D of d tuples, at each iteration i, a training set $D_i$ of $d$ tuples is sampled with replacement from D (i.e. bootstrap)
        &lt;ul&gt;
          &lt;li&gt;bootstrap 방법 : sampling with replacement - 전체 dataset으로부터 sampling하여 modeling하고 다시 복원&lt;/li&gt;
          &lt;li&gt;각각의 data subset에 대하여 model을 만듬&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;average, Sum 은 같은 방식 : sum에서 classifier number만큼 나눠주면 average value&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;bootstrapping = original data로부터 sampling&lt;/li&gt;
  &lt;li&gt;aggregating = 그것들로부터 각각의 classifier를 만들어 병합하는 방법&lt;/li&gt;
  &lt;li&gt;Classification: classify an unknown sample X
    &lt;ul&gt;
      &lt;li&gt;Each classifier $M_i$ returns its class prediction&lt;/li&gt;
      &lt;li&gt;The bagged classifier $M^*$ counts the votes and assigns the class with the most votes to X
        &lt;ul&gt;
          &lt;li&gt;각 classifier가 sample에 대한 class 예측값을 계산하고, 그리고 최종 판단은 voting / sum/ 등 여러 방법을 사용할 수 있다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Prediction:
    &lt;ul&gt;
      &lt;li&gt;can be applied to the prediction of continuous values by taking the average value of each prediction for a given test tuple&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Accuracy
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Often significantly better than a single classifier derived from&lt;/p&gt;

        &lt;p&gt;significantly better : 5 ~ 10% 상승&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;물론 model을 여러번 쓰고 연산량은 그만큼 증가&lt;/li&gt;
          &lt;li&gt;test stage : Test sample에서는 model들 다 유지해서 그만큼 분류 작업 수행 후 융합&lt;/li&gt;
        &lt;/ul&gt;

        &lt;p&gt;Train + test stage 연산량 증가&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;For noisy data: not considerably worse, more robust
        &lt;ul&gt;
          &lt;li&gt;noisy data : robust하게 됨 (boost sampling : Noisy data가 빠진 형태로 학습)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Proved improved accuracy in prediction&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Requirement: need unstable classifier types
    &lt;ul&gt;
      &lt;li&gt;Unstablemeansasmallchangetothetrainingdatamayleadtomajor decision changes&lt;/li&gt;
      &lt;li&gt;requirement : unstable classifier&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Unstable : train data를 조금 바꿀 경우 model decision이 크게 바뀌는 model을 의미함&lt;/p&gt;

    &lt;p&gt;(Remind) Model이 바뀐 train data에 대해서 diverse한 error = variance가 커야 한다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;bagging의 관점에서는 var 큰게 좋다 (일반적으로는 별로 안 좋다)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Stability in Training
    &lt;ul&gt;
      &lt;li&gt;Training: construct classifier from&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Stability: small changes on results in small changes on&lt;/p&gt;

        &lt;p&gt;Training : f를 d로부터 형성&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;Decision trees are a typical unstable classifier&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;11/Untitled_10.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;11/Untitled_11.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;boosting&quot;&gt;Boosting&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Analogy: Consult several doctors, when there are disagreements, we focus more attention on that case&lt;/p&gt;

    &lt;p&gt;의사들의 의견이 갈릴 때 합치되지 않는 의견들에 대해 더 주의를 기울인다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Incrementally create models selectively using training examples based on some distribution.
    &lt;ul&gt;
      &lt;li&gt;Incrementally하게 sample이 subset으로 selection된 확률값을 가지고 있음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How boosting works?
    &lt;ul&gt;
      &lt;li&gt;Weights are assigned to each training example&lt;/li&gt;
      &lt;li&gt;A series of k classifiers is iteratively learned&lt;/li&gt;
      &lt;li&gt;After a classifier $M_i$  is learned, the weights are updated to allow the subsequent classifier, $M_i +1$, to pay more attention to the training examples that were misclassified by&lt;/li&gt;
      &lt;li&gt;The final $M^*$ combines the votes of each individual classifier, where the weight of each classifier’s vote is a function of its accuracy 𝒊&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;각 sample들이 weight를 가지고 있음.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그리고 우리는 k개의 classifier를 학습할 것&lt;/p&gt;

&lt;p&gt;그런데 M_i가 학습 된 다음, classifier가 학습된 이후에는&lt;/p&gt;

&lt;p&gt;weight을 update하는데 앞 단계에서 학습된 model들이 misclassified 에 더 주의를 기울인다 (weight를 올린다)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;higher chance to be selected&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;즉 misclassified sample들이 점점 그 쪽으로 select되면서 hard sample들이 점점 추가되어 뒤쪽 classifier 학습&lt;/p&gt;

&lt;p&gt;1~k개 classifier를 조합하여 m*&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;weighted combination : weight는 accuracy에 비례&lt;/li&gt;
  &lt;li&gt;boosting 기본 아이디어 : disagreement, hard sample&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hard sample에 초점 맞추는 방법 : classifier 1번을 만들고 misclassified에 대해서 classifier 2번을 만들고 m1, m2가 다른 결정을 내리는 sample에 대해서 classifier 3번을 만들어 test sample이 들어오면 m1, m2를 돌려 최종 결과로 사용하고 두 분류기 결과가 다르면 m3를 활용하여 결과 도출&lt;/p&gt;

&lt;p&gt;(data가 다시 sampling될 확률값 조정하는 방식 : adaboosting)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;M_i : weak classifier&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;adaboost&quot;&gt;Adaboost&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Using Different Data Distribution
    &lt;ul&gt;
      &lt;li&gt;Start with uniform weighting&lt;/li&gt;
      &lt;li&gt;misclassified sample의 weight 증가&lt;/li&gt;
      &lt;li&gt;well classified sample에 대해서는 weight 감소&lt;/li&gt;
      &lt;li&gt;During each step of learning
        &lt;ul&gt;
          &lt;li&gt;Increase weights of the examples which are not correctly learned by the weak learner&lt;/li&gt;
          &lt;li&gt;Decrease weights of the examples which are correctly learned by the weak learner&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Idea
    &lt;ul&gt;
      &lt;li&gt;Focus on difficult examples which are not correctly classified in the previous steps&lt;/li&gt;
      &lt;li&gt;difficult example에 더 주의를 기울인 케이스&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Weighted Voting
    &lt;ul&gt;
      &lt;li&gt;Construct strong classifier by weighted voting of the weak classifiers&lt;/li&gt;
      &lt;li&gt;&lt;/li&gt;
      &lt;li&gt;strong classifier 만들 때 weak classifier 에 weight를 주고 weighted voting / weighted sum 등 일반적인 ensemble 방법 적용&lt;/li&gt;
      &lt;li&gt;weak classifier를 많이 첨가하여 combined classifier의 accuracy 증가 (strong classifier/learner)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Idea
    &lt;ul&gt;
      &lt;li&gt;Better weak classifier gets a larger weight&lt;/li&gt;
      &lt;li&gt;Iteratively add weak classifiers
        &lt;ul&gt;
          &lt;li&gt;Increase accuracy of the combined classifier through minimization of a cost function Ensemble Learning Adaboost Introduction to Machine Learning Page 17&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;11/Untitled_12.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Differences with Bagging:bagging과의 차이점
    &lt;ul&gt;
      &lt;li&gt;Models are built sequentially on modified versions of the data
        &lt;ul&gt;
          &lt;li&gt;random하게 sample된게 아니라 weight에 의해 sample된 data에 의해 학습&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The predictions of the models are combined through a weighted sum/vote
        &lt;ul&gt;
          &lt;li&gt;점점 hard sample에 대해 학습되니 easy sample / hard sample의 classifier가 동일한 weight를 가질 수 없음 : bagging은 동일한 조건으로 randomly sampling (no weight)
            &lt;ul&gt;
              &lt;li&gt;거의 동등한 조건이기 때문에 weight를 주지 않음&lt;/li&gt;
              &lt;li&gt;boosting의 경우 misclassified에 대해 overfitting (hard sample이 증가하는 방향으로 weight update)-&amp;gt; ensemble하면 점점 hard sample 추가되며 overfitting 위험&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Boosting algorithm can be extended for numeric prediction
    &lt;ul&gt;
      &lt;li&gt;Comparing with bagging: Boosting tends to achieve greater accuracy, but it also risks overfitting the model to misclassified data&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The diagram should be interpreted with the understanding that the algorithm is sequential: classifier $C_k$ is created before classifier $C_{k+1}$, which in turn requires that $\beta_k$ and the current distribution $D_k$ be available&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;11/Untitled_13.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;sequential = 앞서 misclassified sample을 구해야 이를 바탕으로 추가 학습을 진행하기에
  ck는 ck+1보다 학습이 사전에 이루어져야 하며
  Beta k : 4th classifer의 error / 현재 data distribution을 알아야 다음 단계 classifer를 학습시킬 수 있음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;comments&quot;&gt;Comments&lt;/h3&gt;

&lt;p&gt;이런식으로 sample distribution에 의해 data update하여 학습하면
앞 쪽 단계 misclassified data들이 current stage에 학습&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;hard sample에 편중하여 학습이 일어남 (undemocratic voting scheme)
Weighted majority voting : ensemble 대상 단위의 classifier들이 성능 상 큰 차이 존재가 있어 weight를 줄 수밖에 없고 성능 좋은 classifier에 대해 더 높은 weight를 주는 게 더 자연스러울 수 있고, 이런게 democratic하지는 않다.&lt;/li&gt;
  &lt;li&gt;This distribution update ensures that instances misclassified bythe previous classifier are more likely to be included in the training data of the next classifier.&lt;/li&gt;
  &lt;li&gt;Hence, consecutive classifiers’ training data are geared towards increasingly hard-to-classify instances.&lt;/li&gt;
  &lt;li&gt;Unlike Bagging, AdaBoost uses a rather undemocratic voting scheme, called the weighted majority voting.
    &lt;ul&gt;
      &lt;li&gt;The idea is an intuitive one: those classifiers that have shown good performance during training are rewarded with higher voting weights than the others.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;##&lt;/p&gt;

&lt;h1 id=&quot;random-forest&quot;&gt;Random Forest&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Random Forest: A variation of the bagging algorithm - bagging처럼 여러 개 ensemble&lt;/li&gt;
  &lt;li&gt;Created from individual decision trees
    &lt;ul&gt;
      &lt;li&gt;Diversity is guaranteed by selecting randomly at each split, a subset of the original features during the process of tree generation&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;tree 구조 : unstable 구조 → diversity가 guaranteed됨 automatically&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;R.F 활용
    &lt;ul&gt;
      &lt;li&gt;During classification, each tree votes and the most popular class is returned
        &lt;ul&gt;
          &lt;li&gt;classification에서는 : vote를 가장 많이 받은 class가 최종 결과 decision&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;During regression, the result is the averaged prediction of all generated trees
        &lt;ul&gt;
          &lt;li&gt;regression에서는 :각 tree들이 result을 만드는데 이를 average 취하면 random forest result&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;random selection이 : feature selection / data sampling&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Two Methods to construct RandomForest:&lt;/p&gt;

    &lt;p&gt;Random forest 만드는 두 가지 방법&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Random input selection : 각 node에서 attribute를 randomly selection하는 방법
        &lt;ul&gt;
          &lt;li&gt;Forest-RI (random input selection): Randomly select, at each node, F attributes as candidates for the split at the node. The CART methodology is used to grow the trees to maximum size&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Random linear combination: 기존 feature에 대한 linear combination 작업을 취하여 여러 개의 attribute에 linear combination을 바탕으로 tree 학습을 진행한다.
        &lt;ul&gt;
          &lt;li&gt;Forest-RC (random linear combinations): Creates new attributes (or features) that are a linear combination of the existing attributes (reduces the correlation between individual classifiers)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;adaboost와 유사한 특징을 가지지만 error / outlier에 더 robust한 특성을 보인다.
    &lt;ul&gt;
      &lt;li&gt;Comparable in accuracy to Adaboost, but more robust to errors and outliers&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;민감하게 반응하지는 않고 더 빠르게 실행 : decision tree 생성 과정은 학습 model 자체가 효율적으로 구성될 수 있기 때문에 (tree 구성)
    &lt;ul&gt;
      &lt;li&gt;Insensitive to the number of attributes selected for consideration at each split, and faster than bagging or boosting&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;model-selection&quot;&gt;Model Selection&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Given a problem, which algorithms should we use?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Golden rule: there is no algorithm that is the best one for all the problems
    &lt;ul&gt;
      &lt;li&gt;하나의 특정 알고리즘이 다른 모든 problem 모두를 해결하지는 않는다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Typically, two approaches (or both) can be adopted:
    &lt;ul&gt;
      &lt;li&gt;To choose the algorithm more suitable for the given problem&lt;/li&gt;
      &lt;li&gt;To adapt the given data for the intended algorithm (using pre-processing, for instance)
        &lt;ul&gt;
          &lt;li&gt;주어진 data를 잘 tuning할 수 있도록 한다 for 사용하고자 하는 algorithm (preprocessing)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The concept of “good algorithm” depends on the problem:
    &lt;ul&gt;
      &lt;li&gt;good algorithm : prob by prob&lt;/li&gt;
      &lt;li&gt;Explainability : model이 어떤 판단을 내린다면 판단의 정확도도 중요하나 그 결정의 이유도 중요함 : bayesian, decision tree는 쉽게 설명할 수 있는데 그 외에는 설명이 쉽지 않음&lt;/li&gt;
      &lt;li&gt;분류 관리 문제에 있어서는 이송 시간 예측 정확도가 가장 중요한 선택요인&lt;/li&gt;
      &lt;li&gt;For a doctor, the interpretation of the model can be a major criterion for the selection of the model (decision trees and Bayesian networks are very appreciated)&lt;/li&gt;
      &lt;li&gt;For logistics, the accuracy of travel time prediction is, typically, the most important selection criterion.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;statistical-validation&quot;&gt;Statistical Validation&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Mixture of Experts
    &lt;ul&gt;
      &lt;li&gt;Combine votes or scores&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;11/Untitled_14.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Stacking
    &lt;ul&gt;
      &lt;li&gt;Combiner f() is another learner (Wolpert, 1992)&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;adaboost도 최종 함수 : 개별 classifier에 근거하여 accuracy로부터 sequentially 생성&lt;/p&gt;

        &lt;p&gt;Stacked generalization by &lt;a href=&quot;https://www.sciencedirect.com/science/article/abs/pii/S0893608005800231#!&quot;&gt;David H.Wolpert&lt;/a&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/abs/pii/S0893608005800231#aep-article-footnote-id1&quot;&gt;&lt;/a&gt;&lt;/p&gt;

        &lt;p&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/abs/pii/S0893608005800231&quot;&gt;https://www.sciencedirect.com/science/article/abs/pii/S0893608005800231&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;11/Untitled_15.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Cascading
    &lt;ul&gt;
      &lt;li&gt;Use next level of classifier if the previous decision is not confident enough&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;11/Untitled_16.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>KyuHwan Shim</name><email>skh7343@cnsh.hs.kr</email></author><category term="ml" /><category term="ML" /><category term="AI" /><category term="Lecture" /><summary type="html">Chap11.Ensemble</summary></entry><entry xml:lang="en"><title type="html">Deep Neural Net 2 (Chapter 10)</title><link href="http://localhost:4000/blog/ML-10-DNN/" rel="alternate" type="text/html" title="Deep Neural Net 2 (Chapter 10)" /><published>2022-06-06T12:26:09+09:00</published><updated>2022-06-06T12:26:09+09:00</updated><id>http://localhost:4000/blog/ML-10-DNN</id><content type="html" xml:base="http://localhost:4000/blog/ML-10-DNN/">&lt;h1 id=&quot;10-dnn-2&quot;&gt;10. DNN 2&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;구조상 차이 : hidden layer 개수
fully connected layer -&amp;gt; conv layer&lt;/li&gt;
  &lt;li&gt;Activation, normalization 하는 부분들&lt;/li&gt;
  &lt;li&gt;weight update하는 부분들&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여러 학습 알고리즘이 제안되며 더 좋은 성능을 가지게 됨&lt;/p&gt;

&lt;h1 id=&quot;data-processing&quot;&gt;Data Processing&lt;/h1&gt;

&lt;p&gt;input layer - hidden lyaer - output layer로 그려진 NN&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;x, y, z (hidden lyaer 하나로만 두고 보면) y layer 의 첫 번째 node를 볼 때 각자 연결된다&lt;/li&gt;
  &lt;li&gt;fc 구조가 기본적인 구조&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;앞 node의 weight combination + bias&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Consider what happens when the input to a neuron is always positive…&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;10/Untitled.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;i의 변화에 따라 x도 변화 → w가 모든 같은 부호&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;w update slowly → learn slowly
    &lt;ul&gt;
      &lt;li&gt;이상적인 w에 도달하지 않을 수 있다&lt;/li&gt;
      &lt;li&gt;학습 시간에도 문제가 될 수 있다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What can we say about the gradients on w?&lt;/li&gt;
  &lt;li&gt;Always all positive or all negative!&lt;/li&gt;
  &lt;li&gt;(this is also why you want zero-mean data!)
    &lt;ul&gt;
      &lt;li&gt;data normalization : $\mu = 0$&lt;/li&gt;
      &lt;li&gt;for input hidden layer&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;step-1-preprocess-the-data&quot;&gt;Step 1: Preprocess the data&lt;/h2&gt;

&lt;p&gt;(Assume X [NxD] is data matrix, each example in a row)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;10/Untitled_1.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;normalized data : $N(0, 1^2)$
    &lt;ul&gt;
      &lt;li&gt;learn faster&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In practice, you may also see PCA and Whitening of the data&lt;/p&gt;

&lt;p&gt;PCA : dimensionality reduction, clustering (unsupervised)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;decorrelated data
    &lt;ul&gt;
      &lt;li&gt;(data has diagonal covariance matrix)&lt;/li&gt;
      &lt;li&gt;axis방향으로 평행 : with x1 only (1dim)&lt;/li&gt;
      &lt;li&gt;from 2dim → 1dim compression (data info loss)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;whitened data
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;(covariance matrix is the identity matrix)&lt;/p&gt;

        &lt;p&gt;$\Sigma =$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;acc 변화했을 수도 있으므로 performance 체크&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;10/Untitled_2.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In practice for Images: Zero-center only&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;e.g. consider CIFAR-10 example with [32,32,3] images&lt;/li&gt;
  &lt;li&gt;Subtract the mean image (e.g.AlexNet)
    &lt;ul&gt;
      &lt;li&gt;(mean image = [32,32,3] array)
        &lt;ul&gt;
          &lt;li&gt;RGB 평균 구해서 average&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Subtract per-channel mean (e.g.VGGNet)
    &lt;ul&gt;
      &lt;li&gt;(mean along each channel = 3 numbers)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Not common to normalize variance (for PCA or whitening)
    &lt;ul&gt;
      &lt;li&gt;w 효과적으로&lt;/li&gt;
      &lt;li&gt;PCA → data rotation, whitening → Cov to Identity Mat&lt;/li&gt;
      &lt;li&gt;if original data에 대한 학습 중 특정 w를 학습해야 한다면&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;weight-initialization&quot;&gt;Weight Initialization&lt;/h1&gt;

&lt;p&gt;원래 w : randomly init.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Q: what happens when W=0 init is used?&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;10/Untitled_3.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;f’(0) x_i → wi에 update됨&lt;/p&gt;

&lt;p&gt;모든 w에 동일한 pattern으로 update&lt;/p&gt;

&lt;p&gt;i가 달라짐에 다르게 but 같게 실행 : 지그재그로 수행되는 것보다 성능이 안좋을 수 있음&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;First idea: Small random numbers
    &lt;ul&gt;
      &lt;li&gt;(gaussian with zero mean and 1e-2 standard deviation)&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;H&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;small w : hidden layer가 커질수록 → backprop되는 layer 적어짐
        &lt;ul&gt;
          &lt;li&gt;뒤 layer로 갈수록 앞 layer update 작아짐 : 학습 잘 안됨&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;big w : vanishing GD : update 안될수록 f’ 작아짐
        &lt;ul&gt;
          &lt;li&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Works ~okay for small networks, but problems with deeper networks.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lets look at some activation statistics
    &lt;ul&gt;
      &lt;li&gt;10-layer net with 500 neurons on each layer, using tanh&lt;/li&gt;
      &lt;li&gt;non-linearities, and initializing as described in previous slide.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;All activations become zero!&lt;/li&gt;
  &lt;li&gt;Q: think about the backward pass. What do the gradients look like?
    &lt;ul&gt;
      &lt;li&gt;Hint: think about backward pass for a W*X gate.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;*1.0 instead of *0.01&lt;/li&gt;
  &lt;li&gt;Almost all neurons completely saturated, either -1 and 1. Gradients will be all zero.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Deep Neural Networks
Weight Initialization&lt;/p&gt;

&lt;p&gt;“Xavier initialization” [Glorot et al., 2010]&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fanin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fanout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fanin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Reasonable initialization. (Mathematical derivation assumes linear activations) with tanh fn&lt;/li&gt;
  &lt;li&gt;현재 layer node의 sqrt로 init&lt;/li&gt;
  &lt;li&gt;but when using the ReLU nonlinearity it breaks. (0에 접근)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;He et al., 2015 (note additional /2)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;error가 더 잘 감소됨을 확인할 수 있음&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fanin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fanout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fanin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;proper-initialization-is-an-active-area-of-research&quot;&gt;Proper initialization is an active area of research&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Understanding the difficulty of training deep feedforward neural networks
by Glorot and Bengio, 2010&lt;/li&gt;
  &lt;li&gt;Exact solutions to the nonlinear dynamics of learning in deep linear neural networks by Saxe et al, 2013&lt;/li&gt;
  &lt;li&gt;Random walk initialization for training very deep feedforward networks by Sussillo and Abbott, 2014&lt;/li&gt;
  &lt;li&gt;Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification by He et al., 2015&lt;/li&gt;
  &lt;li&gt;Data-dependent Initializations of Convolutional Neural Networks by Krähenbühl et al., 2015&lt;/li&gt;
  &lt;li&gt;All you need is a good init, Mishkin and Matas, 2015 …&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;batch-normalization&quot;&gt;Batch Normalization&lt;/h1&gt;

&lt;p&gt;[Ioffe and Szegedy, 2015]&lt;/p&gt;

&lt;p&gt;layer에 data를 넣을 때 전체 data를 randomly partition하여 mini batch 생성&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;“you want unit gaussian activations? just make them so.”&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;consider a batch of activations at some layer.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;To make each dimension unit gaussian, apply:
    &lt;ul&gt;
      &lt;li&gt;$\hat x^{(k)} = \frac{x^{(k)} - E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}$
        &lt;ul&gt;
          &lt;li&gt;this is a vanilla differentiable function…&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;dimension 단위 normalilze&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;compute the empirical mean and variance independently for each dimension.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;10/Untitled_4.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Normalize&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;$\hat x^{(k)} = \frac{x^{(k)} - E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}$
    - Usually inserted after Fully Connected or Convolutional layers, and before &lt;strong&gt;nonlinearity.&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;10/Untitled_5.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Normalize:
    &lt;ul&gt;
      &lt;li&gt;$\hat x^{(k)} = \frac{x^{(k)} - E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}$&lt;/li&gt;
      &lt;li&gt;$\hat x \sqrt{Var} + E[x] = X$&lt;/li&gt;
      &lt;li&gt;$\gamma = \sqrt{Var} , \beta = E[x]$&lt;/li&gt;
      &lt;li&gt;$\hat x$ : normalized data, X : original data&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;And then allow the network to squash the range if it wants to:
    &lt;ul&gt;
      &lt;li&gt;$\hat y^{(k)} = \gamma^{(k)} \hat x^{(k)}+\beta^{(k)}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Note, the network can learn:to recover the identity mapping.
    &lt;ul&gt;
      &lt;li&gt;$\gamma^{(k)} = \sqrt{Var[x^{(k)}]}$ (stretch)&lt;/li&gt;
      &lt;li&gt;$\beta^{(k)} = E[x^{(k)}]$ (이동)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;$X \rightarrow \hat X$ : normalize : $\gamma, \beta$로 scaling된 y value&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;10/Untitled_6.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Improves gradient flow through the network&lt;/li&gt;
  &lt;li&gt;Allows higher learning rates&lt;/li&gt;
  &lt;li&gt;Reduces the strong dependence on initialization&lt;/li&gt;
  &lt;li&gt;Acts as a form of regularization in a funny way, and slightly reduces the need for dropout, maybe&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Note: at test time BatchNorm layer functions differently:&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;The mean/std are not computed based on the &lt;strong&gt;batch(test batch)&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;Instead, a single fixed empirical mean of activations during training is used.
    &lt;ul&gt;
      &lt;li&gt;(e.g. can be estimated during training with running averages)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1&gt;—&lt;/h1&gt;

&lt;h1 id=&quot;model-ensembles&quot;&gt;Model Ensembles&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;Train multiple independent models&lt;/li&gt;
  &lt;li&gt;At test time average their results (여러 model result average)&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Enjoy 2% extra performance&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;single model : learning method 변경&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;ex. tanh → ReLU : 종합하여 result 추출&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;how-to-improve-single-model-performance&quot;&gt;How to improve single-model performance?&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;10/Untitled_7.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Regularization&lt;/p&gt;

&lt;h1 id=&quot;regularization-add-term-to-loss&quot;&gt;Regularization: Add term to loss&lt;/h1&gt;

\[L = \frac 1 N \Sigma_{i=1}^{N} \Sigma_{j\neq y_i}{\max(0, f(x_i);W)_j - f(x_i);W)_{y_i} +1} + \lambda R(W)\]

&lt;ul&gt;
  &lt;li&gt;Loss Fn : $\frac 1 N \Sigma_{i=1}^{N} \Sigma_{j\neq y_i}{\max(0, f(x_i);W)&lt;em&gt;j - f(x_i);W)&lt;/em&gt;{y_i} +1}$&lt;/li&gt;
  &lt;li&gt;Lambda weight term $+ \lambda R(W)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;10/Untitled_8.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;In common use:&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;10/Untitled_9.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;regularization-dropout&quot;&gt;Regularization: Dropout&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;In each forward pass, randomly set some neurons to zero Probability of dropping is a hyperparameter; 0.5 is common&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;10/Untitled_10.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Srivastava et al, “Dropout: A simple way to prevent neural networks from overfitting”, JMLR 2014&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Example forward pass with a 3-layer network using dropout&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;10/Untitled_11.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;10/Untitled_12.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;How can this possibly be a good idea?&lt;/li&gt;
  &lt;li&gt;Forces the network to have a redundant representation;
    &lt;ul&gt;
      &lt;li&gt;Prevents co-adaptation of features&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;개별 node들이 학습에 적극적으로 사용되도록 강제화시키는 작업&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;10/Untitled_13.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;how-can-this-possibly-be-a-good-idea&quot;&gt;How can this possibly be a good idea?&lt;/h3&gt;

&lt;p&gt;randomly selection of node → network 구조 다양 - 종합적 사용&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Another interpretation:
    &lt;ul&gt;
      &lt;li&gt;Dropout is training a large &lt;strong&gt;ensemble&lt;/strong&gt; of models (that share parameters).&lt;/li&gt;
      &lt;li&gt;Each binary mask is one model&lt;/li&gt;
      &lt;li&gt;An FC layer with 4096 units has 24096 ~ 101233 possible masks!&lt;/li&gt;
      &lt;li&gt;Only ~ 1082 atoms in the universe..&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;dropout-test-time&quot;&gt;Dropout: Test time&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Dropout makes our output random!&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;10/Untitled_14.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Want to “average out” the randomness at test-time
    &lt;ul&gt;
      &lt;li&gt;$y = f(x) = E_z[f(x,z)] = \int p(z)f(x,z)dz$ㅓㄹ&lt;/li&gt;
      &lt;li&gt;여러 var mask  ㅇ - mu, sum&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;But this integral seems hard …&lt;/li&gt;
  &lt;li&gt;Want to approximate the integral
    &lt;ul&gt;
      &lt;li&gt;$y = f(x) = E_z[f(x,z)] = \int p(z)f(x,z)dz$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Consider a single neuron.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;10/Untitled_15.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;At test time we have:
    &lt;ul&gt;
      &lt;li&gt;$E[a] = w_1x + w_2y$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;During training we have:&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;10/Untitled_16.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;At test time, multiply by dropout probability&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;10/Untitled_17.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;p to be dropped → *p : 값을 줄여나가는 식으로 진행&lt;/li&gt;
  &lt;li&gt;At test time all neurons are active always
    &lt;ul&gt;
      &lt;li&gt;→ We must scale the activations so that for each neuron:&lt;/li&gt;
      &lt;li&gt;output at test time = expected output at training time&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;dropout-summary&quot;&gt;Dropout Summary&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;drop in forward pass
    &lt;ul&gt;
      &lt;li&gt;train때 사용된 w값이 test 시점에도 반영&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;scale at test time&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;10/Untitled_18.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;more-common-inverted-dropout&quot;&gt;More common: “Inverted dropout”&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;train시 p로 나누어줌&lt;/li&gt;
  &lt;li&gt;test time is unchanged!
    &lt;ul&gt;
      &lt;li&gt;test 단계에 적용 → test 에서는 X X&lt;/li&gt;
      &lt;li&gt;if v1 &amp;gt; p → test시점 (1-p)&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;10/Untitled_19.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;regularization-a-common-pattern&quot;&gt;Regularization: A common pattern&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Cross Entropy Loss : $-\Sigma y_i \lim P_i$
    &lt;ul&gt;
      &lt;li&gt;yi : the answer&lt;/li&gt;
      &lt;li&gt;Pi : prediction&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Training: Add some kind of randomness
    &lt;ul&gt;
      &lt;li&gt;randomness - regularize&lt;/li&gt;
      &lt;li&gt;$y = f_W (x,z)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Testing: Average out randomness (sometimes approximate)
    &lt;ul&gt;
      &lt;li&gt;$y = f(x) = E_z[f(x,z)] = \int p(z)f(x,z)dz$&lt;/li&gt;
      &lt;li&gt;iteration별 여러 mu, sigma → average를 구하여 test시점에 적용한다&lt;/li&gt;
      &lt;li&gt;BN도 regularization작업&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Example:BatchNormalization
    &lt;ul&gt;
      &lt;li&gt;Training:Normalize using stats from random mini batches&lt;/li&gt;
      &lt;li&gt;Testing:Use fixed stats to normalize&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>KyuHwan Shim</name><email>skh7343@cnsh.hs.kr</email></author><category term="ml" /><category term="ML" /><category term="AI" /><category term="Lecture" /><summary type="html">Chap10.DNN2</summary></entry><entry xml:lang="en"><title type="html">Deep Neural Net (Chapter 9)</title><link href="http://localhost:4000/blog/ML-9-DNN/" rel="alternate" type="text/html" title="Deep Neural Net (Chapter 9)" /><published>2022-06-04T12:26:09+09:00</published><updated>2022-06-04T12:26:09+09:00</updated><id>http://localhost:4000/blog/ML-9-DNN</id><content type="html" xml:base="http://localhost:4000/blog/ML-9-DNN/">&lt;h1 id=&quot;9-dnn&quot;&gt;9. DNN&lt;/h1&gt;
&lt;p&gt;Property 1: Goodfellow6-9&lt;/p&gt;

&lt;h1 id=&quot;deep-learning&quot;&gt;Deep Learning&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;A machine learning subfield. Exceptional performance in learning patterns.&lt;/li&gt;
  &lt;li&gt;Deep learning algorithms attempt to learn (multiple levels of) representation by using a hierarchy of multiple layers.&lt;/li&gt;
  &lt;li&gt;If you provide the system tons of information, it begins to understand it and respond in useful ways.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280841-5f543450-343f-428d-a710-2de87ec07d90.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Manually designed features are often over-specified, incomplete and take a long time to design and validate&lt;/li&gt;
  &lt;li&gt;Learned Features are easy to adapt, fast to learn&lt;/li&gt;
  &lt;li&gt;Deep learning provides a very flexible, (almost?) universal, learnable
framework for representing world, visual and linguistic information.&lt;/li&gt;
  &lt;li&gt;Can learn both unsupervised and supervised&lt;/li&gt;
  &lt;li&gt;Effective end-to-end joint system learning&lt;/li&gt;
  &lt;li&gt;Utilize large amounts of training data&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;history&quot;&gt;History&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;In ~2012, deep learning (DL) started outperforming other machine learning (ML) techniques, first in speech and vision, then NLP&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280850-84f61fd3-b882-4e05-88c2-f3a9726f65e9.png&quot; alt=&quot;Untitled_1&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280851-27c1c196-b18a-48ad-8d1f-995ab74974d7.png&quot; alt=&quot;Untitled_2&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;structure&quot;&gt;Structure&lt;/h2&gt;

&lt;p&gt;어떻게 DL이 좋은 성능을 내는가?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fat + Short vs. Thin + Tall Networks&lt;/li&gt;
  &lt;li&gt;The same number of parameters&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280852-f4b51bc9-82ea-40b6-8444-335edc605fd6.png&quot; alt=&quot;Untitled_3&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Deep → Modularization&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280854-4800d400-c5a6-486d-9a1b-f5c9f0eac4ab.png&quot; alt=&quot;Untitled_4&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280855-6388a472-0576-43ff-a35d-48ec1d93e0e8.png&quot; alt=&quot;Untitled_5&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280857-b2c58c84-6ccd-40c2-bf71-c7c54072fa53.png&quot; alt=&quot;Untitled_6&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280858-e8cb1992-3783-4534-ae1f-4aca21858335.png&quot; alt=&quot;Untitled_7&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280860-ad51845e-23d1-433a-b6e2-8b4ce62bab6a.png&quot; alt=&quot;Untitled_8&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280865-2800259e-5654-431e-a0f6-810f65f58103.png&quot; alt=&quot;Untitled_9&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280869-d15d08ad-3e05-4ede-a963-a9f83b5b49e0.png&quot; alt=&quot;Untitled_10&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Before 2006, deeper usually does not imply better performance.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985&quot;&gt;Geoffrey Hinton showed how to train deep network in 2006 [1]&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Learned layers one by one&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985&quot;&gt;Deep Neural Networks showed good classification performance with large image data set in 2012. [2]&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;GPU&lt;/li&gt;
      &lt;li&gt;Big data&lt;/li&gt;
      &lt;li&gt;Better learning algorithms&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280873-199a43e5-7947-49cb-a4e4-b95ea20e5443.png&quot; alt=&quot;Untitled_11&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.gizmodo.com.au/2015/04/the-basic-recipe-for-machinelearning-explained-in-a-single-powerpoint-slide/&quot;&gt;http://www.gizmodo.com.au/2015/04/the-basic-recipe-for-machinelearning-explained-in-a-single-powerpoint-slide/&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Rectified Linear Unit (ReLU)
    &lt;ul&gt;
      &lt;li&gt;Fast to compute&lt;/li&gt;
      &lt;li&gt;Vanishing gradient problem&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280876-10d270b6-6457-4cfe-aa5a-33ac75a73968.png&quot; alt=&quot;Untitled_12&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985&quot;&gt;[Xavier Glorot, AISTATS’11] [3]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985&quot;&gt;[Andrew L. Maas, ICML’13] [4]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985&quot;&gt;[Kaiming He, arXiv’15] [5]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;dropout&quot;&gt;Dropout&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985&quot;&gt;Dropout [6]&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Each time before computing the gradients&lt;/li&gt;
  &lt;li&gt;Each neuron has $p \times 100 \%$ chance to be dropped
    &lt;ul&gt;
      &lt;li&gt;The structure of the network is changed&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Use the new network for training&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280877-2dc86cb3-9b0d-4d4e-a023-9033c7feecfe.png&quot; alt=&quot;Untitled_13&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280879-7b1bb0dc-9046-41c7-9b25-4a3a3181a9d7.png&quot; alt=&quot;Untitled_14&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Weights should be multiplied by (1-p) when testing&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;training-stage&quot;&gt;Training stage&lt;/h2&gt;

&lt;p&gt;Assume dropout rate is 50%&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280880-ff0c4282-cd2d-4a25-8f52-c12f00c7b30f.png&quot; alt=&quot;Untitled_15&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;testing-stage&quot;&gt;Testing stage&lt;/h3&gt;

&lt;p&gt;No dropout&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280882-0f356b1b-47ae-4161-ba6c-0bae951b40ef.png&quot; alt=&quot;Untitled_16&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;convolutional-neural-network&quot;&gt;Convolutional Neural Network&lt;/h1&gt;

&lt;h2 id=&quot;fully-connected-layer&quot;&gt;Fully connected layer&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Example: 200x200 image * 40K hidden units → ~2B parameters&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280884-b24fcebf-e58f-4fa8-91a0-f07fb0ae74f4.png&quot; alt=&quot;Slide Credit: Marc&apos;Aurelio Ranzato&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Slide Credit: Marc’Aurelio Ranzato&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Waste of resources + we have not enough training samples&lt;/li&gt;
  &lt;li&gt;Spatial correlation is local&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;locally-connected-layer&quot;&gt;Locally Connected Layer&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Example: 200x200 image * 40K hidden units → ~4M parameters (Filter size: 10x10)
Page 20- Spatial correlation is local&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280885-abf3d04d-52d9-4cc0-8e77-652c6a175602.png&quot; alt=&quot;Untitled_18&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Waste of resources + we have not enough training samples&lt;/li&gt;
  &lt;li&gt;Spatial correlation is local&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280888-46729577-a232-4023-83ae-b674f374652f.png&quot; alt=&quot;Untitled_19&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Statistics is similar at different locations
    &lt;ul&gt;
      &lt;li&gt;Share the same parameters across&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;different locations (weight sharing)
    &lt;ul&gt;
      &lt;li&gt;Convolutions with learned kernels&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;convolution-operation&quot;&gt;Convolution operation&lt;/h2&gt;

&lt;p&gt;$F(m,n) = f * h = \Sigma_{l= -\frac w 2}^{\frac f 2}\Sigma_{k= -\frac w 2}^{\frac w 2} {f(m+k, n+l) *h(\frac w 2 -k, \frac w 2 -l)}$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280891-91050b9e-3257-4c55-8b39-17d9cfdb9f02.png&quot; alt=&quot;Untitled_20&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280892-f7bb4b05-ff9c-4279-ab46-2a5d1fc9c858.png&quot; alt=&quot;Untitled_21&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If a feature is useful in some locations during training, detectors for that feature will be useful in all locations during testing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280893-984efb4c-2f50-4619-ada2-f6163419c454.png&quot; alt=&quot;Untitled_22&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;pooling&quot;&gt;Pooling&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;By “pooling” (e.g., taking max) filter responses at different locations, we gain robustness to the exact spatial location of features.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e67b7b1d-c185-4386-9709-7a1df8aa9300/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220903%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20220903T170529Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=ea14f0e42827df426e05d2d83b2b582cb021c2809728eb87c440796e4de8d8c1&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Untitled.png%22&amp;amp;x-id=GetObject&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e50a0769-e4bf-459b-a7d7-694d8349d6d5/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220903%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20220903T170547Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=086688091b424dd8949d23ca311338eb957bffd91cff034975057fbba1803b7c&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Untitled.png%22&amp;amp;x-id=GetObject&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-west-2.amazonaws.com/secure.notion-static.com/2c85de26-0778-4864-b757-e7fe1d00e352/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220903%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20220903T170601Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=7c91f58dfc23593943ce40dd7b381a325b1ec8821b7e585b5787ade47df9584c&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Untitled.png%22&amp;amp;x-id=GetObject&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;max-pooling&quot;&gt;Max-pooling&lt;/h3&gt;

&lt;p&gt;$h_i^n(r,c) = max_{\bar r \in N(r), \bar c \in N(c), } h_i^{n-1} (\bar r, \bar c)$&lt;/p&gt;

&lt;h3 id=&quot;average-pooling&quot;&gt;Average-pooling&lt;/h3&gt;

&lt;p&gt;$h_i^n(r,c) = mean_{\bar r \in N(r), \bar c \in N(c), } h_i^{n-1} (\bar r, \bar c)$&lt;/p&gt;

&lt;h3 id=&quot;l2-pooling&quot;&gt;L2-pooling&lt;/h3&gt;

&lt;p&gt;$h_i^n(r,c) = \sqrt{\Sigma_{\bar r \in N(r), \bar c \in N(c), } h_i^{n-1} (\bar r, \bar c)}$&lt;/p&gt;

&lt;h2 id=&quot;convolution-kernel-filter-examples&quot;&gt;Convolution kernel (filter) examples&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;9/Untitled_26.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Examples of learned object parts from object categories&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;9/Untitled_27.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lenet-5-1998&quot;&gt;LeNet-5 (1998)&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985&quot;&gt;[7] Le-Net&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Yann LeCun and his collaborators developed a really good recognizer for
handwritten digits by using backpropagation in a feedforward net with
    &lt;ul&gt;
      &lt;li&gt;Many hidden layers (at that time),&lt;/li&gt;
      &lt;li&gt;3 convolution layer,&lt;/li&gt;
      &lt;li&gt;2 subsampling (pooling) layer&lt;/li&gt;
      &lt;li&gt;5*5 convolution kernels,&lt;/li&gt;
      &lt;li&gt;~340,000 connections,&lt;/li&gt;
      &lt;li&gt;~60,000 parameter&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Used for reading ~10% of the checks in North America&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;9/Untitled_28.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;9/Untitled_29.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;9/Untitled_30.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;9/Untitled_31.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;backpropagation-in-cnn&quot;&gt;Backpropagation in CNN&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Same color shares the same weight&lt;/li&gt;
  &lt;li&gt;Compute the gradients as usual, and then modify the gradients so that they satisfy the constraints&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;9/Untitled_32.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;9/Untitled_33.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The 82 errors made by LeNet5&lt;/li&gt;
  &lt;li&gt;Notice that most of the errors are cases that people find quite easy.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The human error rate is probably 20 to 30 errors.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;LeNet uses knowledge about the invariances to design:
    &lt;ul&gt;
      &lt;li&gt;local connectivity&lt;/li&gt;
      &lt;li&gt;weight-sharing&lt;/li&gt;
      &lt;li&gt;Pooling&lt;/li&gt;
      &lt;li&gt;~ 80 errors&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Using many different transformations of the input and other tricks (Ranzato2008)
    &lt;ul&gt;
      &lt;li&gt;~ 40 errors&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Using carefully designed extra training data (Ciresan 2010)
    &lt;ul&gt;
      &lt;li&gt;For each training image, they produced many new training examples by applying many different transformations&lt;/li&gt;
      &lt;li&gt;~ 35 errors&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[Ciresan 2010][8]&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;9/Untitled_34.png&quot; alt=&quot;PyTorch implementation of LeNet-5 for MNIST, [https://github.com/radsn/LeNet5](https://github.com/radsn/LeNet5)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;PyTorch implementation of LeNet-5 for MNIST, &lt;a href=&quot;https://github.com/radsn/LeNet5&quot;&gt;https://github.com/radsn/LeNet5&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The top printed digit is the right answer.&lt;/li&gt;
  &lt;li&gt;The bottom two printed digits are the network’s best two guesses.&lt;/li&gt;
  &lt;li&gt;The right answer is almost always in the top 2 guesses.&lt;/li&gt;
  &lt;li&gt;With model averaging they can now get about 25 errors.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;from-handwritten-digits-to-3-d-objects&quot;&gt;From Handwritten Digits to 3-D objects&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Recognizing real objects in color photographs downloaded from the web is much more complicated than recognizing hand-written digits:
    &lt;ul&gt;
      &lt;li&gt;Hundred times as many classes (1000 vs 10)&lt;/li&gt;
      &lt;li&gt;Hundred times as many pixels (256* 256 color vs. 28* 28 gray)&lt;/li&gt;
      &lt;li&gt;Two dimensional image of three-dimensional scene&lt;/li&gt;
      &lt;li&gt;Multiple objects in each image&lt;/li&gt;
      &lt;li&gt;Cluttered background&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Will the same type of convolutional neural network work?&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;the-ilsvrc-2012-competition-on-imagenet&quot;&gt;The ILSVRC-2012 Competition on ImageNet&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;9/Untitled_35.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;[9] ImageNet
    &lt;ul&gt;
      &lt;li&gt;Over 15 million labeled high-resolution images&lt;/li&gt;
      &lt;li&gt;Roughly 22,000 categories&lt;/li&gt;
      &lt;li&gt;Collected from the web&lt;/li&gt;
      &lt;li&gt;Labeled by human using Amazon’s Mechanical Turk crowd-sourcing tool&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ImageNet Large-Scale Visual Recognition Challenge (ILSVRC)
    &lt;ul&gt;
      &lt;li&gt;Uses a subset of ImageNet&lt;/li&gt;
      &lt;li&gt;1,000 categories&lt;/li&gt;
      &lt;li&gt;1.2 million training images&lt;/li&gt;
      &lt;li&gt;50,000 validation images&lt;/li&gt;
      &lt;li&gt;150,000 test images&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The classification task:
    &lt;ul&gt;
      &lt;li&gt;Get the “correct” class in your top 5 bets. There are 1000 classes.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The localization task:
    &lt;ul&gt;
      &lt;li&gt;For each bet, put a box around the object. Your box must have at least 50%
  overlap with the correct box.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Some of the best existing computer vision methods were tried on this dataset by leading computer vision groups from Oxford, INRIA, XRCE(XEROX), …
    &lt;ul&gt;
      &lt;li&gt;Computer vision systems use complicated multi-stage systems&lt;/li&gt;
      &lt;li&gt;The early stages are typically hand-tuned by optimizing a few parameters&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;examples-from-the-test-set-with-the-networks-guesses&quot;&gt;Examples from the test set (with the network’s guesses)&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;9/Untitled_36.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Error rates on the ILSVRC-2012 competition&lt;/p&gt;

&lt;p&gt;|  | classification | classification &amp;amp; localization |
| — | — | — |
| UToronto
 | 16.4%  | 34.1% |
| UTokyo | 26.1% | 53.6% |
| Oxford University Computer Vision Group
 | 26.9% | 50.0% |
| INRIA + XRCE | 27.0% |  |
| UAmsterdam | 29.5% |  |&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;UToronto (deep learning - Alex Krizhevsky, AlexNet)&lt;/li&gt;
  &lt;li&gt;INRIA (French national research institute in CS) + XRCE (Xerox Research Center Europe)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;a-cnn-for-imagenet&quot;&gt;A CNN for ImageNet&lt;/h1&gt;

&lt;p&gt;AlexNet[10]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Alex Krizhevsky (NIPS 2012) developed a very deep convolutional neural net of the type pioneered by Yann LeCun.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;7 hidden layers not counting some max pooling layers&lt;/li&gt;
  &lt;li&gt;The early layers are convolutional, the last two layers are fully connected&lt;/li&gt;
  &lt;li&gt;The activation functions are
    &lt;ul&gt;
      &lt;li&gt;Rectified linear units in every hidden layer. These train much faster and are more expressive than sigmoid.&lt;/li&gt;
      &lt;li&gt;Normalization for better activation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Use “dropout” to regularize the weights in the fully connected layers&lt;/li&gt;
  &lt;li&gt;224&lt;em&gt;224 patches are taken from the 256&lt;/em&gt;256 images (10 different versions) and leftright reflections are used to get more data&lt;/li&gt;
  &lt;li&gt;Used all 10 different patches at test time&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;9/Untitled_37.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;more-examples-from-alexnet&quot;&gt;More examples from AlexNet&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;9/Untitled_38.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;hardware-for-alexnet&quot;&gt;Hardware for AlexNet&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;He uses a very efficient implementation of convolutional nets on two NvidiaGTX 580 Graphics Processor Units (over 1000 fast little cores)
    &lt;ul&gt;
      &lt;li&gt;GPUs are very good for matrix-matrix multiplies.&lt;/li&gt;
      &lt;li&gt;GPUs have very high bandwidth to memory.&lt;/li&gt;
      &lt;li&gt;This allows him to train the network in a week.&lt;/li&gt;
      &lt;li&gt;It also makes it quick to combine results from 10 patches at test time.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;We can spread a network over many cores if we can communicate the states fast enough.&lt;/li&gt;
  &lt;li&gt;As cores get cheaper and datasets get bigger, big neural nets will improve faster than old-fashioned computer vision systems.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;evolution-of-the-dnn&quot;&gt;Evolution of the DNN&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Network depths and the performance&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ILSVRC classification error (top-5 error)&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;9/Untitled_39.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;fully-convolutional-networks&quot;&gt;Fully Convolutional Networks&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Fully connected layer constrains the input image size&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;9/Untitled_40.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Fully convolutional network structure has no constrains on the input image size&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;9/Untitled_41.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;machine-learning-deep-learning-data-mining-big-data&quot;&gt;Machine Learning, Deep Learning, Data Mining, Big data&lt;/h1&gt;

&lt;h2 id=&quot;big-data&quot;&gt;Big Data&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;기존 데이터의 크기 범주를넘어서는 규모(2010~)&lt;/li&gt;
  &lt;li&gt;기존 데이터 처리 이슈 공유&lt;/li&gt;
  &lt;li&gt;대용량 데이터 분산저장/처리 방법 필요&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;machine-learning&quot;&gt;Machine Learning&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;데이터의 속성을 일반적으로 분석하는 방법, 주로 분류/회귀 작업에 사용됨(1950~)&lt;/li&gt;
  &lt;li&gt;지도학습/비지도학습/군집화&lt;/li&gt;
  &lt;li&gt;체스 게임으로부터 발전&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deep-learning-1&quot;&gt;Deep learning&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;심층 인공신경망 기술을 사용하는 기계학습 방법(2010~)&lt;/li&gt;
  &lt;li&gt;기존 기계학습 방법의 성능을 뛰어 넘음&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-mining&quot;&gt;Data Mining&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;데이터에 내재된 속성을 분석 (1930~)&lt;/li&gt;
  &lt;li&gt;기계학습과 유사하나 데이터 간의 규칙을 분석하는 측면으로 차별화&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;some-history&quot;&gt;Some history&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Frank Rosenblatt, Perceptron (1957, 1962): Early description and engineering of single-layer and multilayer artificial neural networks.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;9/Untitled_42.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kasparov vs Deep Blue, 1997&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;9/Untitled_43.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Lee Sedol vs AlphaGo, 2016&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;9/Untitled_44.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;timelines&quot;&gt;timelines&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;1943: Neural networks&lt;/li&gt;
  &lt;li&gt;1957-62: Perceptron&lt;/li&gt;
  &lt;li&gt;1970-86: Backpropagation, RBM, RNN&lt;/li&gt;
  &lt;li&gt;1979-98: CNN, MNIST, LSTM, Bidirectional RNN&lt;/li&gt;
  &lt;li&gt;2006: “Deep Learning”, DBN• 2009: ImageNet + AlexNet&lt;/li&gt;
  &lt;li&gt;2014: GANs&lt;/li&gt;
  &lt;li&gt;2016-17: AlphaGo, AlphaZero&lt;/li&gt;
  &lt;li&gt;Turing Award given for:
    &lt;ul&gt;
      &lt;li&gt;“The conceptual and engineering breakthroughs that have made deep neural
  networks a critical component of computing.”
  • Yann LeCun
  • Geoffrey Hinton
  • Yoshua Bengio&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;limitations-of-deep-learning&quot;&gt;Limitations of Deep Learning&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;9/Untitled_45.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Prediction from Rodney Brooks:
“By 2020, the popular press starts having stories that the era of Deep Learning is over.”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;2019 is the year it became cool to say that “deep learning” has limitations.&lt;/li&gt;
  &lt;li&gt;Books, articles, lectures, debates, videos were released that learning-based methods cannot do commonsense reasoning.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;statics-of-acceptance-rate-neurips&quot;&gt;Statics of acceptance rate NeurIPS&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;9/Untitled_46.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;deep-learning-frameworktoolkits&quot;&gt;Deep Learning Framework/Toolkits&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;9/Untitled_47.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;alexnet&quot;&gt;AlexNet&lt;/h2&gt;

&lt;p&gt;https://sushscience.wordpress.com/2016/12/04/understanding-alexnet/&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;9/Untitled_48.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;[1] Geoffrey Hinton showed how to train deep network in 2006&lt;/p&gt;

&lt;p&gt;[2] Deep Neural Networks showed good classification performance with large image data set in 2012.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985&quot;&gt;[3] [Xavier Glorot, AISTATS’11]&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Deep Sparse Rectifier Neural Networks. &lt;strong&gt;&lt;em&gt;Xavier Glorot, Antoine Bordes, Yoshua Bengio&lt;/em&gt;&lt;/strong&gt;
 &lt;em&gt;Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics.&lt;/em&gt; PMLR 15:315-323, 2011.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://proceedings.mlr.press/v15/glorot11a.html&quot;&gt;https://proceedings.mlr.press/v15/glorot11a.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985&quot;&gt;[4] [Andrew L. Maas, ICML’13]&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Rectifier nonlinearities improve neural network acoustic models (2013) by Andrew L. Maas , Awni Y. Hannun , Andrew Y. Ng&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf&quot;&gt;https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985&quot;&gt;[5] [Kaiming He, arXiv’15]&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Deep Residual Learning for Image Recognition📹
by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1512.03385&quot;&gt;https://arxiv.org/abs/1512.03385&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985&quot;&gt;[6] Dropout: A Simple Way to Prevent Neural Networks from Overfitting&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov&lt;/em&gt;&lt;/strong&gt;; 15(56):1929−1958, 2014.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/6-2-DropOut-7f9244899e884b27969f212af344b6a1&quot;&gt;6.2. DropOut&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/Dropout-A-simple-way-to-prevent-neural-networks-from-overfitting-2014-N-Srivastava-et-al-pdf-b70dbe733db749bfbff250abeb9813e4&quot;&gt;Dropout: A simple way to prevent neural networks from overfitting (2014), N. Srivastava et al. [pdf]&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://jmlr.org/papers/v15/srivastava14a.html&quot;&gt;https://jmlr.org/papers/v15/srivastava14a.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985&quot;&gt;[7] Le-Net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf&quot;&gt;http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/5-1-LeNet-8a448781423b4a3591b77dd91d76a272&quot;&gt;5.1. &lt;strong&gt;LeNet&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[8] [Ciresan 2010]&lt;/p&gt;

&lt;p&gt;[9] ImageNet&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.notion.so/ImageNet-67d9a42cba374a83afb7836c48e304f6&quot;&gt;ImageNet&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ImageNet: A large-scale hierarchical image database&lt;/p&gt;

&lt;p&gt;by Jia Deng; Wei Dong; Richard Socher; Li-Jia Li; Kai Li; Li Fei-Fei&lt;/p&gt;</content><author><name>KyuHwan Shim</name><email>skh7343@cnsh.hs.kr</email></author><category term="ml" /><category term="ML" /><category term="AI" /><category term="Lecture" /><summary type="html">Chap9.DNN</summary></entry><entry xml:lang="en"><title type="html">Artificial Neural Net (Chapter 8)</title><link href="http://localhost:4000/blog/ML-8-ANN/" rel="alternate" type="text/html" title="Artificial Neural Net (Chapter 8)" /><published>2022-06-03T12:26:09+09:00</published><updated>2022-06-03T12:26:09+09:00</updated><id>http://localhost:4000/blog/ML-8-ANN</id><content type="html" xml:base="http://localhost:4000/blog/ML-8-ANN/">&lt;h1 id=&quot;8-ann&quot;&gt;8. ANN&lt;/h1&gt;

&lt;h1 id=&quot;ann-introduction&quot;&gt;ANN Introduction&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280599-fd556de5-9369-437d-b9da-ddbac640bd3e.png&quot; alt=&quot;h+ p ://cs231n.stanford.edu/slides/winter1516_lecture4.pdf&quot; /&gt;&lt;/p&gt;

&lt;p&gt;h+ p ://cs231n.stanford.edu/slides/winter1516_lecture4.pdf&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280605-6b5b6d58-7520-47aa-b52f-bc527b096ea1.png&quot; alt=&quot;© 2017, SNU BioIntelligence Lab, h+ p ://bi.snu.ac.kr/&quot; /&gt;&lt;/p&gt;

&lt;p&gt;© 2017, SNU BioIntelligence Lab, h+ p ://bi.snu.ac.kr/&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;/li&gt;
  &lt;li&gt;Classification with a line, $y = ax + b$
    &lt;ul&gt;
      &lt;li&gt;single, multi layer perceptron with NN&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280608-8fc02bb6-d702-4a2d-9787-24b564739e9d.png&quot; alt=&quot;Untitled_2&quot; /&gt;
  &lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280609-111f213a-6d3f-40ec-9b44-0c154736abe1.png&quot; alt=&quot;Untitled_3&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Generalization&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280610-1e1b8f1f-7146-4151-8992-beecbd21148e.png&quot; alt=&quot;Untitled_4&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;artificial-neural-networks-2-layers&quot;&gt;Artificial Neural Networks (2 layers)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;NN 기본 구조 perceptron → hidden layer 쌓아 DNN&lt;/li&gt;
  &lt;li&gt;Two-layer network
    &lt;ul&gt;
      &lt;li&gt;input layer + output layer (2)&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280613-92493064-dc7e-4b5b-9e1c-eb139df14d42.png&quot; alt=&quot;Untitled_6&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;sigmoid 형태&lt;/li&gt;
      &lt;li&gt;no hidden layer → linearly separable prob only&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280612-1c48ef53-13ac-4d4d-b8e3-249d3b14124f.png&quot; alt=&quot;Untitled_5&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;and&quot;&gt;AND&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280614-20e30d3a-eea9-4ee1-9d30-5ad80c6ffdba.png&quot; alt=&quot;Untitled_7&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280615-3a2d3b4f-3ebb-41c3-8990-69ed36044297.png&quot; alt=&quot;Untitled_8&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280617-419dd254-73e0-4147-a75f-9fbe63c5ffd3.png&quot; alt=&quot;Untitled_9&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;or&quot;&gt;OR&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280618-c0b0a7a2-586e-4934-838f-4dd35f0ad0b9.png&quot; alt=&quot;Untitled_10&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280619-f0e88fd8-f90f-4dd0-bb97-2fcc32431c8e.png&quot; alt=&quot;Untitled_11&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280620-a5af0e0b-c03f-4713-bc74-c328d09f25f2.png&quot; alt=&quot;Untitled_12&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;xor&quot;&gt;XOR&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280621-5b7cf2f0-6451-4b1c-9232-99f0db454138.png&quot; alt=&quot;Untitled_13&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280622-ea215239-ba67-471a-815a-87601d488648.png&quot; alt=&quot;Untitled_14&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Two layer network cannot implement XOR.
    &lt;ul&gt;
      &lt;li&gt;perceptron 으로 분류 시 error가 크게 나타남&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Non-linear
    &lt;ul&gt;
      &lt;li&gt;two decision boundary (nonlinear)&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280623-6edf3a68-4022-4a53-8d79-4a482826ac5a.png&quot; alt=&quot;Untitled_15&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280625-b764e005-d90a-4d34-a441-a38c55250088.png&quot; alt=&quot;Untitled_16&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;multi-layer-networks&quot;&gt;Multi-layer Networks&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280626-1a22355d-ff83-467f-bb86-05e868a63b2d.png&quot; alt=&quot;Untitled_17&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;input - hidden - output&lt;/li&gt;
  &lt;li&gt;hidden layer 개수 → 몇 개인지에 따라 network 구조가 좌우됨
    &lt;ul&gt;
      &lt;li&gt;linearly nonsolvable 문제들도 풀 수 있게 된다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280628-c3a6a074-c967-466a-b133-ce3d9d311c94.png&quot; alt=&quot;Untitled_18&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280630-bb888c8e-ba9f-4ed4-b184-3f37dee0a88d.png&quot; alt=&quot;Untitled_19&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280632-3398c4bf-532a-43fc-849b-6f597ee07b14.png&quot; alt=&quot;Untitled_20&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;hidden layer 1개 추가 → 많은 가중치 w들을 학습한다&lt;/li&gt;
  &lt;li&gt;수백개 hidden layer →  수천, 수만 w 학습&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280633-8a876c51-60a8-488d-a21e-3d60d5bbf7da.png&quot; alt=&quot;Untitled_21&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280635-184498eb-10dd-4446-a78e-25c1df09ee3f.png&quot; alt=&quot;Untitled_22&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280636-97988193-22f4-4fa6-8b12-76a172f7e1b9.png&quot; alt=&quot;Untitled_23&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$wx = \Sigma_i w_i x_i$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280637-228af070-e1ab-4faa-a98a-31e4e128191c.png&quot; alt=&quot;Untitled_24&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;feature space : input layer → hidden layer&lt;/li&gt;
  &lt;li&gt;SVM과 유사한 효과 : high dimension
    &lt;ul&gt;
      &lt;li&gt;원래 feature space: 원래는 not linearly separable하지만 high dimension phi fn을 활용
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280640-d4713e9e-ab23-4794-9b84-8723cffdf9a2.png&quot; alt=&quot;Untitled_25&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280641-0587860d-c9fc-4a66-a3a4-afd8d2b8b694.png&quot; alt=&quot;Untitled_26&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;hidden layer를 추가하면 → 복잡한 boundary를 구할 수 있다&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280643-c9e43cb8-8720-4718-86bd-48ffa1b8156d.png&quot; alt=&quot;Untitled_27&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;ann-training&quot;&gt;ANN Training&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;ANN training?
    &lt;ul&gt;
      &lt;li&gt;Estimate w by using training data&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280645-267339ea-354b-4f80-8597-78065553e3f4.png&quot; alt=&quot;Untitled_28&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;|  | training |
  | — | — |
  | perceptron | w |
  | SVM | w :&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;table&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;margin, slack var, Phi fn&lt;/td&gt;
              &lt;td&gt; &lt;/td&gt;
              &lt;td&gt; &lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt; &lt;/td&gt;
              &lt;td&gt;Bayesian&lt;/td&gt;
              &lt;td&gt;G(mu, sigma^2) : prior&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;density modeling → likelihood&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;table&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;prior P → post P&lt;/td&gt;
              &lt;td&gt; &lt;/td&gt;
              &lt;td&gt; &lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt; &lt;/td&gt;
              &lt;td&gt;Decision Tree&lt;/td&gt;
              &lt;td&gt;Tree 구조&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt; &lt;/td&gt;
              &lt;td&gt;kNN&lt;/td&gt;
              &lt;td&gt;save train data&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
      &lt;/li&gt;
      &lt;li&gt;k value : train통해 결정&lt;/li&gt;
      &lt;li&gt;dinstance metric  : 
  L1 vs L2 vs Euclidean |
  | ANN | w
  NN Structure&lt;/li&gt;
      &lt;li&gt;
        &lt;table&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;I/H/O Layer개수&lt;/td&gt;
              &lt;td&gt; &lt;/td&gt;
              &lt;td&gt; &lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt; &lt;/td&gt;
              &lt;td&gt;DNN&lt;/td&gt;
              &lt;td&gt; &lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt; &lt;/td&gt;
              &lt;td&gt; &lt;/td&gt;
              &lt;td&gt; &lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;test data 분류 작업&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;regularizer&lt;/li&gt;
      &lt;li&gt;hyperparameter normalize&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;By experiment ← train 중 parameter 결정&lt;/li&gt;
  &lt;li&gt;data  : multimedia&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;1-decide-input-layers-node-number&quot;&gt;1. Decide input layer’s node number&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;By experiments, use domain knowledge&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280647-6977fd58-709a-4a5a-89c4-7198e97e0c39.png&quot; alt=&quot;Untitled_29&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;2-decide-output-layers-node-number&quot;&gt;2. Decide output layer’s node number&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;By experiments, use domain knowledge&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280648-ef85e47c-b544-4c90-b78c-a1052346482b.png&quot; alt=&quot;Untitled_30&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280649-d3324505-f5bd-4df1-a18b-d51cb016fc29.png&quot; alt=&quot;Untitled_31&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;구조만 보면 class가 몇 개인지 모른다&lt;/li&gt;
  &lt;li&gt;class 수 = node 수
    &lt;ul&gt;
      &lt;li&gt;classification : output layer node의 activation 여부 확인&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-decide-hidden-layers-node-number&quot;&gt;3. Decide hidden layer’s node number&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;By experiments, use domain knowledge&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280650-380a553d-089d-4fdd-b59c-91c44476c173.png&quot; alt=&quot;Untitled_32&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;4-find-weight-using-training-algorithm&quot;&gt;4. Find weight using training algorithm&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Use back-propagation algorithm. Supervised learning.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280652-89137d13-9776-4895-9188-edda2933dea3.png&quot; alt=&quot;Untitled_33&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;back-propagation-algorithm&quot;&gt;Back-propagation Algorithm&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;등장 배경 : NN → SVM →DNN
    &lt;ul&gt;
      &lt;li&gt;image가 낮인지 밤인지 예견하는 문제&lt;/li&gt;
      &lt;li&gt;data를 잘 준비했어야 하는데 overfitting을 해결하지 못하여 SVM이 1990-2010년도 성행&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;train with back propagation algorithm
    &lt;ul&gt;
      &lt;li&gt;w값 arbitraily initialize → feed forward :
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;w : $\epsilon \downarrow$방향으로 update&lt;/strong&gt;&lt;/li&gt;
          &lt;li&gt;between prediction , ground truth value&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;$y = f (\Sigma_i x_i w_{ij} + b)$
    &lt;ul&gt;
      &lt;li&gt;network의 구조가 결정되면 다음 layer의 node값에 bias를 더하는 함수&lt;/li&gt;
      &lt;li&gt;perceptron 문제와 유사하게 발생 :
        &lt;ul&gt;
          &lt;li&gt;local minima&lt;/li&gt;
          &lt;li&gt;many w → T 증가&lt;/li&gt;
          &lt;li&gt;iterative하게 w 구하는 과정&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280654-7626b34b-fdb4-4169-a409-fb02a3a56ecf.png&quot; alt=&quot;Untitled_34&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;모든 edge에 할당된 w에 대하여 backpropagation&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280655-7390abaa-af14-4eb6-b7ac-a7f2e8393e48.png&quot; alt=&quot;Untitled_35&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;w update하면 iteration 반복 많아짐&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;hidden 많아지면 update bigger&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$E = \Sigma_k \frac 1 2 (z_k - t_k)^2$&lt;/p&gt;

    &lt;p&gt;tk : ground truth&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;제곱을 하고 2로 나누어준 이유 : perceptron처럼, 미분을 위해 제곱하고 1/2 *2하면 표현식이 간단해진다&lt;/li&gt;
      &lt;li&gt;error 미분 : wij, wji 미분하여 update&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;chain rule&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\frac{\partial E}{\partial w_{kj}} = \frac{\partial E}{\partial z_{k}} \frac{\partial z_k}{\partial w_{kj}}$&lt;/li&gt;
  &lt;li&gt;$\frac{\partial E}{\partial w_{ji}} = \frac{\partial E}{\partial z_{k}} \frac{\partial z_k}{\partial w_{ji}}  = \frac{\partial E}{\partial z_{k}} \frac{\partial z_k}{\partial y_j}\frac{\partial y_j}{\partial w_{ji}}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280656-b3bbb82c-b51b-404b-983c-89b001b5b435.png&quot; alt=&quot;Untitled_36&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280657-3d4e8155-0461-4529-aacb-4f22e646141d.png&quot; alt=&quot;Untitled_37&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280658-060efecd-4e1a-4b11-afaf-857232a6c63e.png&quot; alt=&quot;Untitled_38&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280659-753d7774-270d-4f3a-8b56-087a084f2726.png&quot; alt=&quot;Untitled_39&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;big NN의 한계 : hidden layer 제한 → 다양한 성능 제한&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;hidden layer수 증가 감소 이유 :???&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;output에서 input으로 backpropagate할 수록 더 많은 chain rule (Differentiation) 수행 → update양 감소&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;To update weights far from the output layer, more nodes and their derivatives are involved. Due to the chain rule, the amount of update becomes smaller.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;activation-function-sigmoid&quot;&gt;Activation function: sigmoid&lt;/h2&gt;

&lt;p&gt;perceptron, SVM&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;input data (weight) - f(x) update
    &lt;ul&gt;
      &lt;li&gt;동일한 input에 대해 error 계산&lt;/li&gt;
      &lt;li&gt;error가 각 iteration별로 작아짐&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;input data 바꾸면 - updated w도 new input data에 부적절할수도 있으니 fix해야 한다&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280660-50fa1def-3a03-4b0c-9aec-17747f5d1e33.png&quot; alt=&quot;Untitled_40&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;부적합&lt;/li&gt;
  &lt;li&gt;SVM에서, nondifferentiable fn : hinge loss → 구간 나누어 미분 → 복잡해지는 미분 계산 과정 itreation
    &lt;ul&gt;
      &lt;li&gt;수학적으로 옳지는 않다??&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280661-d687f5c3-18e8-4ab5-a137-6fed144b840a.png&quot; alt=&quot;Untitled_41&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280662-b775a1fd-9428-4e7e-953e-688559836ae3.png&quot; alt=&quot;Untitled_42&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;back propagation example
    &lt;ul&gt;
      &lt;li&gt;Ex) 1st error = 0.298371109 
  2nd error = 0.291027924
  …
  …
  10000th error = 0.000035085&lt;/li&gt;
      &lt;li&gt;output neurons after 10000th iteration : 
  0.015912196 (vs 0.01 target) 
  0.984065734 (vs 0.99 target)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280663-18f4a527-57ac-4a79-a965-7dc9bb2e8228.png&quot; alt=&quot;Untitled_43&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;error : 역전파하면서 error 감소
    &lt;ul&gt;
      &lt;li&gt;10000th로 갈수록 0으로 error 수렴&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;output neuron : target에 근사&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;deep-neural-network&quot;&gt;Deep Neural Network&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280666-bf6f4813-099e-47a9-bac8-5e1f65a9b1df.png&quot; alt=&quot;Untitled_44&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;raw data in real world : 영상 획득, microphone 녹음 등 ..&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DNN : Number of hidden layers&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h1 id=&quot;of-hidden-layers-leq-1--shallow-neural-network&quot;&gt;of hidden layers $\leq 1$ → Shallow Neural Network&lt;/h1&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h1 id=&quot;of-hidden-layers-geq-2--deep-neural-network&quot;&gt;of hidden layers $\geq 2$ → Deep Neural Network&lt;/h1&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280667-12a4453c-311d-4c89-8b39-ade39e245887.png&quot; alt=&quot;Untitled_45&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;dnn-training&quot;&gt;DNN Training&lt;/h2&gt;

&lt;h3 id=&quot;vanishing-gradient-problem&quot;&gt;Vanishing gradient problem&lt;/h3&gt;

&lt;p&gt;Problem with non-linear activation&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;As errors are back propagated, the gradient vanishes&lt;/li&gt;
  &lt;li&gt;Derivatives of sigmoid are 0~0.25. As these are multiplied at multiple layers, they become smaller and smaller&lt;/li&gt;
  &lt;li&gt;$w_{ji} = w_{ij} -\eta \frac {\partial E}{\partial w_{ji}}$: as $\frac {\partial E}{\partial w_{ji}}$becomes smaller, $w$ is not well updated, especially for the layers far from the output layer&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280669-e2e0bd8c-ab14-42f7-8653-bc7ec91adc16.png&quot; alt=&quot;Untitled_46&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Typically requires lots of labeled data
    &lt;ul&gt;
      &lt;li&gt;Collecting data is time consuming and expensive (time, price)&lt;/li&gt;
      &lt;li&gt;but time 소모 증가, 비용 증가
        &lt;ul&gt;
          &lt;li&gt;data collection, tagging, labeling&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;2010년도 DNN의 발전배경  :
        &lt;ul&gt;
          &lt;li&gt;Big data → 수집 용이&lt;/li&gt;
          &lt;li&gt;GPU (HW Support)&lt;/li&gt;
          &lt;li&gt;Algorithm적 발달&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Overfitting problem&lt;/em&gt;&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;When training data is not sufficient, model only can handle the training data well (poor performance at test time)&lt;/li&gt;
      &lt;li&gt;data 변화 요인에 w 학습하고 , 다양한 test에 대해서도 적용&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280670-892307f0-cbe3-4e9f-86e0-60f4836eb8b0.png&quot; alt=&quot;Untitled_47&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;ground truth sampling → data에 fit하여 정답과 일치하도록&lt;/li&gt;
  &lt;li&gt;overfitting : regression, classification 시 정답을 보지 않아도 train well됨을 확인함&lt;/li&gt;
  &lt;li&gt;Get stuck in &lt;strong&gt;local minima : iteration시 유의&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Problem even with enough training data&lt;/li&gt;
      &lt;li&gt;solution : 초기값을 randomly setting하고 train을 많이 하여 그 avearge를 추출한다
        &lt;ul&gt;
          &lt;li&gt;test set에 대해 일반적으로 성능 좋아짐&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Train Set 에서의 문
    &lt;ul&gt;
      &lt;li&gt;input data : raw data→ input layer : x1, x2&lt;/li&gt;
      &lt;li&gt;state of the nature $\in$ real world&lt;/li&gt;
      &lt;li&gt;학습 data로 model을 만들지만 prediction-ground truth가 0이라고 하여도 좋은 model인지 아닌지 확신할 수 없다.
        &lt;ul&gt;
          &lt;li&gt;사실 정답을 알 리가 없다 : 그 정답으로 추출된 제한된 관찰에 의해 얻어진 학습 data로 model을 구한 것이기에&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;sol &lt;strong&gt;→ train data를 변화시키며 model이 얼마나 안정된 결과를 보이는지 (test data를 변화시키기도 해보자)&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Vanishing gradient problem
    &lt;ul&gt;
      &lt;li&gt;ReLU(Rectified Linear Unit)
        &lt;ul&gt;
          &lt;li&gt;$\max(0,x)$ gradient update&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Layer-wise training
        &lt;ul&gt;
          &lt;li&gt;
            &lt;p&gt;충분히 학습되었다면 건너뜀&lt;/p&gt;

            &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46957634/188280673-e07ecb47-7d3a-46dc-9a95-8923804b9d01.png&quot; alt=&quot;Untitled_48&quot; /&gt;&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Requires &lt;strong&gt;lots&lt;/strong&gt; of labeled data&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Overfitting&lt;/strong&gt; problem&lt;/li&gt;
  &lt;li&gt;Get stuck in &lt;strong&gt;local minima&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Mitigated by increasing data and computation power&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;시간 소모 :
    &lt;ul&gt;
      &lt;li&gt;depend on performance of HW&lt;/li&gt;
      &lt;li&gt;w update : vanishing gradient → activation fn 변화&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>KyuHwan Shim</name><email>skh7343@cnsh.hs.kr</email></author><category term="ml" /><category term="ML" /><category term="AI" /><category term="Lecture" /><summary type="html">Chap8.ANN</summary></entry></feed>