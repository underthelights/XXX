<h1 id="6-concurrent-prog">6. Concurrent Prog.</h1>

<p>Property: CSAPP 6</p>

<ul>
  <li><strong>Thread</strong>
    <ul>
      <li>stack not shared, process~~ 보다 더 명확하게 state할 것</li>
    </ul>
  </li>
  <li><strong>Process vs Thread</strong>
    <ul>
      <li>
        <p>Similarity</p>

        <p>has its own logical control flow</p>

        <p>can run concurrently with others (also on different core)</p>

        <p>context switched?</p>
      </li>
      <li>
        <p>Differences</p>
        <ol>
          <li>Process
            <ol>
              <li>process privacy - on each process, physically isolated된 상태로 OS설계시 만들어진다. → process마다 addr space가 달라서 data를 share하기 어렵다 :</li>
              <li>via IPC (message passing shared memory) Mechanism - FIFO, shared memory, semaphore</li>
            </ol>
          </li>
          <li>Thread
            <ol>
              <li>1 process내 많은 execution flow가 존재한다.</li>
              <li>Heap, Data, Code가 공유된다 → thread끼리 easy to share data
                <ul>
                  <li>Local stack은 제외</li>
                </ul>
              </li>
              <li>effective cost than process : process control cycle is more expensive</li>
            </ol>
          </li>
        </ol>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Race, Deadlock, Livelock, Starvation, Fairness : Def &amp; contents</strong></p>

    <p>(사고 접근) 화장실이 하나 있는데 대기자 5명 / 허니버터칩 등 대란</p>

    <ol>
      <li><strong>Race</strong>
        <ol>
          <li>(def) outcome depends on arbitrary scheduling decisions elsewhere in the system</li>
          <li>(비유) 무한 경쟁</li>
        </ol>
      </li>
      <li><strong>Deadlock</strong>
        <ol>
          <li>(def) improper rsrc alloc prevents forward progress</li>
          <li>(비유) 교차로 무한대기 - 누구도 지나가지 못하고 state에서 횡행하며 무한대기</li>
          <li>(sol) order 설정 (OS범위)</li>
        </ol>
      </li>
      <li><strong>Livelock</strong>
        <ol>
          <li>(def) shared memory내 오직 한 Process만 접근 가능 
 → lock을 잡기 위해 매번 시도한다.</li>
          <li>(결과) 잡지도 못하는데도 불구하고 지속해서 시도하기에 inefficient CPU Usage</li>
        </ol>
      </li>
      <li><strong>Starvation</strong>
        <ol>
          <li>(def) 한 번도 lock 잡을 Chance를 갖지 못하는 Process 발생</li>
        </ol>
      </li>
      <li><strong>Fairness</strong>
        <ol>
          <li>(def) 공정히 compete했음에도 한 process가 독식하며 필요한 clock cycle만큼 획득하지 못하는 현상</li>
          <li>(비유) 교차로 무한대기</li>
        </ol>
      </li>
    </ol>
  </li>
  <li>[2021기출-12] <strong>Process based concurrency vs Event-based concurrency vs thread-base concurrency</strong>
    <ul>
      <li>
        <ol>
          <li><strong>Process-based :</strong> server가 client 개수만큼 multiple process</li>
          <li>single process : if loop에 따라 file descriptor 본 후 event가 있는 경우 handling
            <ul>
              <li><strong>kernel automatically interleaves : multiple logical flows</strong></li>
              <li><code class="language-plaintext highlighter-rouge">**Listenfd</code>에 각 Connection 요청 마다 parent process를 accept하고 client에 <code class="language-plaintext highlighter-rouge">fork()</code>를 띄워 <code class="language-plaintext highlighter-rouge">connfd</code>와 client를 연결시켜 각 client마다 자신만의 address space를 가질 수 있도록 한다.  → Process Privacy : 각 client의 space는 독립적인 고립된 공간이다.**</li>
              <li><strong>Pros</strong></li>
            </ul>
            <ul>
              <li>Handle multiple connections concurrently</li>
              <li>clean sharing model : file table</li>
              <li>simple, straightforward → isolated address space :execution flow 변화 고려 필요 X
        - <strong>Cons</strong></li>
              <li>additional overhead for process control - server: client개수만큼 process fork 진행
                <ul>
                  <li>110개의 client가 들어오면 110개의 Fork가 진행된다.</li>
                </ul>
              </li>
              <li>Nontrivial to share data between processes : Hard to share rsrcs 
 (pros : avoid unintended sharing)
                <ul>
                  <li>Isolated -&gt;→ process마다 addr space가 달라서 data를 share하기 어렵다 :</li>
                  <li>via IPC (interprocess communication message passing shared memory) Mechanism - FIFO, shared memory, semaphore → data share가능해짐
    - Issues :</li>
                </ul>
              </li>
              <li>listening server process : must reap zombie chiled - prevent memory leak</li>
              <li>close its copy of <code class="language-plaintext highlighter-rouge">connfd</code></li>
            </ul>
          </li>
        </ol>
      </li>
      <li>
        <ol>
          <li><strong>Event-Based</strong> : process 1개
            <ul>
              <li>programmer에 의해 mulitple logical flow 수동</li>
              <li>server daemon이 listenfd의 Connection request가 client로부터 오는지 보고 그에 맞춰 connfd 생성 → client-server channel 생성 후 응답</li>
              <li><strong>각 client들이 fd를 따로 두어, process의 조건에 따라 각자 처리한다.</strong></li>
            </ul>
            <ul>
              <li><code class="language-plaintext highlighter-rouge">**connfd</code> - Descriptor에 pending input의 유무를 확인한 후 : <code class="language-plaintext highlighter-rouge">epoll</code>, <code class="language-plaintext highlighter-rouge">select</code>**
                <ul>
                  <li>ask kernel to suspend the process, returning control to applicatoin after 1개 이상의 IO Event 발생시</li>
                </ul>
              </li>
              <li><code class="language-plaintext highlighter-rouge">**listenfd</code> 있다면 event 처리: <code class="language-plaintext highlighter-rouge">accept</code>통해 Connection + new connfd 배열에 추가**
                <ul>
                  <li>없다면 skip한다.
                    <ul>
                      <li>all flows share : same address space</li>
                    </ul>
                  </li>
                </ul>
              </li>
              <li>IO Multiplexing : client 1, 2,3에 fd 따로 → Process if loop에 따라 각자 처리함
    - <strong>Pros</strong></li>
              <li>One logical control flow and address space.</li>
              <li>Can single-step with a debugger.
                <ul>
                  <li>total control over scheduling</li>
                  <li>tedious, low-lv</li>
                </ul>
              </li>
              <li><strong>Very Low overhead :</strong> No process or thread control overhead.
                <ul>
                  <li>Design of choice for high-performance Web servers and search engines.</li>
                  <li>e.g., Node.js, nginx, Tornado
                    <ul>
                      <li>Cons</li>
                    </ul>
                  </li>
                </ul>
              </li>
              <li>Significantly <strong>more complex</strong> to code than process- or thread-based designs.</li>
              <li>Hard to provide <strong>fine-grained concurrency</strong> → developer 알아서
                <ul>
                  <li>E.g., how to deal with partial HTTP request headers</li>
                </ul>
              </li>
              <li>Cannot take advantage of <strong>multi-core</strong>
                <ul>
                  <li>Single thread of control + 나머지는 놀고 있다!</li>
                </ul>
              </li>
            </ul>
          </li>
        </ol>
      </li>
      <li>
        <ol>
          <li><strong>Thread-Based</strong> : process 1개 → lightweight concurrent programming
            <ul>
              <li>kernel automatically interleaves : multiple logical flows</li>
              <li>kernel에 의해 mulitple logical flow 자동</li>
              <li><strong>each flows share : same address space</strong></li>
              <li>process based + event based / mid overhead</li>
              <li>issues</li>
            </ul>
            <ul>
              <li><strong>run ‘detached’ to avoid memory leak</strong>
                <ul>
                  <li>joinable thread - can be reaped, killed by other thread
  → reap to free memory rsrc</li>
                  <li>detached thread - can’t be reaped, killed by others 
  → rsrcs automatically reaped on termination</li>
                </ul>
              </li>
              <li>all fn called by thread must be <strong>thread-safe</strong>
    - Pros</li>
              <li><strong>Easy to share</strong> data structs between threads</li>
              <li>efficient than process : not so much control voer scheduling policies
    - Cons</li>
              <li>careful to avoid unintended sharing → subtle, hard-to-reproduce error
                <ul>
                  <li>synchronization</li>
                </ul>
              </li>
              <li>구현이 복잡하다 &amp; debug 어렵다:
                <ul>
                  <li>event orderings not repeatable + shared data로 인한 unexpected error</li>
                </ul>
              </li>
              <li>overhead많다: process creation overhead + process간 context switch overhead</li>
            </ul>
          </li>
        </ol>
      </li>
    </ul>
  </li>
  <li><strong>Thread : stack variable에서 다른 thread가 visible한 이유</strong>
    <ul>
      <li>개념 : Thread는 다른 stack invisible</li>
      <li>실제 : trick을 통해 reference 가능
        <ul>
          <li>global variable indirection</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Thread view</strong>
    <ol>
      <li>Traditional view
        <ol>
          <li>
            <p>[Process] = [Process context] + [code, data, stack]</p>

            <p><img src="https://user-images.githubusercontent.com/46957634/183250210-85429987-e8b7-4f6f-8b8b-9f40c3b04111.png" alt="Untitled" /></p>
          </li>
        </ol>
      </li>
      <li>Alternative view
        <ol>
          <li>
            <p>[Thread] + [code, data, kernel context]</p>

            <p>[Thread] = [stack] + [thread context]</p>

            <p><img src="https://user-images.githubusercontent.com/46957634/183250208-7422ff11-a03f-46eb-9d95-70b59e032b68.png" alt="Untitled-1" /></p>
          </li>
          <li>
            <p>each thread has</p>
            <ol>
              <li>has its own logical control flow  / own TID</li>
              <li>has its own stack for logical var - not protected from other thread</li>
              <li>same code, data, kernel context</li>
            </ol>
          </li>
        </ol>
      </li>
    </ol>

    <ul>
      <li>Concurrent execution
        <ul>
          <li>single-core : simulate parallelism by time slicing</li>
          <li>multi-core : true parallelism</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>[2021] Iterative server (6-concurrent programming)</strong></p>

    <p>[2021기출] iterative servers process one request at a time. in this iterative server, while a client exchanges messages with the server, the second client is blocking. however, the second client was still able to send a message even though the server didn’t accept the connection request. where and how is the message sent by the second client managed?</p>

    <p>Second client는 connection을 server에 요청했으나 First Client에 의해 blocking된 상태이다. 그러나 message를 보낼 수는 있기 때문에 해당 server process가 돌고 있는 OS의 TCP Manager내 write()함수를 수행할 수 있다. 이는 읽을 수 없고 buffering만 되어 있는 상태이다.</p>

    <p>실제로 수행되기 위해서는 first client가 close하여 client2와의 새로운 connection이 형성되면 해당 message를 read하고 write한다.</p>
  </li>
</ul>
