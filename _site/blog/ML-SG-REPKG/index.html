<h1 id="final-repkg-for-ml">[Final Repkg. for ML]</h1>

<h1 id="7-knn">7. kNN</h1>

<p><a href="https://www.notion.so/7-k-Nearest-Neighbor-abad63e2757e4de39af29914c4c63e82">7. k-Nearest Neighbor</a></p>

<ul>
  <li>
    <p><strong>kNN = Instance based learning</strong></p>

    <p>주어진 test sample X에 대하여, kNN samples (xn1, yn1) … (xnk, ynk)를 위치시켜 majority class label yn1, .. ynk를 xt에 assign한다.</p>
  </li>
  <li><strong>kNN pros and cons</strong>
    <ul>
      <li>pros :
        <ul>
          <li>training is very fast : feature extraction and save</li>
          <li>learn complex target fn</li>
          <li>doesn’t lose info</li>
        </ul>
      </li>
      <li>cons :
        <ul>
          <li>slow at test  → not goot</li>
          <li>requires large storage</li>
          <li>not robust against irrevalent attributes, outliers</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Distance Metrics</strong>
    <ul>
      <li>kNN - test 시점 ) data와 Near한지 distance 계산</li>
      <li>distance : 모든 Classification , regression에서 중요
        <ul>
          <li>단 Nominal data다루는 DT에서는 불필요</li>
          <li>similiarity와 반비례</li>
        </ul>
      </li>
      <li>
        <table>
          <tbody>
            <tr>
              <td>Euclidean distance : $\sqrt{\Sigma_{d=1}^{D}</td>
              <td>x_{td} - x_{nd}</td>
              <td>^2}$</td>
            </tr>
          </tbody>
        </table>
      </li>
      <li>
        <table>
          <tbody>
            <tr>
              <td>Manhattan distance : ${\Sigma_{d=1}^{D}</td>
              <td>x_{td} - x_{nd}</td>
              <td>}$</td>
            </tr>
          </tbody>
        </table>
      </li>
      <li>
        <table>
          <tbody>
            <tr>
              <td>$L^n$-norm : $\sqrt{\Sigma_{d=1}^{D}</td>
              <td>x_{td} - x_{nd}</td>
              <td>^n}$</td>
            </tr>
          </tbody>
        </table>
      </li>
      <li>When we say ‘nearest’, it depends on the distance metric :
        <ul>
          <li>
            <table>
              <tbody>
                <tr>
                  <td>Euclidean distance : $\sqrt{\Sigma_{d=1}^{D}</td>
                  <td>x_{td} - x_{nd}</td>
                  <td>^2}$</td>
                </tr>
              </tbody>
            </table>
          </li>
          <li>
            <table>
              <tbody>
                <tr>
                  <td>Manhattan distance : ${\Sigma_{d=1}^{D}</td>
                  <td>x_{td} - x_{nd}</td>
                  <td>}$</td>
                </tr>
              </tbody>
            </table>
          </li>
          <li>
            <table>
              <tbody>
                <tr>
                  <td>$L^n$-norm : $\sqrt{\Sigma_{d=1}^{D}</td>
                  <td>x_{td} - x_{nd}</td>
                  <td>^n}$</td>
                </tr>
              </tbody>
            </table>
          </li>
        </ul>
      </li>
      <li>Each dimension can be differently <strong>scaled</strong>
        <ul>
          <li>Each dimension may have different impact</li>
          <li>
            <table>
              <tbody>
                <tr>
                  <td>May <strong>bias</strong> the performance of the classifier $\sqrt{\Sigma_{d=1}^{D} w_d</td>
                  <td>x_{td} - x_{nd}</td>
                  <td>^2}$</td>
                </tr>
              </tbody>
            </table>
            <ul>
              <li>동일한 기준 측정 X → performance bias 발생 가능</li>
              <li>weight를 특정 feature에 넣어 거리의 상대적인 크기를 feature에 따라서 넣는다</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>VDM</strong></p>

    <p>provide d measurements for nominal attributes</p>
  </li>
  <li><strong>Problem from Euclidean distance</strong>
    <ol>
      <li>High dim data - curse of dimensionality
        <ul>
          <li>너무 많이 feature, attrib 증가시킬 경우 dim이 너무 많이 증가해 차원의저주</li>
          <li>sample로부터 available info 가 많고 정확하다면 dim 높아도 괜찮음</li>
        </ul>
      </li>
      <li>보통 sparse하고 density를 shrink하여 적용한다.</li>
      <li>과연 d가 동일하다고 data feature를 잘 나타낼까?
        <ul>
          <li>MSB, LSB 등 bit 연산으로부터 잘 표현이 안될수도 있음</li>
          <li>Hamming d.</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>
    <p><strong>Behavior of limit</strong></p>

    <p>$\lim _{n \rightarrow \infty} \leq 2 \epsilon ^*$</p>

    <p>pf) goodnote 참고</p>
  </li>
  <li>
    <p><strong>Standardization</strong></p>

    <p>z = x - mu / sigma</p>
  </li>
  <li><strong>how to choose k</strong>
    <ul>
      <li>k is too small → sensitive to noise points</li>
      <li>k is too big → neighborhood may include pts from other classes
        <ul>
          <li>smoother when k get bigger</li>
        </ul>
      </li>
      <li>보통 $k = \sqrt N$</li>
      <li>$n \rightarrow \infty$, k gets larger → good performance as good as bayes classifier</li>
    </ul>
  </li>
  <li><strong>Cross Validation !!!</strong>
    <ul>
      <li>N fold cross validation → k to minimize cross valid error</li>
    </ul>

    <p>overfitting에 의해 - train error를 줄이는 것이 무작정 좋지는 않다</p>
  </li>
  <li><strong>Condensing!!!</strong>
    <ul>
      <li>[Aim] reduce the number of training samples</li>
      <li>Decision boundary consistent : same with entire training set
        <ul>
          <li>min. consistent set : smallest subset of samples</li>
        </ul>
      </li>
    </ul>

    <p>1) init subset with single ex. 
  → 2) nearest neighbor 생성, epsilon나오는 incorrected samples 선택 
  → 3) 2)반복 Until no transfers or subset is full → result 구하기</p>
  </li>
  <li><strong>Voronoi Diagram</strong>
    <ul>
      <li>Voronoi Diagram : div space into such cells : 구획으로 나누고 boundary 영향없는 sample del</li>
      <li>Delaunary triagulation 생성 → circumcircle center pt 끼리 연결 : 
  각 sample pt class에 따라 전체 영역 Class 결정
        <ul>
          <li>Delaunary triagulation : 삼각형의 세 점에 외접하는 삼각형, 각도 최대화</li>
          <li>not unique</li>
        </ul>
      </li>
      <li></li>
    </ul>
  </li>
</ul>

<h1 id="8-ann"><strong>8. ANN</strong></h1>

<p><a href="https://www.notion.so/8-ANN-2866fb8a17b645a1af86f8a713f28c3d">8. ANN</a></p>

<ul>
  <li><strong>Differences with</strong>
    <ul>
      <li>Similar : SVM처럼 high dimension mapping과 유사한 input layer to hidden layer
        <ul>
          <li>원래 feature space에서는 not linearly separable → phi fn(high dim) 으로 sol</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Bitwise Calc.</strong></p>

    <p>perceptron : AND, OR연산 가능하나 XOR 불가능</p>

    <ul>
      <li>sol: XOR이 nonlinear해서 생긴 문제 : 2 Decision boundary</li>
    </ul>
  </li>
  <li><strong>ANN Training</strong>
    <ul>
      <li>input - hidden - output : hidden layer 수에 따라 네트워크 구조가 좌우되며 linearly nonsolvable 문제도 해결해낼 수 있다</li>
      <li>1) decide input /output / hidden layer node number 
  → 2) find weight using training alg (backpropagation)</li>
      <li>#class = #node</li>
    </ul>
  </li>
  <li><strong>Backpropagation</strong>
    <ul>
      <li>(등장배경) NN-SVM-DNN에서 SVM이 많이 쓰이는 경우였음. NN에서 overfitting / XOR문제</li>
      <li>(Idea) Weight w를 Error 감소하는 방향으로 Update - between prediction vs ground truth val</li>
      <li>(prob. similar to perceptron) stuck in local minima, iteratively get w, many w to get y</li>
      <li>chain rule</li>
    </ul>
  </li>
  <li>
    <p><strong>Vanishing Gradient Problem</strong></p>

    <p>error들이 backpropagate하면 gradient가 vanish하는 현상 : layer에서 소수점이 곱해질수록 0으로 수렴하기 때문이다. w = w - eta dE/du</p>

    <ul>
      <li>sol : requires lots of data</li>
      <li>nonlinear ReLU</li>
      <li>Layerwise learning : 충분히 학습되면 넘어감</li>
    </ul>
  </li>
  <li><strong>Overfitting</strong>
    <ul>
      <li>Only get good result for train data only</li>
    </ul>

    <p>get stuck in local minima</p>

    <ul>
      <li>solution : randomly set initial val +many data + much computation power→ train many times → avg 추출</li>
    </ul>

    <p>good model check</p>

    <ul>
      <li>solution : train data, test data 변화시키며 stable result를 보이는지 확인한다</li>
    </ul>
  </li>
</ul>

<h1 id="9-dnn">9. DNN</h1>

<p><a href="https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985">9. DNN</a></p>

<ul>
  <li><strong>Why is better than traditional ML</strong>
    <ul>
      <li>SVM) Manual, Human supervised, div and conquer
        <ul>
          <li>기존에 human이 feature extraction한 후 classification함.</li>
          <li>SVM에서는 Hand-crafted phi fn을 활용해서 alg에서 Pattern이 더 잘 보이도록 수정했다</li>
        </ul>
      </li>
      <li>DL) Automatical, end-to-end NN
        <ul>
          <li>end-to-end joint system : NN이라는 hierarchical structure로 feature extract + classification 과정 수행
            <ul>
              <li>→ data를 지속적으로 분류 : 자체적으로 자동적으로 배우고 지능적인 결정 수행</li>
            </ul>
          </li>
          <li>modularization : automatically learned from data (each classes)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>DNN consist</strong>
    <ul>
      <li>input layer + multiple hidden l + output layer</li>
    </ul>
  </li>
  <li>
    <p><strong>(CNN) Layers : FC Layer, Locally connected layer</strong></p>

    <p>corelation 구하는 작업 → 조합을 다음 layer로 전달한다.</p>

    <ul>
      <li>FC : globally corelated - rsrc waste, too much calc., not enough data to train pm</li>
      <li>LC : 일정 convolution내 node (different locations-convolutions with learned kernel)
        <ul>
          <li>convolution : 특정 Window size filter</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>(CNN) Conv. operations</strong>
    <ul>
      <li>Conv A * B = B * A</li>
      <li>cross-corelation : A . B ≠ B . A</li>
      <li>auto-correlation : 자기 자신과 동일</li>
    </ul>
  </li>
  <li>
    <p><strong>(CNN) Pooling</strong></p>

    <p>filter responses at different location → robustnest to spatial location of filters</p>

    <ul>
      <li>max, avg, l2 pooling</li>
    </ul>
  </li>
  <li>
    <p><strong>(CNN) size of feature map 계산</strong></p>
  </li>
  <li><strong>tasks</strong>
    <ul>
      <li>Classification : exact class 분류</li>
      <li>Localization : obj 주변에 box를 두고 정답과 적어도 50%이상 겹쳐야 함</li>
      <li>Obj Detection : n개의 obj에 모두 boundary box 처리</li>
    </ul>
  </li>
  <li><strong>Alexnet</strong>
    <ul>
      <li>act. fn. : ReLU in Hidden layers → faster, expressive than sigmoid</li>
      <li>ten different 224<em>224 patches from from 256</em>256 img</li>
      <li>dropout to reg. weight in FC layers</li>
      <li>padding</li>
    </ul>
  </li>
  <li>
    <p><strong>FC Layer</strong></p>

    <p>has no constrains the input img size (상관 없음)</p>
  </li>
  <li>
    <p><strong>DNN Evolution</strong></p>

    <p>NN - Perceptron - Backporpagatino ,RNN, RBM - CNN, MNIST, LSTM, BRNN - DBN - GAN - AlphaGo</p>

    <ul>
      <li>data labeled</li>
      <li>obj detection focused</li>
      <li>GPU
        <ul>
          <li>good for mat*mat multiplies + high bandwidth</li>
        </ul>
      </li>
      <li>shallower</li>
    </ul>
  </li>
  <li><strong>Backgrounds</strong>
    <ul>
      <li>HW (GPU) + Data (Big data) + Alg (learning Alg)</li>
      <li>limit : cannot do commonsense reasoning - 상식, 윤리의 Lack</li>
    </ul>
  </li>
</ul>

<h1 id="10-dnn2">10. DNN2</h1>

<p><a href="https://www.notion.so/10-DNN-2-c5c97bb69d724e25bb655b70f34d2575">10. DNN 2</a></p>

<ul>
  <li>
    <p><strong>Data Processing</strong></p>

    <p>In practice, you may also see PCA and Whitening of the data</p>

    <p>PCA : dimensionality reduction, clustering (unsupervised)</p>

    <ul>
      <li>decorrelated data
        <ul>
          <li>(data has diagonal covariance matrix)</li>
          <li>axis방향으로 평행 : with x1 only (1dim)</li>
          <li>from 2dim → 1dim compression (data info loss)</li>
        </ul>
      </li>
      <li>whitened data
        <ul>
          <li>
            <p>(covariance matrix is the identity matrix)</p>

            <p>$\Sigma =$</p>
          </li>
          <li>
            <p>acc 변화했을 수도 있으므로 performance 체크</p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Weight Init.</strong></p>

    <p>“Xavier initialization” [Glorot et al., 2010]</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">fanin</span><span class="p">,</span> <span class="n">fanout</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fanin</span><span class="p">)</span>
</code></pre></div>    </div>

    <ul>
      <li>Reasonable initialization. (Mathematical derivation assumes linear activations) with tanh fn</li>
      <li>현재 layer node의 sqrt로 init</li>
      <li>but when using the ReLU nonlinearity it breaks. (0에 접근)</li>
    </ul>

    <p>He et al., 2015 (note additional /2)</p>

    <ul>
      <li>error가 더 잘 감소됨을 확인할 수 있음</li>
    </ul>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">fanin</span><span class="p">,</span> <span class="n">fanout</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fanin</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Batch Normalization</strong></p>

    <ul>
      <li>To make each dimension unit gaussian, apply:
        <ul>
          <li>$\hat x^{(k)} = \frac{x^{(k)} - E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}$
            <ul>
              <li>this is a vanilla differentiable function…</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>dimension 단위 normalilze</li>
    </ul>

    <ol>
      <li>
        <p>compute the empirical mean and variance independently for each dimension.</p>

        <p><img src="Final/10/Untitled.png" alt="Untitled" /></p>
      </li>
      <li>
        <p>Normalize</p>
        <ul>
          <li>$\hat x^{(k)} = \frac{x^{(k)} - E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}$
        - Usually inserted after Fully Connected or Convolutional layers, and before <strong>nonlinearity.</strong></li>
        </ul>
      </li>
    </ol>

    <p><img src="Final/10/Untitled_1.png" alt="Untitled" /></p>

    <ul>
      <li>Normalize:
        <ul>
          <li>$\hat x^{(k)} = \frac{x^{(k)} - E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}$</li>
          <li>$\hat x \sqrt{Var} + E[x] = X$</li>
          <li>$\gamma = \sqrt{Var} , \beta = E[x]$</li>
          <li>$\hat x$ : normalized data, X : original data</li>
        </ul>
      </li>
      <li>And then allow the network to squash the range if it wants to:
        <ul>
          <li>$\hat y^{(k)} = \gamma^{(k)} \hat x^{(k)}+\beta^{(k)}$</li>
        </ul>
      </li>
      <li>Note, the network can learn:to recover the identity mapping.
        <ul>
          <li>$\gamma^{(k)} = \sqrt{Var[x^{(k)}]}$ (stretch)</li>
          <li>$\beta^{(k)} = E[x^{(k)}]$ (이동)</li>
        </ul>
      </li>
      <li>$X \rightarrow \hat X$ : normalize : $\gamma, \beta$로 scaling된 y value</li>
    </ul>
  </li>
  <li>
    <p><strong>Regularization</strong></p>

\[L = \frac 1 N \Sigma_{i=1}^{N} \Sigma_{j\neq y_i}{\max(0, f(x_i);W)_j - f(x_i);W)_{y_i} +1} + \lambda R(W)\]

    <ul>
      <li>Loss Fn : $\frac 1 N \Sigma_{i=1}^{N} \Sigma_{j\neq y_i}{\max(0, f(x_i);W)<em>j - f(x_i);W)</em>{y_i} +1}$</li>
      <li>Lambda weight term $+ \lambda R(W)$</li>
    </ul>

    <p><img src="Final/10/Untitled_2.png" alt="Untitled" /></p>

    <ul>
      <li>
        <p>In common use:</p>

        <p><img src="Final/10/Untitled_3.png" alt="Untitled" /></p>
      </li>
    </ul>
  </li>
  <li><strong>Dropout</strong>
    <ul>
      <li>(배경) deep NN 일수록 특정 node가 학습 시 dropped case 발생</li>
      <li>(train) assume dropout rate p → (test) no dropout</li>
    </ul>
  </li>
  <li>
    <p><strong>regularization common pattern</strong></p>

    <ul>
      <li>Cross Entropy Loss : $-\Sigma y_i \lim P_i$
        <ul>
          <li>yi : the answer</li>
          <li>Pi : prediction</li>
        </ul>
      </li>
      <li>Training: Add some kind of randomness
        <ul>
          <li>randomness - regularize</li>
          <li>$y = f_W (x,z)$</li>
        </ul>
      </li>
      <li>Testing: Average out randomness (sometimes approximate)
        <ul>
          <li>$y = f(x) = E_z[f(x,z)] = \int p(z)f(x,z)dz$</li>
          <li>iteration별 여러 mu, sigma → average를 구하여 test시점에 적용한다</li>
          <li>BN도 regularization작업</li>
        </ul>
      </li>
      <li>Example:BatchNormalization
        <ul>
          <li>Training:Normalize using stats from random mini batches</li>
          <li>Testing:Use fixed stats to normalize</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="11-ensemble-learning">11. Ensemble learning</h1>

<p><a href="https://www.notion.so/11-Ensemble-Learning-afd95182fd9c4803b961642026442403">11. <strong>Ensemble Learning</strong></a></p>

<ul>
  <li>Ensemble Learning
    <ol>
      <li></li>
    </ol>
  </li>
  <li>
    <p>Generate Ensembles</p>

    <ul>
      <li>
        <p>Data Manipulation</p>

        <ol>
          <li>Train set에 변화</li>
        </ol>

        <p>Supervised learning에서 train set에 대해 train 되어 얻어진 model</p>

        <ul>
          <li>다른 train set을 사용하면 -&gt; 다른 model : 분류 성능이 다름</li>
          <li>it changes the training set in order to obtain different models</li>
        </ul>
      </li>
      <li>
        <p>Modeling process manipulation</p>

        <ol>
          <li>algorihtm에 변화</li>
        </ol>

        <ul>
          <li>model process manipulation : algorithm의 변화</li>
          <li>parameter만 변화하는 경우도 있고, classifier 자체를 변경할수도 있음, algorithm 자체를 변화시킬수도 있고</li>
          <li>→ 다양한 model (f1 _ /// fk)</li>
          <li>it changes the induction algorithm, the parameter set or the model in order to obtain different models</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Ensemble learning via negative correlation learning:</strong>
    <ul>
      <li>Generating sequentially new predictors <strong>negatively correlated</strong> with the existing ones
        <ul>
          <li>현재 classifier하고 negative corelation갖는 classifier를 학습하여 융합한다</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Bagging
    <ul>
      <li>
        <p>Averaging the prediction over a collection of predictors generated from <strong>bootstrap samples</strong> (both classification and regression)</p>

        <p>bootstrap sample :trian data있으면 subset sampling</p>

        <ul>
          <li>
            <p>각각 sampling으로부터 classifier 학습</p>

            <p>Random하게 sampling하며 다양한 model</p>
          </li>
        </ul>
      </li>
      <li>
        <p>Training</p>
        <ul>
          <li>Given a set D of d tuples, at each iteration i, a training set $D_i$ of $d$ tuples is sampled with replacement from D (i.e. bootstrap)
            <ul>
              <li>bootstrap 방법 : sampling with replacement - 전체 dataset으로부터 sampling하여 modeling하고 다시 복원</li>
              <li>각각의 data subset에 대하여 model을 만듬</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>

    <p>average, Sum 은 같은 방식 : sum에서 classifier number만큼 나눠주면 average value</p>

    <ul>
      <li>bootstrapping = original data로부터 sampling</li>
      <li>aggregating = 그것들로부터 각각의 classifier를 만들어 병합하는 방법</li>
      <li>Classification: classify an unknown sample X
        <ul>
          <li>Each classifier $M_i$ returns its class prediction</li>
          <li>The bagged classifier $M^*$ counts the votes and assigns the class with the most votes to X
            <ul>
              <li>각 classifier가 sample에 대한 class 예측값을 계산하고, 그리고 최종 판단은 voting / sum/ 등 여러 방법을 사용할 수 있다.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Prediction:
        <ul>
          <li>can be applied to the prediction of continuous values by taking the average value of each prediction for a given test tuple</li>
        </ul>
      </li>
      <li>Accuracy
        <ul>
          <li>
            <p>Often significantly better than a single classifier derived from</p>

            <p>significantly better : 5 ~ 10% 상승</p>

            <ul>
              <li>물론 model을 여러번 쓰고 연산량은 그만큼 증가</li>
              <li>test stage : Test sample에서는 model들 다 유지해서 그만큼 분류 작업 수행 후 융합</li>
            </ul>

            <p>Train + test stage 연산량 증가</p>
          </li>
          <li>For noisy data: not considerably worse, more robust
            <ul>
              <li>noisy data : robust하게 됨 (boost sampling : Noisy data가 빠진 형태로 학습)</li>
            </ul>
          </li>
          <li>Proved improved accuracy in prediction</li>
        </ul>
      </li>
      <li>Requirement: need unstable classifier types
        <ul>
          <li>Unstablemeansasmallchangetothetrainingdatamayleadtomajor decision changes</li>
          <li>requirement : unstable classifier</li>
        </ul>

        <p>Unstable : train data를 조금 바꿀 경우 model decision이 크게 바뀌는 model을 의미함</p>

        <p>(Remind) Model이 바뀐 train data에 대해서 diverse한 error = variance가 커야 한다.</p>

        <ul>
          <li>bagging의 관점에서는 var 큰게 좋다 (일반적으로는 별로 안 좋다)</li>
        </ul>
      </li>
      <li>Stability in Training
        <ul>
          <li>Training: construct classifier from</li>
          <li>
            <p>Stability: small changes on results in small changes on</p>

            <p>Training : f를 d로부터 형성</p>
          </li>
          <li>Decision trees are a typical unstable classifier</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Boosting
    <ul>
      <li>
        <p>Weighted vote with a collection of classifiers that were trained sequentially from training sets given priority to instances <strong>wrongly classified</strong></p>

        <p>Boosting : 여러 단계를 거쳐 classifier 학습</p>

        <ul>
          <li>이전 단계의 classifier의 오답에 초점을 맞춘다.</li>
        </ul>

        <p>오류가 나오는 data들을 모아 다음 stage에서 초점을 맞추어 학습하여 융합한다</p>
      </li>
      <li>Incrementally create models selectively using training examples based on some distribution.
        <ul>
          <li>Incrementally하게 sample이 subset으로 selection된 확률값을 가지고 있음</li>
        </ul>
      </li>
      <li>How boosting works?
        <ul>
          <li>Weights are assigned to each training example</li>
          <li>A series of k classifiers is iteratively learned</li>
          <li>After a classifier $M_i$  is learned, the weights are updated to allow the subsequent classifier, $M_i +1$, to pay more attention to the training examples that were misclassified by</li>
          <li>The final $M^*$ combines the votes of each individual classifier, where the weight of each classifier’s vote is a function of its accuracy 𝒊</li>
        </ul>
      </li>
      <li>각 sample들이 weight를 가지고 있음.</li>
    </ul>

    <p>그리고 우리는 k개의 classifier를 학습할 것</p>

    <p>그런데 M_i가 학습 된 다음, classifier가 학습된 이후에는</p>

    <p>weight을 update하는데 앞 단계에서 학습된 model들이 misclassified 에 더 주의를 기울인다 (weight를 올린다)</p>

    <ul>
      <li>
        <blockquote>
          <p>higher chance to be selected</p>
        </blockquote>
      </li>
    </ul>

    <p>즉 misclassified sample들이 점점 그 쪽으로 select되면서 hard sample들이 점점 추가되어 뒤쪽 classifier 학습</p>

    <p>1~k개 classifier를 조합하여 m*</p>

    <ul>
      <li>weighted combination : weight는 accuracy에 비례</li>
      <li>boosting 기본 아이디어 : disagreement, hard sample</li>
    </ul>

    <p>Hard sample에 초점 맞추는 방법 : classifier 1번을 만들고 misclassified에 대해서 classifier 2번을 만들고 m1, m2가 다른 결정을 내리는 sample에 대해서 classifier 3번을 만들어 test sample이 들어오면 m1, m2를 돌려 최종 결과로 사용하고 두 분류기 결과가 다르면 m3를 활용하여 결과 도출</p>
  </li>
  <li>
    <p>Boosting - Adaboost</p>

    <ul>
      <li>Using Different Data Distribution
        <ul>
          <li>Start with uniform weighting</li>
          <li>misclassified sample의 weight 증가</li>
          <li>well classified sample에 대해서는 weight 감소</li>
          <li>During each step of learning
            <ul>
              <li>Increase weights of the examples which are not correctly learned by the weak learner</li>
              <li>Decrease weights of the examples which are correctly learned by the weak learner</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Idea
        <ul>
          <li>Focus on difficult examples which are not correctly classified in the previous steps</li>
          <li>difficult example에 더 주의를 기울인 케이스</li>
        </ul>
      </li>
      <li>Weighted Voting
        <ul>
          <li>Construct strong classifier by weighted voting of the weak classifiers</li>
          <li></li>
          <li>strong classifier 만들 때 weak classifier 에 weight를 주고 weighted voting / weighted sum 등 일반적인 ensemble 방법 적용</li>
          <li>weak classifier를 많이 첨가하여 combined classifier의 accuracy 증가 (strong classifier/learner)</li>
        </ul>
      </li>
      <li>Idea
        <ul>
          <li>Better weak classifier gets a larger weight</li>
          <li>Iteratively add weak classifiers
            <ul>
              <li>Increase accuracy of the combined classifier through minimization of a cost function Ensemble Learning Adaboost Introduction to Machine Learning Page 17</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Adaboost vs Boosting</p>

    <ul>
      <li>Differences with Bagging:bagging과의 차이점
        <ul>
          <li>Models are built sequentially on modified versions of the data
            <ul>
              <li>random하게 sample된게 아니라 weight에 의해 sample된 data에 의해 학습</li>
            </ul>
          </li>
          <li>The predictions of the models are combined through a weighted sum/vote
            <ul>
              <li>점점 hard sample에 대해 학습되니 easy sample / hard sample의 classifier가 동일한 weight를 가질 수 없음 : bagging은 동일한 조건으로 randomly sampling (no weight)
                <ul>
                  <li>거의 동등한 조건이기 때문에 weight를 주지 않음</li>
                  <li>boosting의 경우 misclassified에 대해 overfitting (hard sample이 증가하는 방향으로 weight update)-&gt; ensemble하면 점점 hard sample 추가되며 overfitting 위험</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Random Forest</p>

    <p>RandomForest:</p>

    <ul>
      <li>Averaging the prediction over a collection of trees constructed using a <strong>randomly selected subset of features</strong>
        <ul>
          <li>tree를 randomly생성하여 randomly select해서 만든다.</li>
        </ul>
      </li>
      <li>Random Forest: A variation of the bagging algorithm - bagging처럼 여러 개 ensemble</li>
      <li>Created from individual decision trees
        <ul>
          <li>Diversity is guaranteed by selecting randomly at each split, a subset of the original features during the process of tree generation</li>
          <li><strong>tree 구조 : unstable 구조 → diversity가 guaranteed됨 automatically</strong></li>
        </ul>
      </li>
      <li>R.F 활용
        <ul>
          <li>During classification, each tree votes and the most popular class is returned
            <ul>
              <li>classification에서는 : vote를 가장 많이 받은 class가 최종 결과 decision</li>
            </ul>
          </li>
          <li>During regression, the result is the averaged prediction of all generated trees
            <ul>
              <li>regression에서는 :각 tree들이 result을 만드는데 이를 average 취하면 random forest result</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>random selection이 : feature selection / data sampling</li>
    </ul>
  </li>
  <li>Heterogeneous ensembles:
    <ul>
      <li>Combining a set of <strong>heterogeneous predictors</strong>
        <ul>
          <li>NN + SVM + DT 등 융합</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Model Selection</p>

    <ul>
      <li>Golden rule: there is no algorithm that is the best one for all the problems
        <ul>
          <li>하나의 특정 알고리즘이 다른 모든 problem 모두를 해결하지는 않는다</li>
        </ul>
      </li>
      <li>Typically, two approaches (or both) can be adopted:
        <ul>
          <li>To choose the algorithm more suitable for the given problem</li>
          <li>To adapt the given data for the intended algorithm (using pre-processing, for instance)
            <ul>
              <li>주어진 data를 잘 tuning할 수 있도록 한다 for 사용하고자 하는 algorithm (preprocessing)</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>The concept of “good algorithm” depends on the problem:
        <ul>
          <li>good algorithm : prob by prob</li>
          <li>Explainability : model이 어떤 판단을 내린다면 판단의 정확도도 중요하나 그 결정의 이유도 중요함 : bayesian, decision tree는 쉽게 설명할 수 있는데 그 외에는 설명이 쉽지 않음</li>
          <li>분류 관리 문제에 있어서는 이송 시간 예측 정확도가 가장 중요한 선택요인</li>
          <li>For a doctor, the interpretation of the model can be a major criterion for the selection of the model (decision trees and Bayesian networks are very appreciated)</li>
          <li>For logistics, the accuracy of travel time prediction is, typically, the most important selection criterion.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Statistical Validation</li>
</ul>

<h1 id="12-clustering">12. Clustering</h1>

<p><a href="https://www.notion.so/12-Clustering-68dc57c409b94b27afd366a66f7d672c">12. Clustering</a></p>

<ul>
  <li>
    <p><strong>K-means clustering</strong></p>

    <p>An iterative clustering algorithm</p>

    <ul>
      <li>
        <p>Initialize: Pick K random points as cluster centers</p>

        <ol>
          <li>cluster의 개수 가정 : k개의 cluster = k개의 random point 초깃값 assume</li>
        </ol>
      </li>
      <li>Alternate:
        <ol>
          <li>
            <p>Assign data points to closest cluster center</p>

            <ol>
              <li>k개의 pt에 대해서 각각의 data들을 가장 가까운 cluster center에 할당하고</li>
            </ol>
          </li>
          <li>
            <p>Change the cluster center to the average of its assigned points</p>

            <ol>
              <li>Cluster center update : 각 iteration마다 update</li>
            </ol>

            <ul>
              <li>더 이상 update되지 않는 시점에서 cluster 중단</li>
            </ul>
          </li>
        </ol>
      </li>
      <li>
        <p>Stop when no point assignments change</p>

        <p>초깃값에 대해서 (initial center point) partition 나눔</p>

        <ul>
          <li>그 data들의 center mean을 구해서 이로 center를 update함</li>
          <li>이를 기반으로 update된 값들의 member들을 재할당</li>
          <li>반복하다 보면 각각의 cluster의 center로 이동하게 됨</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>K-means clustering properties</strong></p>

    <p>## Properties of K-means algorithm (convergence)</p>

    <ul>
      <li>
        <p>Objective</p>

        <p>모든 sample들에 대해서 center값을 계산 :sample들의 center 값으로부터의 거리 제곱의 합이
  k개의 cluster에 대해서 최소</p>

        <ul>
          <li>cluster center에 잘 일치하게 되면, 해당 cluster에 속하는 sample들이 그 cluster center 와 이루는 거리의 합이 모든 cluster에 대해서 minimum이 됨</li>
        </ul>

\[\min_{\mu} \min_{c}  \Sigma_{i=1}^{k} {\Sigma_{x\in C_i}|x-\mu_i|^2}\]
      </li>
      <li>
        <p>Fix $\mu$, optimize $C$</p>

        <p>iteration작업- partition update</p>

        <ul>
          <li>mu 고정, C optimize</li>
          <li>center까지의 모든 sample들의 거리를 최소화하는 작업</li>
        </ul>

\[\min_{c}  \Sigma_{i=1}^{k} {\Sigma_{x\in C_i}|x-\mu_i|^2} = \min_{c}  \Sigma_{i=1}^{n} {|x_i-\mu_{xi}|^2}\]
      </li>
      <li>
        <p>Fix $\mu$, optimize $\mu$</p>

        <p>Partition update후 center값 update</p>

        <ul>
          <li>각 cluster sample들에서 sample들로부터 center 거리를 최소화시킬 수 있도록 평균값 설정</li>
          <li>mu에 대해서 미분하고ㅡ 이를 0으로 setting하면 평균값이라는 것은 각 cluster에 속한 sample들의 값의 합을 그 cluster에 속한 sample들의 값의 합을 그 cluster에 속한 sample들의 개수로 나눈 값이 그 center 값 : center mean</li>
        </ul>

\[\min_{\mu} \Sigma_{i=1}^{k} {\Sigma_{x\in C_i}|x-\mu_i|^2}\]

        <ul>
          <li>Take partial derivative with respect to $\mu_i$and sets to zero, we have $\mu_i = \frac 1 {C_i} \Sigma_{x\in C_i} x$</li>
        </ul>
      </li>
      <li>
        <p>K-means takes an alternating optimization, each step is guaranteed to decrease the objective – thus guaranteed to converge</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Agglomerative clustering</strong></p>

    <ul>
      <li>Agglomerative clustering
        <ul>
          <li>First merge very similar instances
            <ul>
              <li>비슷한 data끼리 grouping : 처음에는 모든 data pt가 개별 cluster로 되고 점차 하나의 group이 될 때까지 group화</li>
            </ul>
          </li>
          <li>Incrementally build larger clusters out of smaller clusters
            <ul>
              <li>가장 similarity가 큰 data끼리 group화함 :
                <ul>
                  <li>1,3을 하나의 group으로 묶고 2, 5 group으로 묶이게 되면 1st-2nd group간 거리는 가장 가까운 거리로 할 것인지 (1-2) 먼 거리로 할 것인지 (3-5) 평균으로 할 것인지에 따라, similarity 판단 기준에 따라 clustering이 다르게 됨</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Algorithm:
        <ul>
          <li>Maintain a set of clusters, Initially, each instance in its own cluster</li>
          <li>Repeat:
            <ul>
              <li>Pick the two closest clusters</li>
              <li>Merge them into a new cluster</li>
              <li>Stop when there’s only one cluster left</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Produces not one cluster, but a family of clusters represented by a dendrogram</li>
    </ul>

    <p><img src="Final/12/Untitled.png" alt="Untitled" /></p>

    <ul>
      <li>How should we define “close” for clusters with multiple elements?
        <ul>
          <li>similarity를 어떻게 판단할 것인가  =(distance를 어떻게 계산할 것인가)</li>
          <li>
            <p>closest / Farthest / Average → cluster가 달라지게 됨</p>

            <p><img src="Final/12/Untitled_1.png" alt="Untitled" /></p>
          </li>
        </ul>
      </li>
      <li>Many options:
        <ul>
          <li>Closest pair (single-link clustering)</li>
          <li>Farthest pair (complete-link clustering)</li>
          <li>Average of all pairs</li>
        </ul>
      </li>
      <li>Different choices create different clustering behaviors</li>
    </ul>
  </li>
  <li>
    <p><strong>Agglomerative clustering - hierarchical clustering : strength, complexity</strong></p>

    <p>## Strengths of Hierarchical Clustering</p>

    <ul>
      <li>No assumptions on the number of clusters
        <ul>
          <li>cluster 개수 가정하고 수행하게 됨</li>
          <li>단) cluster 개수 잘못 예측하면 algorithm 좋지 않은 결과를 낼 것</li>
          <li>Any desired number of clusters can be obtained by ‘cutting’ the dendogram at the proper level</li>
        </ul>
      </li>
      <li>Hierarchical clusterings may correspond to meaningful taxonomies
        <ul>
          <li>cluster 몇 개인지 모르는 상태에서 clustering</li>
          <li>clustering : dendrogram 그려서 duration 긴 구간을 판단하여 cluster 개수 결정 / 적절한 상태에서 dendrogram cutting</li>
          <li>대칭적 분류 : phylogeny. Catalog</li>
          <li>Example in biological sciences (e.g., phylogeny reconstruction, etc), web (e.g., product catalogs), etc.</li>
        </ul>
      </li>
    </ul>

    <p>## Complexity of hierarchical clustering</p>

    <ul>
      <li>Distance matrix is used for deciding which clusters to merge/split
        <ul>
          <li>distance &lt;-&gt; proximity</li>
        </ul>
      </li>
      <li>data point n개가 있다면, n by n개 distance를 모두 계산함 : n^2 연산
        <ul>
          <li>At least quadratic in the number of data points
            <ul>
              <li>Not usable for large datasets</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>

    <p>group화가 진행되며 Matrix 크기가 점차 줄어들게 되어 최종적으로 하나의 block만 남게 됨</p>
  </li>
  <li>
    <p><strong>Closest pair (single-link clustering)</strong></p>

    <ul>
      <li>Each cluster is a set of points</li>
      <li>How do we define distance between two sets of points</li>
      <li>Lots of alternatives</li>
      <li>
        <p>Not an easy task</p>
      </li>
      <li>Single-link distance between clusters Ci and Cj is the minimum distance between any object in Ci and any object in Cj
        <ul>
          <li>Single link : shortest distance</li>
        </ul>
      </li>
      <li>
        <p>The distance is defined by the two most similar objects</p>

\[D _{s l} ( C _i , C _j ) = \min _{x , y} (d ( x , y )| x \in C _i , y \in C _j )\]
      </li>
    </ul>

    <p># Single-link clustering: example</p>

    <ul>
      <li>
        <p>Determined by one pair of points, i.e., by one link in the proximity graph</p>

        <p>Diagonal value를 보고 판단할 수 있음</p>

        <p>같은 요소에 대한 값이 1-&gt; similarity</p>

        <ul>
          <li>data 분포에 의하면 1,2,3,4,5 clustering</li>
          <li>symmetric : 대각선 아래 부분은 크게 의미가 없음</li>
          <li>값이 높은 순대로 먼저 cluster를 형성하게 됨</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Farthest pair (complete-link clustering)</strong></p>

    <p>## Distance between two clusters</p>

    <ul>
      <li>Complete-link distance between clusters Ci and Cj is the maximum distance between any object in Ci and any object in Cj</li>
      <li>
        <p>The distance is defined by the two most dissimilar objects</p>

        <p>가장 먼 거리의 simple pair에 대해서 data를 clustering (Most dissimilar)</p>

        <p>Most similar</p>
      </li>
    </ul>

\[D _{s l} ( C _i , C _j ) = \max _{x , y} (d ( x , y )| x \in C _i , y \in C _j )\]

    <p>## Complete-link clustering: example</p>

    <ul>
      <li>
        <p>Distance between clusters is determined by the two most distant points in the different clusters</p>

        <p>거리 판단한 이후(차이-dissimilar)
  cluster끼리 병합할 때는 가장 가까운 것 끼리 (동일)</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Average of all pairs</strong></p>

    <p># Distance between two clusters</p>

    <ul>
      <li>Group average distance between clusters Ci and Cj is the average distance between any object in Ci and any object in Cj
        <ul>
          <li>전체 data pair의 average 이용</li>
          <li>I cluster , j cluster : 평균 distance 계산한 후 shortest path 결정</li>
        </ul>
      </li>
    </ul>

\[D_{avg} (C_i, C_j) = \frac 1 {|C_i| \times |C_j| } \Sigma_{x\in C_i, y \in C_j} d(x,y)\]
  </li>
  <li>
    <p><strong>statistical validation</strong></p>
  </li>
</ul>

<h1 id="13-dimensionality-reduction">13. Dimensionality Reduction</h1>

<p><a href="https://www.notion.so/13-Dimensionality-Reduction-c21c309ea0724478ba6924d6ce913f81">13. Dimensionality Reduction </a></p>

<ul>
  <li>
    <p><strong>Goal of Dimensionality Reduction</strong></p>

    <p>Visualization 용이 : 3dim 이하로 Reduct → visualize easy</p>

    <p>Performance 향상 : easy to handle data</p>

    <p>Computation cost 감소</p>
  </li>
  <li>
    <p><strong>Data Compression</strong></p>

    <p>(필요성) Too high dimension of detection windows : computationally intensive</p>

    <ul>
      <li>Cannot handle them : too high dimensionality → pixel diminish시켜 사용</li>
      <li>Curse of dimensionality : 너무 Data dimension이 높아지면 accuracy가 떨어지는 현상
        <ul>
          <li>boolean이 아닌 Observed value (measured) : boolean이 아니라 acc 떨어질 수 있음</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Feature Extraction</strong></p>

    <p>(과정) very high-dim raw data → feature extraction dimension reduction → classifier</p>
  </li>
  <li>
    <p><strong>dimension reduction</strong></p>

    <p>axis에 projection한 형태로 reduct dimension</p>
  </li>
  <li><strong>왜 좌표축을 rotate한 것이라고 표현하는가? (multivariate dataset into new config)</strong>
    <ul>
      <li>simplify data</li>
      <li>easy to look at rel. between variable - patterns of units</li>
    </ul>
  </li>
  <li><strong>PCA process</strong>
    <ul>
      <li>[goal] find k-dim projection  which preserves best variance</li>
    </ul>

    <ol>
      <li>compute mean vector $\mu$ and covariance matrix $\Sigma$ of original data
        <ol>
          <li>D-dim data로부터 Mean, Covariance 구함</li>
          <li>$X = [X1, X2, … , Xn]$</li>
          <li>(mean centered X) $X_{\mu_0} = X-\mu = [X1-\mu, X2-\mu, … , Xn-\mu]$</li>
          <li>$\Sigma = X_{\mu_0} X_{\mu_0} ^T = \frac 1 n  \Sigma (X_i - \mu)(X_i - \mu)^T$</li>
          <li>$S = \Sigma(X_i - \mu)(X_i - \mu)^T$</li>
          <li>$\Sigma v = \lambda v$</li>
        </ol>
      </li>
      <li>Compute eigenvectors and eigenvalues of $\Sigma$</li>
      <li>Select top k eigenvectors
        <ol>
          <li>Top k개 eigenvalue에 대응하눈 eigenvector 구함</li>
        </ol>
      </li>
      <li>Project points onto subspace spanned by them
        <ol>
          <li>$y = A(x-\mu)$</li>
          <li>where y is the new data, x is the original data, and the rows of A are the eigenvectors</li>
        </ol>
      </li>
      <li>When we said the eigenvector as</li>
    </ol>

    <p><img src="Final/13/Untitled.png" alt="Untitled" /></p>

    <p>in the previous lecture, $A$ is $V^T$ (k vectors, $v_1$ … $v_k$)</p>
  </li>
  <li><strong>PCA  - Eigenvalue, vector의 의미?</strong>
    <ul>
      <li><strong>eigenvector :PCA분석을 했을 때 data가 가장 크게 분산된 방향으로 표현하는 방향벡터이고 그 정도를 가리키는 것은 eigenvalue.</strong></li>
      <li>smaller eigenvalue 순 - eigenvector 정렬 → 크게 var되는 방향으로 정렬</li>
      <li>가장 큰 eigenvector로 하여 좌표축을 변환해도 data들이 잘 표현이 됨
        <ul>
          <li>data를 Eigenvector에 Projection : 새로운 좌표값으로 나오게 됨</li>
        </ul>
      </li>
      <li>Covariance matrix :
        <ul>
          <li>d dimension data로부터 d개의 eigenvector</li>
          <li>2차원 data로부터 2개의 eigenvector, eigenvalue</li>
          <li></li>
        </ul>
      </li>
      <li><strong>The eigenvectors of $\Sigma$ define a new coordinate system 
  (새로운 coordinate system으로 적용)</strong>
        <ul>
          <li>Eigenvector with largest eigenvalue captures the <strong>most variation</strong> among data X
            <ul>
              <li><strong>eigenvector :PCA분석을 했을 때 data가 가장 크게 분산된 방향으로 표현하는 방향벡터이고 그 정도를 가리키는 것은 eigenvalue.</strong></li>
            </ul>
          </li>
          <li>Eigenvector with smallest eigenvalue has least variation
            <ul>
              <li>
                <p><strong>가장 작은 eigenvalue에 대응되는 Eigenvector는 분산이 제일 작다.</strong>
  <img src="Final/13/Untitled_1.png" alt="Untitled" /></p>
              </li>
              <li>
                <p>v1이라는 axis로 투영한다면 Data가 가장 잘 분산되는 최적의 방향이다 → 최대 분산 방향으로 압축되면 제일 잘 분산되는 방향으로 data의 차원을 축소시키는 것이기에 원본 Data 정보 잘 반영</p>
              </li>
            </ul>
          </li>
          <li>Dimension reduction에 따른 원본 data의 information loss정도
            <ul>
              <li>1Dim 압축 : 가장 최소 eigenvector, 2Dim 압축 : 두 번째eigenvector</li>
              <li>d dim에 대해서 D개를 모두 사용 → 어떠한 손실도 없이 원본 Data 수행 가능
                <ol>
                  <li>표현된 Data는 동일하지만 PCA 분석이 되어 있기에 Dimension을 줄이면 됨</li>
                  <li>corelation이 감소된 형태로 좌표축 정립 : x1의 값이 변화할 때 x2의 값이 변화되는 정도</li>
                </ol>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>LDA</strong></p>

    <p>LDA : labeled</p>

    <ul>
      <li>PCA는 unsupervised learning에서 clustering, dimensionality reduction
        <ul>
          <li>Not for classification</li>
        </ul>
      </li>
      <li>LDA는 supervised learning, dimensionality reduction
        <ul>
          <li>Classification을 위해 쓸 수 있으나 label 사용해서 unsupervised라고 볼 수는 없음</li>
        </ul>
      </li>
    </ul>

    <p>LDA의 필요성</p>

    <ul>
      <li>PCA maximizes the total scatter → PCA does not consider class information
        <ul>
          <li>PCA 분석 하면 data의 최대 분산 방향으로 eigenvector가 얻어지게 됨</li>
          <li>최대 분산 방향으로 data 투영하게 되면 data label 구분이 없어짐 (섞임)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>PCA vs. LDA</strong></p>

    <ul>
      <li>
        <p>PCA maximizes projected total scatter
  label이 없으니 전체 data에 대해서 covariance를 구함</p>

\[\Sigma = \frac 1 N \Sigma_{i=1}^{N}{(x_i -\mu)(x_i -\mu)^T}\]

\[\Sigma v = \lambda v\]
      </li>
      <li>
        <p>LDA maximizes ratio of projected between-class to projected within-class scatter</p>
        <ul>
          <li>LDA: 각 class별로 covariance matrix를 구함
            <ul>
              <li>within class scatter</li>
            </ul>
          </li>
          <li>Eigen-decomposition: Sigma value가 최대화되는 방향 :
            <ul>
              <li>pca : covariance 최대화</li>
              <li>lda : $\Sigma_b$ 최대화, $\Sigma_w$ 최소화</li>
            </ul>
          </li>
          <li>cluser의 분산이 각각 cluster 내부에서는 cov가 최소
  서로 다른 class 간에는 cov 최대의 방향</li>
        </ul>

\[\Sigma_w = \Sigma_{j=1}^{c}\frac 1 {N_c} \Sigma_{i=1}^{N_c}{(x_i -\mu_c)(x_i -\mu_c)^T}\]

\[\Sigma_c = \frac 1 {c} \Sigma_{i=1}^{c}{(\mu_c-\mu)(\mu_c-\mu)^T}\]

\[\frac{\Sigma_b}{\Sigma_w}v = \lambda v\]
      </li>
    </ul>

    <p>## PCA vs. LDA (for reference)</p>

    <ul>
      <li>eigenvector PCA = var 최대 방향으로 vector를 구함
        <ul>
          <li>원래 vector를 transformation하여 var이 최대화되도록</li>
        </ul>
      </li>
      <li>$z = w^Tx$</li>
      <li>
        <table>
          <tbody>
            <tr>
              <td>Maximize $</td>
              <td> </td>
              <td>z</td>
              <td> </td>
              <td>= z^Tz$  , while $</td>
              <td> </td>
              <td>w</td>
              <td> </td>
              <td>= w^Tw = 1$</td>
            </tr>
          </tbody>
        </table>
        <ul>
          <li>
            <table>
              <tbody>
                <tr>
                  <td>z를 maximize =</td>
                  <td>z</td>
                  <td>최대 = z^Tz 최대화</td>
                </tr>
              </tbody>
            </table>
          </li>
          <li>앞에서 이 weight matrix는 norm =1이 되는 방향으료 표준화해놓고 z 최대화하는 방향으로 eigenvalue vector 구함 → $z^Tz$</li>
        </ul>
      </li>
      <li>$z^Tz = w^Tx(w^Tx)^T = w^Tx x^Tw = w^T \Sigma w$</li>
      <li>
        <p>$\max_w{(z^Tz - \lambda(w^T w-1))} = \max_w{(w^T \Sigma w - \lambda(w^Tw-1))}$</p>
      </li>
      <li>Take derivative w.r.t. $w$</li>
      <li>$2 \Sigma w - 2 \lambda w = 0$</li>
      <li>$\Sigma w = \lambda w$</li>
    </ul>
  </li>
  <li>
    <p><strong>Eigenface</strong></p>

    <p>x new = sigma wi xi</p>

    <ul>
      <li>data의 Weighted sum으로 나온다 : linear data</li>
      <li>whoe data to DNN → 더 효과적이더라</li>
    </ul>
  </li>
</ul>

<h1 id="14-rl">14. RL</h1>

<p><a href="https://www.notion.so/14-Reinforcement-Learning-0fffcc707ee9413a90b11ae19e6be037">14. Reinforcement Learning</a></p>

<ul>
  <li><strong>Characteristics of Reinforcement Learning</strong>
    <ul>
      <li>Feedback is delayed, not instantaneous</li>
      <li>Time really matters (sequential, non i.i.d. data)
        <ul>
          <li>시간이 중요한 요소 중 하나</li>
          <li>sequential : 전반의 선택이 후반의 선택에 영향
  iid = independent identically distributed - 상호 연관</li>
        </ul>
      </li>
      <li>Agent’s actions affect the subsequent data it receives
        <ul>
          <li>agent action이 이후 data에 영향을 미친다.</li>
        </ul>
      </li>
      <li><strong>Goal: select actions to maximize total future reward</strong>
        <ul>
          <li>일련의 행동에 따른 reward가 최대가 되도록 학습한다</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Diff. with supervised, unsupervised learning</strong>
    <ul>
      <li>What makes reinforcement learning different from other machine learning paradigms?</li>
      <li>supervised l. vs unsupervised l. vs. RL
        <ul>
          <li>supervised : label + data</li>
          <li>Unsupervised : just use given data</li>
          <li>RL : data + reward - Reward에 해당하는 추가적인 input이 존재함</li>
        </ul>
      </li>
    </ul>

    <p>→ There is no supervisor, only a reward signal</p>
  </li>
  <li><strong>Rewards</strong>
    <ul>
      <li>Indicate show well agent is doing at step t &amp; The agent’s job is to maximize cumulative reward</li>
      <li>각각의 시간에 얼마나 잘 행동 했는지 보고 reward 최대화되는 방향으로 행동하도록 학습</li>
      <li>Reinforcementlearning is based on the reward hypothesis
        <ul>
          <li>reward = 사람이 만든 기준
  ex. Atari game : target 별 최대한의 점수를 학습할 수 있도록 학습이 되기도 함. 점수가 많은 쪽을 더 빨리 얻을 수 있도록 학습시키는 양상이 생길 수 있다,</li>
          <li>Reward hypothesis: all goals can be described by the m<strong>aximization of expected cumulative reward</strong></li>
        </ul>
      </li>
      <li>Reward may be delayed reward는 delay를 수반하여 주어질 수 있다</li>
      <li>현재 action으로 인한 reward에 더 중점을 둘 것인지, 미래의 reward에 중점을 더 둘 것인지 : user setting할 수도 있고 학습 단계에서 어떻게 parameter를 설정했는지에 따라 / 학습이 잘 효과적으로 이루어질수 있는지를 고려하여 모수 조정
        <ul>
          <li>(greedy) 현재 reward에 초점을 맞추는 경우 - current reward</li>
          <li>(optimal) 전체 reward에 초점을 맞추는 경우 - total reward
            <ul>
              <li>Itmay be better to sacrifice immediate reward to gain more long-term reward (greedy optimal)</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>구성 of RL</strong>
    <ul>
      <li>At each stept the agent: agent가 주변을 관찰하고, reward를 받아 action을 취함
        <ul>
          <li>Executes action At</li>
          <li>Receives observation Ot</li>
          <li>Receives scalar reward Rt</li>
        </ul>
      </li>
      <li>An RL agent may include one or more of these components:
        <ul>
          <li>Policy: agent’s behavior function 행동 정의</li>
          <li>Value function: how good is each state and/or action 얼마나 좋은가</li>
          <li>Model: agent’s representation of the environment  학습 모델</li>
        </ul>
      </li>
    </ul>

    <p>&lt;agent, environment의 상호작용&gt;
  agent는 action을 취하고 state에 따라 Reward를 받게 됨
  env는 action을 받아들여서 agent에게 주고 변환된 statement를 agent에게 줌</p>

    <ul>
      <li>t타임으로 이루어지는 요소들</li>
    </ul>
  </li>
  <li>
    <p><strong>Bellman Eq</strong></p>

\[V(s) = max_a(R(s,a) + \gamma V(s'))\]

    <ul>
      <li>$R(s,a)$ : reward: state에서 취한 action에 따른 reward</li>
      <li>$V(s)$ : is the value function - value function:전체 reward 를 어떻게 표현할 것인가</li>
      <li>$\gamma$ : is the discounting factor
        <ul>
          <li>현재-미래 reward중 어느 것에 초점을 맞출 것인지 중요도 맞추는 상수</li>
        </ul>
      </li>
      <li>$s’$ : is the next state agent can go from
        <ul>
          <li>s : 현재 state, s’ : next state</li>
        </ul>
      </li>
    </ul>

\[V(s) = max_a(R(s,a) + \gamma V(s'))\]

    <ul>
      <li>By calculating V(s) for all states
        <ul>
          <li>Agent can move to the state with larger state value</li>
        </ul>
      </li>
      <li>임의의 출발점에서 state function 커지는 쪽으로 action을 취하면 된다
  → equation을 이용해서 value funcition을 구한후 최적의 path를 구할 수 있다</li>
    </ul>
  </li>
  <li><strong>Sequential Decision Making</strong>
    <ul>
      <li>현재의 action이 다음 턴 action에 영향을 미치는데, 오랜 turn에 대해 영향을 끼칠수도 있음.</li>
      <li>Actions may have long term consequences
        <ul>
          <li>state가 있고 action을 취해서 s1-(a1)-&gt;s2-(a2)-&gt;s3</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
